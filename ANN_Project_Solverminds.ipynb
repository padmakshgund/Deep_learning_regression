{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ANN Project"
      ],
      "metadata": {
        "id": "m5Z2Xkl1d86a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Library"
      ],
      "metadata": {
        "id": "oA8VYRF6dSmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install keras-tuner"
      ],
      "metadata": {
        "id": "cU6o3zXF9zIt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kx2vPQJkIF4N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,InputLayer,Dropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras_tuner.tuners import RandomSearch, GridSearch\n",
        "from tensorflow.keras.regularizers import L1,L2\n",
        "from tensorflow.keras import backend\n",
        "import random\n",
        "random.seed(1)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "Y5XvxG4De8N1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AzRTLH6-NJ5i"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/DEEP Learning Project/Input Data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fzhqIddNPqa",
        "outputId": "fb6c76f7-f50f-4539-bd13-ad5653302dcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12597, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Checking the number of rows and columns in the data\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Dataset has 12597 rows and 2 columns\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lOQYWb1dfT-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data overview"
      ],
      "metadata": {
        "id": "vA0hZVpgfrQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view the first 5 rows of the data\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "W6K248OPfpq9",
        "outputId": "89f42251-47a9-4621-a411-4c13bc93df1a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         X           Y\n",
              "0  12261.2  782.200000\n",
              "1  12271.2  782.414455\n",
              "2  12281.2  782.628910\n",
              "3  12291.2  782.843364\n",
              "4  12301.2  783.057819"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc07c99a-2b48-4e7a-8343-0b86f3e43329\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12261.2</td>\n",
              "      <td>782.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12271.2</td>\n",
              "      <td>782.414455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12281.2</td>\n",
              "      <td>782.628910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12291.2</td>\n",
              "      <td>782.843364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12301.2</td>\n",
              "      <td>783.057819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc07c99a-2b48-4e7a-8343-0b86f3e43329')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc07c99a-2b48-4e7a-8343-0b86f3e43329 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc07c99a-2b48-4e7a-8343-0b86f3e43329');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view the last 5 rows of the data\n",
        "data.tail(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "fcKWwxtyf7AS",
        "outputId": "c545f115-604f-44c4-9030-95255f5dd710"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              X            Y\n",
              "12592  137535.0  2295.533700\n",
              "12593  137545.0  2295.618689\n",
              "12594  137555.0  2295.703677\n",
              "12595  137565.0  2295.788665\n",
              "12596  137575.0  2295.873654"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-848139b9-b64c-4194-bed3-a8c98434816f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12592</th>\n",
              "      <td>137535.0</td>\n",
              "      <td>2295.533700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12593</th>\n",
              "      <td>137545.0</td>\n",
              "      <td>2295.618689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12594</th>\n",
              "      <td>137555.0</td>\n",
              "      <td>2295.703677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12595</th>\n",
              "      <td>137565.0</td>\n",
              "      <td>2295.788665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12596</th>\n",
              "      <td>137575.0</td>\n",
              "      <td>2295.873654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-848139b9-b64c-4194-bed3-a8c98434816f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-848139b9-b64c-4194-bed3-a8c98434816f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-848139b9-b64c-4194-bed3-a8c98434816f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check the datatypes of the columns in the dataset\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh0mlXmigIr9",
        "outputId": "c1378cd1-8605-4c40-c550-7e29499396de"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12597 entries, 0 to 12596\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X       12597 non-null  float64\n",
            " 1   Y       12597 non-null  float64\n",
            "dtypes: float64(2)\n",
            "memory usage: 197.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* There are  12597 observations and 2 columns in the data.\n",
        "* All columns has numerical data type.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FDuKvnXWgVyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's check for duplicate values in the data\n",
        "data.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "204BsH2vgsAl",
        "outputId": "a77370fb-fc37-47b9-db39-7da773310e25"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's view the statistical summary of the numerical columns in the data\n",
        "data.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "2oYzjfB8gxOx",
        "outputId": "128b418d-b939-4384-9a2a-2d203010d78a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     count          mean           std      min           25%           50%  \\\n",
              "X  12597.0  74895.214321  36180.124225  12261.2  43557.400000  74887.400000   \n",
              "Y  12597.0   1568.233102    419.278035    782.2   1230.974888   1559.535675   \n",
              "\n",
              "            75%            max  \n",
              "X  106230.50000  137575.000000  \n",
              "Y    1913.57751    2295.873654  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-256ac6d7-f5e0-477e-bd49-5fc3ec34ad9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>X</th>\n",
              "      <td>12597.0</td>\n",
              "      <td>74895.214321</td>\n",
              "      <td>36180.124225</td>\n",
              "      <td>12261.2</td>\n",
              "      <td>43557.400000</td>\n",
              "      <td>74887.400000</td>\n",
              "      <td>106230.50000</td>\n",
              "      <td>137575.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Y</th>\n",
              "      <td>12597.0</td>\n",
              "      <td>1568.233102</td>\n",
              "      <td>419.278035</td>\n",
              "      <td>782.2</td>\n",
              "      <td>1230.974888</td>\n",
              "      <td>1559.535675</td>\n",
              "      <td>1913.57751</td>\n",
              "      <td>2295.873654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-256ac6d7-f5e0-477e-bd49-5fc3ec34ad9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-256ac6d7-f5e0-477e-bd49-5fc3ec34ad9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-256ac6d7-f5e0-477e-bd49-5fc3ec34ad9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Univariate Analysis"
      ],
      "metadata": {
        "id": "0xVKVgFriCd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot a boxplot and a histogram along the same scale.\n",
        "\n",
        "\n",
        "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
        "    \"\"\"\n",
        "    Boxplot and histogram combined\n",
        "\n",
        "    data: dataframe\n",
        "    feature: dataframe column\n",
        "    figsize: size of figure (default (12,7))\n",
        "    kde: whether to the show density curve (default False)\n",
        "    bins: number of bins for histogram (default None)\n",
        "    \"\"\"\n",
        "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
        "        nrows=2,  # Number of rows of the subplot grid= 2\n",
        "        sharex=True,  # x-axis will be shared among all subplots\n",
        "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
        "        figsize=figsize,\n",
        "    )  # creating the 2 subplots\n",
        "    sns.boxplot(\n",
        "        data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
        "    )  # boxplot will be created and a star will indicate the mean value of the column\n",
        "    sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
        "    ) if bins else sns.histplot(\n",
        "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
        "    )  # For histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
        "    )  # Add mean to the histogram\n",
        "    ax_hist2.axvline(\n",
        "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
        "    )  # Add median to the histogram\n",
        "\n",
        "histogram_boxplot(data,'X')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "el1b_36Yh7ug",
        "outputId": "a2fbe28e-c0f9-49ce-d684-1d23cf4ba0b2"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From the above plot, we observe that there X is uniformaly distributed and has no outlier in that.\n",
        "* Mean == Median for X\n",
        "\n"
      ],
      "metadata": {
        "id": "rrgpfUU8ipj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histogram_boxplot(data,\"Y\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "c_epHhXfjHoV",
        "outputId": "199194a6-80b9-4613-b797-9059fdfcd718"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x700 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+0AAAJaCAYAAABa/6ZqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIKklEQVR4nO39f5xdVX0v/r/OZH4kBCYhQCaJJCRWSxJEQaBh1NoKKUGpSsm9VYuYKtWam6ASL3CpKL/UWFqVSgNIvwq2V0rrR1SKiEJAsSVEjCAEAsItOCiZxDEmAySZzGT29w+bU4cEIWGSvWfyfD4e83jss/c6Z703i8k5r1n77FUriqIIAAAAUDkNZRcAAAAA7JjQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUY1lF1AF/f39efLJJ7PffvulVquVXQ4AAADDXFEUeeqppzJp0qQ0NDz3fLrQnuTJJ5/M5MmTyy4DAACAvcwTTzyRgw8++DmPC+1J9ttvvyS//o/V2tpacjUAAAAMd93d3Zk8eXI9jz4XoT2pXxLf2toqtAMAALDHPN9XtN2IDgAAACpKaAcAAICKEtoBAACgooR2AAAAqCihHQAAACpKaAcAAICKEtoBAACgoqzTDlAhRVFky5YtZZcBg64oivT29iZJmpqanndNWtjbNDc3+70AdkhoB6iQLVu25Oyzzy67DAD2sEsuuSQtLS1llwFUkMvjAQAAoKLMtANU1PxD5qep1lR2GTAoevt7c0XHFUmS+VPmp6nB/9vQW/Tmip9eUXYZQMUJ7QAV1VRrEmwYlpoa/L8NSZL+sgsAhgKXxwMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVFRj2QXwwhRFkS1btiRJmpubU6vVSq4IAACgOoZrZjLTPkRs2bIlZ599ds4+++z6/4gAAAD82nDNTEI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgCU5p7Ge/L+/d6fexrvKbsUAKgkoR0AKEWRIl8a+aU8MeKJfGnkl1KkKLskAKicxrIL4IUpiv/+ILNly5YSKwF2p9/8/f7N33sYjn7U+KM80vhIkuSRxkfyo8Yf5ai+o0quCvYcn+9gcA3Xz1F7ZWjv6elJT09P/XF3d3eJ1bwwvb299e3zzjuvxEqAPaWv6EtzmssuA3aLIkX+aeQ/paFoSH+tPw1FQ/5p5D/l1U+/OrXUyi4P9oi+oq++7fMdDK7e3t6MHDmy7DIGxV55efzixYszZsyY+s/kyZPLLgkA9irbZtn7a/1Jkv5af322HQD4b3vlTPu5556bRYsW1R93d3dXPrg3NTXVtz/+8Y+nudnsGwxHW7Zsqc+2NNb2yn+i2Qs8e5Z9G7Pt7G1+8995n+/gxfvNz1G/mZ+Gur3yE2FLS0taWlrKLmOn1Gr//eGlubl5yNUP7Lzf/L2H4eTepnvr32X/Tb852+677ewNfL6D3Wc4fY7aKy+PBwDKUaTIl0d9ObVixx+makUt/zTyn9xJHgD+i9AOAOwxRa1IV0NXitqOQ/m2433p2+FxANjb7JWXxwMA5WgoGvI33X+TjSM2Pmebsf1j05Th811EAHgxhHYAYI86qP8goRwAXiCXxwMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUY1lF8AL09zcnEsuuaS+DQAAwH8brplJaB8iarVaWlpayi4DAACgkoZrZnJ5PAAAAFSU0A4AAAAVJbQDAABARQntAAAAUFFCOwAAAFSU0A4AAAAVJbQDAABARQntAAAAUFFCOwAAAFSU0A4AAAAVJbQDAABARQntAAAAUFFCOwAAAFSU0A4AAAAVJbQDAABARQntAAAAUFFCOwAAAFSU0A4AAAAVJbQDAABARQntAAAAUFGNZRcAwI71Fr1Jf9lVwODo7e/d4TbszXoLvwvA8xPaASrqip9eUXYJsFtc0eH/bQB4oVweDwAAABVlph2gQpqbm3PJJZeUXQYMuqIo0tv760uBm5qaUqvVSq4IqqW5ubnsEoCKEtoBKqRWq6WlpaXsMmC3GDlyZNklAMCQ4/J4AAAAqCihHQAAACpKaAcAAICKEtoBAACgooR2AAAAqCihHQAAACpKaAcAAICKEtoBAACgohrLLqAKiqJIknR3d5dcCQAAAHuDbflzWx59LkJ7kqeeeipJMnny5JIrAQAAYG/y1FNPZcyYMc95vFY8X6zfC/T39+fJJ5/Mfvvtl1qtVnY5L1p3d3cmT56cJ554Iq2trWWXw04yfkOXsRvajN/QZvyGLmM3tBm/oc34lasoijz11FOZNGlSGhqe+5vrZtqTNDQ05OCDDy67jEHX2trql28IM35Dl7Eb2ozf0Gb8hi5jN7QZv6HN+JXnt82wb+NGdAAAAFBRQjsAAABUlNA+DLW0tOT8889PS0tL2aWwC4zf0GXshjbjN7QZv6HL2A1txm9oM35DgxvRAQAAQEWZaQcAAICKEtoBAACgooR2AAAAqCihHQAAACpKaAcAAICKEtoBgBesKIrMnj07c+bM2e7Y5ZdfnrFjx+ZnP/tZCZUBwPAktAMAL1itVsvVV1+d5cuX5/Of/3x9/2OPPZazzz47l112WQ4++OASKwSA4cU67QDATvvSl76UhQsX5r777svUqVNz/PHHZ+zYsbn++uvLLg0AhhWhHQDYJSeffHI2bNiQU045JRdffHEeeOCBHHTQQWWXBQDDitAOAOyStWvX5rDDDsu6devy1a9+NSeffHLZJQHAsOM77QDALhk/fnz+8i//MjNmzBDYAWA3EdoBgF3W2NiYxsbGsssAgGFLaAcAAICKEtoBAACgooR2AAAAqCh3jwcAAICKMtMOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFdVYdgFV0N/fnyeffDL77bdfarVa2eUAAAAwzBVFkaeeeiqTJk1KQ8Nzz6cL7UmefPLJTJ48uewyAAAA2Ms88cQTOfjgg5/zuNCeZL/99kvy6/9Yra2tJVcDAMPPM888k0mTJiX59R/LR48enWe2PJNJn/6vfR9+MqObR5dZIgDsUd3d3Zk8eXI9jz4XoT2pXxLf2toqtAPAbjBixIj6dmtra0aPHp0RW0YkI39jn9AOwF7o+b6iLbQDAKVobGjMvFfNq28DANvzDgkAlKKlsSXXnHxN2WUAQKVZ8g0AAAAqykw7AFCKoiiysXdjkmSfpn0suwoAO2CmHQAoxcbejdl38b7Zd/G+9fAOAAwktAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUdZpBwBKMaJhRP7HzP9R3wYAtie0AwClGNk4Ml/5n18puwwAqDSXxwMAAEBFmWkHAABg0HR0dKSrq6u0/g888MBMmTKltP4Hm9AOAJTimS3PZN/F+yZJnj736YxuHl1yRQC8WB0dHZk+fUY2bdpYWg2jRu2Thx5aNWyCu9AOAADAoOjq6sqmTRsz6z3np3Xi1D3ef/fqx7P8ixemq6tLaAcAAIAdaZ04NeOmHFp2GcOCG9EBAABARQntAAAAUFEujwcAeJHcKRmA3UVoBwB4EdwpGYDdSWgHAEoxomFE3vTyN9W3hyp3SgZgdxLaAYBSjGwcmW/+2TfLLmPQuFMyALuDG9EBAABARQntAAAAUFFCOwBQime2PJPRnxyd0Z8cnWe2PFN2OQBQSb7TDgCUZmNveXdcB4ChwEw7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJS7xwMApWioNeQPDvmD+jYAsD2hHQAoxaimUfnun3+37DIAoNL8WRsAAAAqSmgHAACAihLaAYBSPLPlmRz0NwfloL85KM9seabscgCgknynHQAoTdfGrrJLAIBKM9MOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUVOmh/ec//3ne+c535oADDsioUaNy+OGH54c//GH9eFEU+djHPpaJEydm1KhRmT17dh555JEBr7Fu3bqceuqpaW1tzdixY3P66afn6aef3tOnAgAAAIOq1ND+q1/9Kq997WvT1NSUb33rW3nwwQfz6U9/Ovvvv3+9zSWXXJLPfe5zufLKK7N8+fKMHj06c+bMyebNm+ttTj311DzwwAO55ZZbcuONN+aOO+7I+973vjJOCQB4gRpqDTl60tE5etLRaaiVPo8AAJVU6pJvf/3Xf53Jkyfn6quvru+bNm1afbsoilx66aU577zz8ta3vjVJ8o//+I9pa2vL17/+9bz97W/PqlWrcvPNN+fuu+/O0UcfnSS57LLL8qY3vSl/+7d/m0mTJu3ZkwIAXpBRTaNy93vvLrsMAKi0Uv+sfcMNN+Too4/O//yf/zPjx4/PkUcemX/4h3+oH3/sscfS2dmZ2bNn1/eNGTMms2bNyrJly5Iky5Yty9ixY+uBPUlmz56dhoaGLF++fM+dDAAAAAyyUmfa//M//zNXXHFFFi1alL/6q7/K3XffnQ984ANpbm7OvHnz0tnZmSRpa2sb8Ly2trb6sc7OzowfP37A8cbGxowbN67e5tl6enrS09NTf9zd3T2YpwUA7EEdHR3p6uoqrf9Vq1aV1jcAw1+pob2/vz9HH310PvnJTyZJjjzyyKxcuTJXXnll5s2bt9v6Xbx4cS688MLd9voAwPPb2LsxM5fMTJI8uODB7NO0z06/RkdHR6ZPn5FNmzYOdnk7rbdnS9klADAMlRraJ06cmJkzZw7YN2PGjHz1q19NkkyYMCFJsmbNmkycOLHeZs2aNTniiCPqbdauXTvgNfr6+rJu3br685/t3HPPzaJFi+qPu7u7M3ny5Bd9PgDAC1cURX664af17V3R1dWVTZs2ZtZ7zk/rxKmDWN0Lt/r+ZVl5w1Xp6+srpX8AhrdSQ/trX/vaPPzwwwP2/eQnP8khhxyS5Nc3pZswYUKWLl1aD+nd3d1Zvnx55s+fnyRpb2/P+vXrs2LFihx11FFJkttuuy39/f2ZNWvWDvttaWlJS0vLbjorANi7vJDL0zdt2lTfvvfeezNq1Khs6nvWvsZRO933tkvTWydOzbgph+708wdD9+rHS+kXgL1DqaH9zDPPzGte85p88pOfzJ/+6Z/mBz/4Qa666qpcddVVSZJarZYPfehD+fjHP56Xv/zlmTZtWj760Y9m0qRJOfnkk5P8emb+xBNPzHvf+95ceeWV6e3tzcKFC/P2t7/dneMBYDfblcvTX/e61/16oynJR35jX++u1+HSdACGq1JD+zHHHJOvfe1rOffcc3PRRRdl2rRpufTSS3PqqafW25x99tl55pln8r73vS/r16/P6173utx8880ZOXJkvc2Xv/zlLFy4MMcff3waGhoyd+7cfO5znyvjlABgr/JCL0/fuqUnt/3N+5Mkx511ZUY0t2RrenJb/mvf2VdmRHb+KjiXpgMw3JUa2pPkj//4j/PHf/zHz3m8VqvloosuykUXXfScbcaNG5drr712d5QHALwAz3d5el/Pf18Kv//kl6exZVT6+jcla/5r38EvT2PDzl8e79J0gIGsqDH8lB7aAQAAePGsqDE8Ce0AMIQN6RmVWi2tjdPq2wC8OFbUGJ6EdgAYoob6jEpjbWTeeNCXd0M1AHs3K2oML0I7AAxRZlQAYPgT2gFgiDOjAgDDV0PZBQAAe6e+YnO+9YtT861fnJq+YnPZ5QBAJZlpBwDKURTp7nusvh33ogOA7ZhpBwAAgIoS2gEAAKCiXB4PAC9Cmeukv6g10gGAIUFoB4BdVJV10ndljXQAYGgQ2gFgF5W9Tro10gFg+BPaAeBFKmud9CG/Rnqtln1GTKhvAwDbE9oBgFI01kbmzeOvL7sMAKg0d48HAACAihLaAQAAoKJcHg/AkFXmcmuJJdderL6iJ7f9cn6S5LgDrkhjraXkigCgeoR2AIakqiy3llhybZcV/flV70P17bgXHQBsR2gHYEgqe7m1xJJrAMDuJ7QDMKSVtdxaMgyWXAMAKs+N6AAAAKCihHYAAACoKKEdAAAAKsp32gGA0rQ0jC27BACoNKEdgF1W5jrp1kgf+hobRuXktpvKLgMAKk1oB2CXVGWddGukAwDDmdAOMESVOcud/Hqmu8x10q2RDgDsDYR2gCGoKrPcSTJq3KRS1km3RvrQ11f05I51i5Ikrx/3mTTWWkquCACqR2gHGIK6urpKneVOzHQzCIr+/GLLPfXt1MotBwCqSGgHGMJaJ04tZZY7MdMNALAnWKcdAAAAKspMOwDAMFD2MogHHnhgpkyZUmoNAMOR0A4AMIRt2vDLJLW8853vLLWOUaP2yUMPrRLcAQaZ0A4AMIT1bnwqSZEj/uycHDRteik1dK9+PMu/eGG6urqEdoBBJrQDAKUZURtZdgnDxr7jp5R2Y0oAdh+hHQAoRWPDqPyPCbeVXQYAVJq7xwMAAEBFCe0AAABQUUI7AFCKrUVP7lj34dyx7sPZWvSUXQ4AVJLvtAMApSiK/qzuWVbfTq3kggCggsy0AwAAQEWZaQfYRR0dHenq6iql71WrVpXSLwAAe1apof2CCy7IhRdeOGDfoYcemoceeihJsnnz5nz4wx/Oddddl56ensyZMyeXX3552tra6u07Ojoyf/783H777dl3330zb968LF68OI2N/h4B7D4dHR2ZPn1GNm3aWGodvT1bSu0fAIDdq/Rke9hhh+XWW2+tP/7NsH3mmWfmm9/8Zr7yla9kzJgxWbhwYU455ZT8x3/8R5Jk69atOemkkzJhwoTceeedWb16dd71rnelqakpn/zkJ/f4uQB7j66urmzatDGz3nN+WidO3eP9r75/WVbecFX6+vr2eN8AAOw5pYf2xsbGTJgwYbv9GzZsyBe+8IVce+21Oe6445IkV199dWbMmJG77rorxx57bL7zne/kwQcfzK233pq2trYcccQRufjii3POOefkggsuSHNz854+HWAv0zpxasZNOXSP99u9+vE93icA8Px8fY7BVnpof+SRRzJp0qSMHDky7e3tWbx4caZMmZIVK1akt7c3s2fPrredPn16pkyZkmXLluXYY4/NsmXLcvjhhw+4XH7OnDmZP39+HnjggRx55JE77LOnpyc9Pf+9tEx3d/fuO0EAAGCv4Otz7A6lhvZZs2blmmuuyaGHHprVq1fnwgsvzO///u9n5cqV6ezsTHNzc8aOHTvgOW1tbens7EySdHZ2Dgjs245vO/ZcFi9evN136QGAPauxYVTeNvHOsssAGDS+PsfuUGpof+Mb31jffuUrX5lZs2blkEMOyb/+679m1KhRu63fc889N4sWLao/7u7uzuTJk3dbfwAAwN7D1+cYTJVap33s2LH53d/93Tz66KOZMGFCtmzZkvXr1w9os2bNmvp34CdMmJA1a9Zsd3zbsefS0tKS1tbWAT8AAABQNZUK7U8//XT+3//7f5k4cWKOOuqoNDU1ZenSpfXjDz/8cDo6OtLe3p4kaW9vz/3335+1a9fW29xyyy1pbW3NzJkz93j9AMALt7XoyX/86iP5j199JFuLnud/AgDshUq9PP5//+//nTe/+c055JBD8uSTT+b888/PiBEj8o53vCNjxozJ6aefnkWLFmXcuHFpbW3NGWeckfb29hx77LFJkhNOOCEzZ87MaaedlksuuSSdnZ0577zzsmDBgrS0tJR5agDA8yiK/vxs8+3/tX1eUiu5IACooFJD+89+9rO84x3vyC9/+cscdNBBed3rXpe77rorBx10UJLks5/9bBoaGjJ37tz09PRkzpw5ufzyy+vPHzFiRG688cbMnz8/7e3tGT16dObNm5eLLrqorFMCAACAQVNqaL/uuut+6/GRI0dmyZIlWbJkyXO2OeSQQ3LTTTcNdmkAAABQukp9px0AAAD4b0I7AAAAVFSpl8cD7KqOjo50dXWV1v+qVatK6xsAgL2H0A4MOR0dHZk+fUY2bdpYdinp7dlSdgkAAAxjQjsw5HR1dWXTpo2Z9Z7z0zpxaik1rL5/WVbecFX6+vpK6R+GgxG1kZnbtrS+DQBsT2gHhqzWiVMzbsqhpfTdvfrxUvqF4aRWq6WxNqrsMgCg0tyIDgAAACrKTDsAUIqtxZb8cMMlSZKjx5ydEbXmkisCgOox0w4AlKIotubxTTfl8U03pSi2ll0OAFSS0A4AAAAVJbQDAABARQntAAAAUFFuRAfsko6OjnR1dZXS96pVq0rpFwAA9jShHdhpHR0dmT59RjZt2lhqHb09W0rtHwAAdjehHdhpXV1d2bRpY2a95/y0Tpy6x/tfff+yrLzhqvT19e3xvgEAYE8S2oFd1jpxasZNOXSP99u9+vE93icw+EbURuat479Z3wYAtie0AwClqNVqGTli/7LLAIBKc/d4AAAAqCgz7QBAKbYWW3Jv9+eSJEe0fiAjas0lVwQA1WOmHQAoRVFszaMbr8+jG69PUWwtuxwAqCShHQAAACpKaAcAAICKEtoBAACgooR2AAAAqCihHQAAACpKaAcAAICKsk47DEEdHR3p6uoqrf9Vq1aV1jcwfIyoteSPD/pqfRsA2J7QDkNMR0dHpk+fkU2bNpZdSnp7tpRdAjCE1WoNGd04sewyAKDShHYYYrq6urJp08bMes/5aZ04tZQaVt+/LCtvuCp9fX2l9A8AAHsLoR2GqNaJUzNuyqGl9N29+vFS+gWGl61Fb+5/6vNJksP3+8uMqDWVXBEAVI8b0QEApSiKvjz8zLV5+JlrUxSu3AGAHRHaAQAAoKKEdgAAAKgooR0AAAAqSmgHAACAihLaAQAAoKKEdgAAAKgo67QDAKUYUWvJiQf+3/o2ALA9oR12UkdHR7q6ukrrf9WqVaX1DTCYarWGjGl6adllMEyU/f6cJAceeGCmTJlSag3A8CO0w07o6OjI9OkzsmnTxrJLSW/PlrJLAIBKqMr786hR++Shh1YJ7iUq+483JlfYHYR22AldXV3ZtGljZr3n/LROnFpKDavvX5aVN1yVvr6+UvoHGCxbi96sevpLSZIZ+87LiFpTyRUxVFXh/bl79eNZ/sUL09XVJbSXpCp/vElMrjC4hHbYBa0Tp2bclENL6bt79eOl9Asw2IqiLw88/cUkyfTRpyZCOy9Sme/PlK8Kf7wxucLuUJnQ/qlPfSrnnntuPvjBD+bSSy9NkmzevDkf/vCHc91116Wnpydz5szJ5Zdfnra2tvrzOjo6Mn/+/Nx+++3Zd999M2/evCxevDiNjZU5NQAAYA8xucJwU4kl3+6+++58/vOfzytf+coB+88888z827/9W77yla/ke9/7Xp588smccsop9eNbt27NSSedlC1btuTOO+/Ml770pVxzzTX52Mc+tqdPAQAAAAZd6dPRTz/9dE499dT8wz/8Qz7+8Y/X92/YsCFf+MIXcu211+a4445Lklx99dWZMWNG7rrrrhx77LH5zne+kwcffDC33npr2tracsQRR+Tiiy/OOeeckwsuuCDNzc1lnRYAAHuhMm9E5u71MDyVHtoXLFiQk046KbNnzx4Q2lesWJHe3t7Mnj27vm/69OmZMmVKli1blmOPPTbLli3L4YcfPuBy+Tlz5mT+/Pl54IEHcuSRR+6wz56envT09NQfd3d374YzAwBgb7Fpwy+T1PLOd76ztBrcvR6Gp1JD+3XXXZcf/ehHufvuu7c71tnZmebm5owdO3bA/ra2tnR2dtbb/GZg33Z827Hnsnjx4lx44YUvsnoAAPi13o1PJSlyxJ+dk4OmTd/j/bt7PQxfpYX2J554Ih/84Adzyy23ZOTIkXu073PPPTeLFi2qP+7u7s7kyZP3aA0AAMNNWZeGV2lt7H3HT3EHe2BQlRbaV6xYkbVr1+bVr351fd/WrVtzxx135O///u/z7W9/O1u2bMn69esHzLavWbMmEyZMSJJMmDAhP/jBDwa87po1a+rHnktLS0taWloG8WzYkzo6OtLV1VVK31X6UAAw1DXUmjP7gP9ffZuhqwqXhifWxgaGp9JC+/HHH5/7779/wL53v/vdmT59es4555xMnjw5TU1NWbp0aebOnZskefjhh9PR0ZH29vYkSXt7ez7xiU9k7dq1GT9+fJLklltuSWtra2bOnLlnT4g9oqOjI9Onz8imTRtLrcOHAoAXr6E2Igc0e78eDsq+NNza2MBwVlpo32+//fKKV7xiwL7Ro0fngAMOqO8//fTTs2jRoowbNy6tra0544wz0t7enmOPPTZJcsIJJ2TmzJk57bTTcskll6SzszPnnXdeFixYYCZ9mOrq6sqmTRsz6z3np3Xi1D3evw8FAPDcyro03NrYwHBW+t3jf5vPfvazaWhoyNy5c9PT05M5c+bk8ssvrx8fMWJEbrzxxsyfPz/t7e0ZPXp05s2bl4suuqjEqtkTWidO9aEAYIjbWvTmkWf+NUny8tF/mhG1ppIrgqGv7K/yWXYOBl+lQvt3v/vdAY9HjhyZJUuWZMmSJc/5nEMOOSQ33XTTbq4MABhsRdGXHz/16/f4l+1zSiK0wy6ryn0FLDsHg69SoR0AANh5Zd9XILHsHOwuQjsAAAwTlpyD4aeh7AIAAACAHdul0P7Sl740v/zlL7fbv379+rz0pS990UUBAAAAuxjaH3/88WzdunW7/T09Pfn5z3/+oosCAAAAdvI77TfccEN9+9vf/nbGjBlTf7x169YsXbo0U6dOHbTiAAAAYG+2U6H95JNPTpLUarXMmzdvwLGmpqZMnTo1n/70pwetOABg+GqoNecN4/6+vg0AbG+nQnt/f3+SZNq0abn77rtz4IEH7paiAIDhr6E2IuNbXl12GQBQabu05Ntjjz022HUAAAAAz7LL67QvXbo0S5cuzdq1a+sz8Nt88YtffNGFAQDDW3/Rl/+38RtJkt/Z561pqO3yxxKgQlatWrVX9Qu72y69O1544YW56KKLcvTRR2fixImp1WqDXRcAMMz1F735Ufev74UzbdSbhHYY4jZt+GWSWt75zneWWkdvz5ZS+4fBtkvvjldeeWWuueaanHbaaYNdDwAAMAT1bnwqSZEj/uycHDRt+h7vf/X9y7LyhqvS19e3x/uG3WmXQvuWLVvymte8ZrBrAQAAhrh9x0/JuCmH7vF+u1c/vsf7hD2hYVee9Bd/8Re59tprB7sWAAAA4Dfs0kz75s2bc9VVV+XWW2/NK1/5yjQ1NQ04/pnPfGZQigMAAIC92S6F9vvuuy9HHHFEkmTlypUDjrkpHQAAAAyOXQrtt99++2DXAQAAADyLtVUAgFI01Jry+/v/TX0bANjeLoX2N7zhDb/1MvjbbrttlwsCAPYODbXGTBr52rLLAIBK26XQvu377Nv09vbm3nvvzcqVKzNv3rzBqAsAAAD2ersU2j/72c/ucP8FF1yQp59++kUVBADsHfqLvvx007eTJIeMmpOGmm/tAcCz7dI67c/lne98Z774xS8O5ksCAMNUf9GbH2z4RH6w4RPpL3rLLgcAKmlQQ/uyZcsycuTIwXxJAAAA2Gvt0nVop5xyyoDHRVFk9erV+eEPf5iPfvSjg1IYAAAA7O12KbSPGTNmwOOGhoYceuihueiii3LCCScMSmEAAACwt9ul0H711VcPdh0AAADAs7yo27SuWLEiq1atSpIcdthhOfLIIwelKAAAAGAXQ/vatWvz9re/Pd/97nczduzYJMn69evzhje8Idddd10OOuigwawRAAAA9kq7dPf4M844I0899VQeeOCBrFu3LuvWrcvKlSvT3d2dD3zgA4NdIwAwDDXUmvKasR/Pa8Z+PA21prLLAYBK2qWZ9ptvvjm33nprZsyYUd83c+bMLFmyxI3ohrmOjo50dXWV1v+2r2MAMPQ11BozedRxZZcBAJW2S6G9v78/TU3b/0W8qakp/f39L7ooqqmjoyPTp8/Ipk0byy4lvT1byi4BAABgt9ul0H7cccflgx/8YP75n/85kyZNSpL8/Oc/z5lnnpnjjz9+UAukOrq6urJp08bMes/5aZ04tZQaVt+/LCtvuCp9fX2l9A/A4Okv+vLzzXckSV4y8vVpqL2o++MCwLC0S++Of//3f5+3vOUtmTp1aiZPnpwkeeKJJ/KKV7wi//f//t9BLZDqaZ04NeOmHFpK392rHy+lXwAGX3/RmzvXn5ckmdu2VGgHgB3YpXfHyZMn50c/+lFuvfXWPPTQQ0mSGTNmZPbs2YNaHAAAAOzNduru8bfddltmzpyZ7u7u1Gq1/NEf/VHOOOOMnHHGGTnmmGNy2GGH5fvf//7uqhUAAAD2KjsV2i+99NK8973vTWtr63bHxowZk7/8y7/MZz7zmUErDgAAAPZmOxXaf/zjH+fEE098zuMnnHBCVqxY8aKLAgAAAHYytK9Zs2aHS71t09jYmF/84hcvuigAAABgJ0P7S17ykqxcufI5j993332ZOHHiiy4KAAAA2MnQ/qY3vSkf/ehHs3nz5u2Obdq0Keeff37++I//eNCKAwCGr4ZaU35vzEfye2M+kobac1/JBwB7s51a8u28887L9ddfn9/93d/NwoULc+ihv16r+6GHHsqSJUuydevWfOQjH9kthQIAw0tDrTHT9jmp7DIAoNJ2KrS3tbXlzjvvzPz583PuueemKIokSa1Wy5w5c7JkyZK0tbXtlkIBAABgb7NTl8cnySGHHJKbbropXV1dWb58ee666650dXXlpptuyrRp03bqta644oq88pWvTGtra1pbW9Pe3p5vfetb9eObN2/OggULcsABB2TffffN3Llzs2bNmgGv0dHRkZNOOin77LNPxo8fn7POOit9fX07e1oAwB7WX/Tlyc3/kSc3/0f6C+/dALAjOzXT/pv233//HHPMMS+q84MPPjif+tSn8vKXvzxFUeRLX/pS3vrWt+aee+7JYYcdljPPPDPf/OY385WvfCVjxozJwoULc8opp+Q//uM/kiRbt27NSSedlAkTJuTOO+/M6tWr8653vStNTU355Cc/+aJqAwB2r/6iN9//1VlJkrltS9NQ2+WPJQAwbJX67vjmN795wONPfOITueKKK3LXXXfl4IMPzhe+8IVce+21Oe6445IkV199dWbMmJG77rorxx57bL7zne/kwQcfzK233pq2trYcccQRufjii3POOefkggsuSHNzcxmnBQAAAINipy+P3122bt2a6667Ls8880za29uzYsWK9Pb2Zvbs2fU206dPz5QpU7Js2bIkybJly3L44YcP+B79nDlz0t3dnQceeOA5++rp6Ul3d/eAHwAAAKia0kP7/fffn3333TctLS15//vfn6997WuZOXNmOjs709zcnLFjxw5o39bWls7OziRJZ2fndje+2/Z4W5sdWbx4ccaMGVP/mTx58uCeFAAAAAyC0kP7oYcemnvvvTfLly/P/PnzM2/evDz44IO7tc9zzz03GzZsqP888cQTu7U/AAAA2BWl3/Glubk5L3vZy5IkRx11VO6+++783d/9Xd72trdly5YtWb9+/YDZ9jVr1mTChAlJkgkTJuQHP/jBgNfbdnf5bW12pKWlJS0tLYN8JgAAADC4Sp9pf7b+/v709PTkqKOOSlNTU5YuXVo/9vDDD6ejoyPt7e1Jkvb29tx///1Zu3Ztvc0tt9yS1tbWzJw5c4/XDgAAAIOp1Jn2c889N2984xszZcqUPPXUU7n22mvz3e9+N9/+9rczZsyYnH766Vm0aFHGjRuX1tbWnHHGGWlvb8+xxx6bJDnhhBMyc+bMnHbaabnkkkvS2dmZ8847LwsWLDCTDgAV11BryqtbP1zfBgC2V2poX7t2bd71rndl9erVGTNmTF75ylfm29/+dv7oj/4oSfLZz342DQ0NmTt3bnp6ejJnzpxcfvnl9eePGDEiN954Y+bPn5/29vaMHj068+bNy0UXXVTWKQEAL1BDrTEvHz237DIAoNJKDe1f+MIXfuvxkSNHZsmSJVmyZMlztjnkkENy0003DXZpAAAAULrSb0QHAOyd+out6dry4yTJgc2vSkNtRMkVAUD1CO0AQCn6iy25fd3CJMnctqVpqI0quSIAqJ7K3T0eAAAA+DUz7UNMR0dHurq6Sul71apVpfQLAACwtxLah5COjo5Mnz4jmzZtLLWO3p4tpfYPAACwtxDah5Curq5s2rQxs95zflonTt3j/a++f1lW3nBV+vr69njfAAAAeyOhfQhqnTg146Ycusf77V79+B7vEwAAYG/mRnQAAABQUWbaAYBS1GqNedV+C+rbAMD2vEMCAKUYUWvK9H1PLbsMAKg0l8cDAABARZlpBwBK0V9sza96H06S7N90aBpqI0quCACqR2gHAErRX2zJrb/8iyTJ3LalaaiNKrkiAKgel8cDAABARQntAAAAUFFCOwAAAFSU0A4AAAAVJbQDAABARQntAAAAUFGWfAMASlGrNeawfd9T3wYAtucdEgAoxYhaU16x31+UXQYAVJrL4wEAAKCizLQDAKUoiv509z2eJGltnJpazVwCADyb0A4AlGJr0ZObu96ZJJnbtjSNtVElVwQA1eNP2gAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlCXfAIBS1GqNOXT0n9W3AYDteYcEAEoxotaUI1oXll0GAFSay+MBAACgosy0AwClKIr+bNy6Jkmyz4i21GrmEgDg2YR2AKAUW4ue3PiLuUmSuW1L01gbVXJFAFA9/qQNAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFSW0AwAAQEVZ8g0AKEWtNiIv2+eU+jYAsL1SZ9oXL16cY445Jvvtt1/Gjx+fk08+OQ8//PCANps3b86CBQtywAEHZN99983cuXOzZs2aAW06Ojpy0kknZZ999sn48eNz1llnpa+vb0+eCgCwk0bUmnPUmP+do8b874yoNZddDgBUUqmh/Xvf+14WLFiQu+66K7fcckt6e3tzwgkn5Jlnnqm3OfPMM/Nv//Zv+cpXvpLvfe97efLJJ3PKKafUj2/dujUnnXRStmzZkjvvvDNf+tKXcs011+RjH/tYGacEAAAAg6bUy+NvvvnmAY+vueaajB8/PitWrMjrX//6bNiwIV/4whdy7bXX5rjjjkuSXH311ZkxY0buuuuuHHvssfnOd76TBx98MLfeemva2tpyxBFH5OKLL84555yTCy64IM3N/nIPAFVUFEV6+tcnSVoaxqZWq5VbEABUUKVuRLdhw4Ykybhx45IkK1asSG9vb2bPnl1vM3369EyZMiXLli1LkixbtiyHH3542tra6m3mzJmT7u7uPPDAAzvsp6enJ93d3QN+AIA9a2uxOd9Ye1K+sfakbC02l10OAFRSZUJ7f39/PvShD+W1r31tXvGKVyRJOjs709zcnLFjxw5o29bWls7Oznqb3wzs245vO7YjixcvzpgxY+o/kydPHuSzAQAAgBevMqF9wYIFWblyZa677rrd3te5556bDRs21H+eeOKJ3d4nAAAA7KxKLPm2cOHC3Hjjjbnjjjty8MEH1/dPmDAhW7Zsyfr16wfMtq9ZsyYTJkyot/nBD34w4PW23V1+W5tna2lpSUtLyyCfBQAAAAyuUmfai6LIwoUL87WvfS233XZbpk2bNuD4UUcdlaampixdurS+7+GHH05HR0fa29uTJO3t7bn//vuzdu3aeptbbrklra2tmTlz5p45EQAAANgNSp1pX7BgQa699tp84xvfyH777Vf/DvqYMWMyatSojBkzJqeffnoWLVqUcePGpbW1NWeccUba29tz7LHHJklOOOGEzJw5M6eddlouueSSdHZ25rzzzsuCBQvMpgMAADCklRrar7jiiiTJH/7hHw7Yf/XVV+fP//zPkySf/exn09DQkLlz56anpydz5szJ5ZdfXm87YsSI3HjjjZk/f37a29szevTozJs3LxdddNGeOg0AAADYLUoN7UVRPG+bkSNHZsmSJVmyZMlztjnkkENy0003DWZpAMBuVquNyNRRb6pvAwDbq8SN6ACAvc+IWnNmjT2v7DIAoNIqs+QbAAAAMJCZdgCgFEVRZGuxOUkyojYytVqt5IoAoHrMtAMApdhabM5X1xyfr645vh7eAYCBhHYAAACoKKEdAAAAKkpoBwAAgIoS2gEAAKCihHYAAACoKKEdAAAAKso67QBAKWq1hhw88g31bQBge0I7AFCKEbWWvHb/T5RdBgBUmj9rAwAAQEUJ7QAAAFBRQjsAUIq+/k35l9Wvyb+sfk36+jeVXQ4AVJLQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFNZZdAACwd6rVGjKxpb2+DQBsT2gHAEoxotaS14/7dNllAECl+bM2AAAAVJTQDgAAABUltAMApejr35T/r/O4/H+dx6Wvf1PZ5QBAJflOOwBQmq3F5rJLAIBKM9MOAAAAFSW0AwAAQEUJ7QAAAFBRQjsAAABUlNAOAAAAFeXu8QBAOWoNOaj5yPo2ALA9oR0AKEVjrSXHHbCk7DIAoNL8WRsAAAAqSmgHAACAihLaAYBS9PVvytfXvClfX/Om9PVvKrscAKgk32kHAErT07++7BIAoNLMtAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABVVami/44478uY3vzmTJk1KrVbL17/+9QHHi6LIxz72sUycODGjRo3K7Nmz88gjjwxos27dupx66qlpbW3N2LFjc/rpp+fpp5/eg2cBAAAAu0epof2ZZ57Jq171qixZsmSHxy+55JJ87nOfy5VXXpnly5dn9OjRmTNnTjZv3lxvc+qpp+aBBx7ILbfckhtvvDF33HFH3ve+9+2pUwAAdlWtIfs3Tc/+TdOTmov/AGBHSl3y7Y1vfGPe+MY37vBYURS59NJLc9555+Wtb31rkuQf//Ef09bWlq9//et5+9vfnlWrVuXmm2/O3XffnaOPPjpJctlll+VNb3pT/vZv/zaTJk3aY+cCAOycxlpLTjjwi2WXAQCVVtk/az/22GPp7OzM7Nmz6/vGjBmTWbNmZdmyZUmSZcuWZezYsfXAniSzZ89OQ0NDli9f/pyv3dPTk+7u7gE/AAAAUDWVDe2dnZ1Jkra2tgH729ra6sc6Ozszfvz4AccbGxszbty4epsdWbx4ccaMGVP/mTx58iBXDwAAAC9eZUP77nTuuedmw4YN9Z8nnnii7JIAYK/TV2zOv609Jf+29pT0FZuf/wkAsBcq9Tvtv82ECROSJGvWrMnEiRPr+9esWZMjjjii3mbt2rUDntfX15d169bVn78jLS0taWlpGfyiAYAXriiycWtnfTu1cssBgCqq7Ez7tGnTMmHChCxdurS+r7u7O8uXL097e3uSpL29PevXr8+KFSvqbW677bb09/dn1qxZe7xmAAAAGEylzrQ//fTTefTRR+uPH3vssdx7770ZN25cpkyZkg996EP5+Mc/npe//OWZNm1aPvrRj2bSpEk5+eSTkyQzZszIiSeemPe+97258sor09vbm4ULF+btb3+7O8cDAAAw5JUa2n/4wx/mDW94Q/3xokWLkiTz5s3LNddck7PPPjvPPPNM3ve+92X9+vV53etel5tvvjkjR46sP+fLX/5yFi5cmOOPPz4NDQ2ZO3duPve5z+3xcwEAAIDBVmpo/8M//MMURfGcx2u1Wi666KJcdNFFz9lm3Lhxufbaa3dHeQAAAFCqyn6nHQAAAPZ2lb17PAAwzNVqaW2cVt8GALYntAMApWisjcwbD/py2WUAQKW5PB4AAAAqSmgHAACAihLaAYBS9BWb861fnJpv/eLU9BWbyy4HACrJd9oBgHIURbr7Hqtvx73oAGA7ZtoBAACgooR2AAAAqCihHQAAACpKaAcAAICKEtoBAACgotw9HgAoR62WfUZMqG8DANsT2gGAUjTWRubN468vuwwAqDSXxwMAAEBFCe0AAABQUUI7AFCKvqIn3+l6T77T9Z70FT1llwMAleQ77QBAOYr+/Kr3ofp23IsOALZjph0AAAAqSmgHAACAihLaAQAAoKKEdgAAAKgooR0AAAAqyt3jAYDStDSMLbsEAKg0oR0AKEVjw6ic3HZT2WUAQKW5PB4AAAAqSmgHAACAihLaAYBS9BU9ue2XC3LbLxekr+gpuxwAqCTfaQcAylH05xdb7qlvp1ZuOQBQRWbaAQAAoKKEdgAAAKgooR0AAAAqSmgHAACAihLaAQAAoKLcPR4AKM2I2siySwCAShPaAYBSNDaMyv+YcFvZZQBApbk8HgAAACpKaAcAAICKEtoBgFJsLXpyx7oP5451H87WoqfscgCgknynHQAoRVH0Z3XPsvp2aiUXBAAVZKYdAAAAKmrYhPYlS5Zk6tSpGTlyZGbNmpUf/OAHZZcEAAAAL8qwCO3/8i//kkWLFuX888/Pj370o7zqVa/KnDlzsnbt2rJLAwAAgF02LEL7Zz7zmbz3ve/Nu9/97sycOTNXXnll9tlnn3zxi18suzQAAADYZUM+tG/ZsiUrVqzI7Nmz6/saGhoye/bsLFu2rMTKAAAA4MUZ8neP7+rqytatW9PW1jZgf1tbWx566KEdPqenpyc9Pf+9tMyGDRuSJN3d3buv0EHw9NNPJ0nW/fTh9PVs2uP9d6/+aZJkw88fSVNjObf4LbuGsvtXQzX6r0INZfdfhRrK7r8KNZTd/87UsHXLf7/v/uLR+zKiuSVb01P/JPKL/3dfRqRlt/W/O5VdQ9n9V6GGsvuvQg1l91+FGsruvwo1lN1/FWro7uxI8uvsVPV8t62+oih+a7ta8XwtKu7JJ5/MS17yktx5551pb2+v7z/77LPzve99L8uXL9/uORdccEEuvPDCPVkmAAAAbOeJJ57IwQcf/JzHh/xM+4EHHpgRI0ZkzZo1A/avWbMmEyZM2OFzzj333CxatKj+uL+/P+vWrcsBBxyQWm3oLxLb3d2dyZMn54knnkhra2vZ5bCTjN/QZeyGNuM3tBm/ocvYDW3Gb2gzfuUqiiJPPfVUJk2a9FvbDfnQ3tzcnKOOOipLly7NySefnOTXIXzp0qVZuHDhDp/T0tKSlpaBl+CNHTt2N1e657W2tvrlG8KM39Bl7IY24ze0Gb+hy9gNbcZvaDN+5RkzZszzthnyoT1JFi1alHnz5uXoo4/O7/3e7+XSSy/NM888k3e/+91llwYAAAC7bFiE9re97W35xS9+kY997GPp7OzMEUcckZtvvnm7m9MBAADAUDIsQnuSLFy48Dkvh9/btLS05Pzzz9/uKwAMDcZv6DJ2Q5vxG9qM39Bl7IY24ze0Gb+hYcjfPR4AAACGq4ayCwAAAAB2TGgHAACAihLaAQAAoKKEdgAAAKgooX2I2Lp1az760Y9m2rRpGTVqVH7nd34nF198cX7zPoJFUeRjH/tYJk6cmFGjRmX27Nl55JFHBrzOunXrcuqpp6a1tTVjx47N6aefnqeffnpPn86wd8cdd+TNb35zJk2alFqtlq9//esDjg/WWN133335/d///YwcOTKTJ0/OJZdcsrtPbdj7bWPX29ubc845J4cffnhGjx6dSZMm5V3veleefPLJAa9h7MrzfL97v+n9739/arVaLr300gH7jV95Xsj4rVq1Km95y1syZsyYjB49Osccc0w6Ojrqxzdv3pwFCxbkgAMOyL777pu5c+dmzZo1A16jo6MjJ510UvbZZ5+MHz8+Z511Vvr6+nb36Q1rzzd2Tz/9dBYuXJiDDz44o0aNysyZM3PllVcOaGPsyrN48eIcc8wx2W+//TJ+/PicfPLJefjhhwe0Gazx+e53v5tXv/rVaWlpycte9rJcc801u/v0hrXnG7t169bljDPOyKGHHppRo0ZlypQp+cAHPpANGzYMeB1jV3EFQ8InPvGJ4oADDihuvPHG4rHHHiu+8pWvFPvuu2/xd3/3d/U2n/rUp4oxY8YUX//614sf//jHxVve8pZi2rRpxaZNm+ptTjzxxOJVr3pVcddddxXf//73i5e97GXFO97xjjJOaVi76aabio985CPF9ddfXyQpvva1rw04PhhjtWHDhqKtra049dRTi5UrVxb//M//XIwaNar4/Oc/v6dOc1j6bWO3fv36Yvbs2cW//Mu/FA899FCxbNmy4vd+7/eKo446asBrGLvyPN/v3jbXX3998apXvaqYNGlS8dnPfnbAMeNXnucbv0cffbQYN25ccdZZZxU/+tGPikcffbT4xje+UaxZs6be5v3vf38xefLkYunSpcUPf/jD4thjjy1e85rX1I/39fUVr3jFK4rZs2cX99xzT3HTTTcVBx54YHHuuefuqdMclp5v7N773vcWv/M7v1PcfvvtxWOPPVZ8/vOfL0aMGFF84xvfqLcxduWZM2dOcfXVVxcrV64s7r333uJNb3pTMWXKlOLpp5+utxmM8fnP//zPYp999ikWLVpUPPjgg8Vll11WjBgxorj55pv36PkOJ883dvfff39xyimnFDfccEPx6KOPFkuXLi1e/vKXF3Pnzq2/hrGrPqF9iDjppJOK97znPQP2nXLKKcWpp55aFEVR9Pf3FxMmTCj+5m/+pn58/fr1RUtLS/HP//zPRVEUxYMPPlgkKe6+++56m29961tFrVYrfv7zn++Bs9g7PfvDy2CN1eWXX17sv//+RU9PT73NOeecUxx66KG7+Yz2Hr8t9G3zgx/8oEhS/PSnPy2KwthVyXON389+9rPiJS95SbFy5crikEMOGRDajV917Gj83va2txXvfOc7n/M569evL5qamoqvfOUr9X2rVq0qkhTLli0riuLX4bKhoaHo7Oyst7niiiuK1tbWAWPKrtvR2B122GHFRRddNGDfq1/96uIjH/lIURTGrmrWrl1bJCm+973vFUUxeONz9tlnF4cddtiAvt72trcVc+bM2d2ntNd49tjtyL/+678Wzc3NRW9vb1EUxm4ocHn8EPGa17wmS5cuzU9+8pMkyY9//OP8+7//e974xjcmSR577LF0dnZm9uzZ9eeMGTMms2bNyrJly5Iky5Yty9ixY3P00UfX28yePTsNDQ1Zvnz5HjybvdtgjdWyZcvy+te/Ps3NzfU2c+bMycMPP5xf/epXe+hs2LBhQ2q1WsaOHZvE2FVdf39/TjvttJx11lk57LDDtjtu/Kqrv78/3/zmN/O7v/u7mTNnTsaPH59Zs2YNuAx7xYoV6e3tHfDv6/Tp0zNlypQB/74efvjhaWtrq7eZM2dOuru788ADD+yx89nbvOY1r8kNN9yQn//85ymKIrfffnt+8pOf5IQTTkhi7Kpm26XT48aNSzJ447Ns2bIBr7GtzbbX4MV79tg9V5vW1tY0NjYmMXZDgdA+RPyf//N/8va3vz3Tp09PU1NTjjzyyHzoQx/KqaeemiTp7OxMkgG/bNsebzvW2dmZ8ePHDzje2NiYcePG1duw+w3WWHV2du7wNX6zD3avzZs355xzzsk73vGOtLa2JjF2VffXf/3XaWxszAc+8IEdHjd+1bV27do8/fTT+dSnPpUTTzwx3/nOd/Inf/InOeWUU/K9730vya//+zc3N9f/iLbNs/99NX573mWXXZaZM2fm4IMPTnNzc0488cQsWbIkr3/965MYuyrp7+/Phz70obz2ta/NK17xiiSDNz7P1aa7uzubNm3aHaezV9nR2D1bV1dXLr744rzvfe+r7zN21ddYdgG8MP/6r/+aL3/5y7n22mtz2GGH5d57782HPvShTJo0KfPmzSu7PNjr9Pb25k//9E9TFEWuuOKKssvhBVixYkX+7u/+Lj/60Y9Sq9XKLoed1N/fnyR561vfmjPPPDNJcsQRR+TOO+/MlVdemT/4gz8oszyex2WXXZa77rorN9xwQw455JDccccdWbBgQSZNmrTd7B3lWrBgQVauXJl///d/L7sUdtLzjV13d3dOOumkzJw5MxdccMGeLY4XxUz7EHHWWWfVZ9sPP/zwnHbaaTnzzDOzePHiJMmECROSZLu7eK5Zs6Z+bMKECVm7du2A4319fVm3bl29DbvfYI3VhAkTdvgav9kHu8e2wP7Tn/40t9xyS32WPTF2Vfb9738/a9euzZQpU9LY2JjGxsb89Kc/zYc//OFMnTo1ifGrsgMPPDCNjY2ZOXPmgP0zZsyo3z1+woQJ2bJlS9avXz+gzbP/fTV+e9amTZvyV3/1V/nMZz6TN7/5zXnlK1+ZhQsX5m1ve1v+9m//Nomxq4qFCxfmxhtvzO23356DDz64vn+wxue52rS2tmbUqFGDfTp7lecau22eeuqpnHjiidlvv/3yta99LU1NTfVjxq76hPYhYuPGjWloGDhcI0aMqM88TJs2LRMmTMjSpUvrx7u7u7N8+fK0t7cnSdrb27N+/fqsWLGi3ua2225Lf39/Zs2atQfOgmTwxqq9vT133HFHent7621uueWWHHroodl///330NnsfbYF9kceeSS33nprDjjggAHHjV11nXbaabnvvvty77331n8mTZqUs846K9/+9reTGL8qa25uzjHHHLPdMlQ/+clPcsghhyRJjjrqqDQ1NQ349/Xhhx9OR0fHgH9f77///gF/nNn2x7dn/0GAwdHb25ve3t7f+jnG2JWrKIosXLgwX/va13Lbbbdl2rRpA44P1vi0t7cPeI1tbba9Bjvv+cYu+fXnzBNOOCHNzc254YYbMnLkyAHHjd0QUO598Hih5s2bV7zkJS+pL/l2/fXXFwceeGBx9tln19t86lOfKsaOHVt84xvfKO67777irW996w6XETvyyCOL5cuXF//+7/9evPzlL7fk227w1FNPFffcc09xzz33FEmKz3zmM8U999xTv8P4YIzV+vXri7a2tuK0004rVq5cWVx33XXFPvvsY9mpF+m3jd2WLVuKt7zlLcXBBx9c3HvvvcXq1avrP79552JjV57n+917tmffPb4ojF+Znm/8rr/++qKpqam46qqrikceeaS+5ND3v//9+mu8//3vL6ZMmVLcdtttxQ9/+MOivb29aG9vrx/ftrTRCSecUNx7773FzTffXBx00EGWDXuRnm/s/uAP/qA47LDDittvv734z//8z+Lqq68uRo4cWVx++eX11zB25Zk/f34xZsyY4rvf/e6A97aNGzfW2wzG+GxbNuyss84qVq1aVSxZssSyYS/S843dhg0bilmzZhWHH3548eijjw5o09fXVxSFsRsKhPYhoru7u/jgBz9YTJkypRg5cmTx0pe+tPjIRz4yICj09/cXH/3oR4u2traipaWlOP7444uHH354wOv88pe/LN7xjncU++67b9Ha2lq8+93vLp566qk9fTrD3u23314k2e5n3rx5RVEM3lj9+Mc/Ll73utcVLS0txUte8pLiU5/61J46xWHrt43dY489tsNjSYrbb7+9/hrGrjzP97v3bDsK7cavPC9k/L7whS8UL3vZy4qRI0cWr3rVq4qvf/3rA15j06ZNxf/6X/+r2H///Yt99tmn+JM/+ZNi9erVA9o8/vjjxRvf+MZi1KhRxYEHHlh8+MMfri99xK55vrFbvXp18ed//ufFpEmTipEjRxaHHnpo8elPf7ro7++vv4axK89zvbddffXV9TaDNT633357ccQRRxTNzc3FS1/60gF9sPOeb+ye63czSfHYY4/VX8fYVVutKIpiMGfuAQAAgMHhO+0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AwAtWFEVmz56dOXPmbHfs8ssvz9ixY/Ozn/2shMoAYHgS2gGAF6xWq+Xqq6/O8uXL8/nPf76+/7HHHsvZZ5+dyy67LAcffHCJFQLA8FIriqIouwgAYGj50pe+lIULF+a+++7L1KlTc/zxx2fs2LG5/vrryy4NAIYVoR0A2CUnn3xyNmzYkFNOOSUXX3xxHnjggRx00EFllwUAw4rQDgDskrVr1+awww7LunXr8tWvfjUnn3xy2SUBwLDjO+0AwC4ZP358/vIv/zIzZswQ2AFgNxHaAYBd1tjYmMbGxrLLAIBhS2gHAACAihLaAQAAoKKEdgAAAKgod48HAACAijLTDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVJTQDgAAABUltAMAAEBFCe0AAABQUUI7AAAAVNT/H3EmY7V5B7GhAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bivarient Analysis"
      ],
      "metadata": {
        "id": "hEuZtsnzj6oX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Function to plot distributions\n",
        "\n",
        "\n",
        "def distribution_plot_wrt_target(data, predictor, target):\n",
        "\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "    target_uniq = data[target].unique()\n",
        "\n",
        "    axs[0, 0].set_title(\"Distribution of target for target=\" + str(target_uniq[0]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[0]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 0],\n",
        "        color=\"teal\",\n",
        "    )\n",
        "\n",
        "    axs[0, 1].set_title(\"Distribution of target for target=\" + str(target_uniq[1]))\n",
        "    sns.histplot(\n",
        "        data=data[data[target] == target_uniq[1]],\n",
        "        x=predictor,\n",
        "        kde=True,\n",
        "        ax=axs[0, 1],\n",
        "        color=\"orange\",\n",
        "    )\n",
        "\n",
        "    axs[1, 0].set_title(\"Boxplot w.r.t target\")\n",
        "    sns.boxplot(data=data, x=target, y=predictor, ax=axs[1, 0], palette=\"gist_rainbow\")\n",
        "\n",
        "    axs[1, 1].set_title(\"Boxplot (without outliers) w.r.t target\")\n",
        "    sns.boxplot(\n",
        "        data=data,\n",
        "        x=target,\n",
        "        y=predictor,\n",
        "        ax=axs[1, 1],\n",
        "        showfliers=False,\n",
        "        palette=\"gist_rainbow\",\n",
        "    )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "distribution_plot_wrt_target(data,'X',\"Y\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "HH4g0Frtj6K7",
        "outputId": "0cd75126-7bc1-41fd-8f8d-131ff54f0861"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   From the above plot, it clear that relation between X and Y is aprox. linear (Correlation in between X and Y is positive )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iHCqa-LLm57e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Check null value in data\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RT0MlFnlGWD",
        "outputId": "32bd0768-50e9-47f9-a183-e88ead9c0e13"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "X    0\n",
              "Y    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saperating data into input (X)variable and target variable (y)"
      ],
      "metadata": {
        "id": "yKhB1eoAky0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = data.X,data.Y"
      ],
      "metadata": {
        "id": "8Im8BSdsksWe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the dataset into the training and testing set.\n",
        "In the ratio:\n",
        "* Training = 90%\n",
        "* testing = 10%"
      ],
      "metadata": {
        "id": "Iz5JX8KOlPmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state = 42)"
      ],
      "metadata": {
        "id": "qk_bq5rYlPMl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping and scaling the datasets"
      ],
      "metadata": {
        "id": "klUDBVwBmRDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reshape(X):\n",
        "  X = np.array(X)\n",
        "  return X.reshape(-1,1)\n",
        "\n",
        "X_train = reshape(X_train[:])\n",
        "X_test = reshape(X_test[:])\n",
        "def scale_datasets(X_train, X_test):\n",
        "\n",
        "  \"\"\"\n",
        "  Standard Scale test and train data\n",
        "  Z - Score normalization\n",
        "  \"\"\"\n",
        "  standard_scaler = StandardScaler()\n",
        "  X_train_scaled = pd.DataFrame(\n",
        "      standard_scaler.fit_transform(X_train)\n",
        "  )\n",
        "  X_test_scaled = pd.DataFrame(\n",
        "      standard_scaler.transform(X_test)\n",
        "  )\n",
        "  return X_train_scaled, X_test_scaled\n",
        "X_train_scaled, X_test_scaled = scale_datasets(X_train, X_test)\n",
        "X_train_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb0QVLFNmQKf",
        "outputId": "76a12ff4-ebcd-4f9b-af2f-c17d5b8e5da1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11337, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building"
      ],
      "metadata": {
        "id": "bubdMAZUoSGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend.clear_session()\n",
        "#Fixing the seed for random number generators so that we can ensure we receive the same output everytime\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "6RNX43-koQzO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing the ANN\n",
        "model = Sequential()\n",
        "\n",
        "# This adds the input layer (by specifying input dimension)\n",
        "model.add(InputLayer(input_shape=X_train.shape[1]))\n",
        "#Add 1st hidden layer\n",
        "model.add(Dense(2800, activation='relu',kernel_initializer='normal'))\n",
        "# Adding the output layer\n",
        "# Notice that we do not need to specify input dim. \n",
        "# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
        "# We use the linear function because we want numerical outcomes\n",
        "model.add(Dense(1, activation = 'linear')) "
      ],
      "metadata": {
        "id": "0d4ekHPCn9He"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create optimizer(Adam) with learning rate =0.0616*1.6\n",
        "# Compile the model with loss function MeanSquaredError()(Because Regression)\n",
        "model.compile(loss=losses.MeanSquaredError(), optimizer=optimizers.Adam(learning_rate=0.0616*1.6), metrics=['mse','mae']) ### Loss function = MeanSquaredError()\n"
      ],
      "metadata": {
        "id": "CAodZKf0qthU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTlAwm9rrYTR",
        "outputId": "4a5beefe-6869-404d-cfc5-dc4305a2e184"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 2800)              5600      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 2801      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,401\n",
            "Trainable params: 8,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training"
      ],
      "metadata": {
        "id": "i-cxiZJLr1GX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint(\"model_weights.h5\",monitor='mae',\n",
        "                            save_weights_only=True, mode='min',verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='mae',factor=0.86,patience=2,min_lr=0.00001,model='auto')\n",
        "\n",
        "callbacks = [checkpoint,reduce_lr]\n",
        "\n",
        "history = model.fit(X_train_scaled,y_train,epochs=200,validation_split=0.2,batch_size=100,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYsdueOTrs4t",
        "outputId": "214fd095-8eee-408b-cdbb-4ca18191b9dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 215002.2500 - mse: 215002.2500 - mae: 235.8199\n",
            "Epoch 1: saving model to model_weights.h5\n",
            "91/91 [==============================] - 7s 6ms/step - loss: 211009.7344 - mse: 211009.7344 - mae: 231.8714 - val_loss: 733.2094 - val_mse: 733.2094 - val_mae: 23.4976 - lr: 0.0986\n",
            "Epoch 2/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 463.9650 - mse: 463.9650 - mae: 17.8488\n",
            "Epoch 2: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 459.9051 - mse: 459.9051 - mae: 17.7721 - val_loss: 371.3990 - val_mse: 371.3990 - val_mae: 16.0256 - lr: 0.0986\n",
            "Epoch 3/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 365.4275 - mse: 365.4275 - mae: 15.3651\n",
            "Epoch 3: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 364.3888 - mse: 364.3888 - mae: 15.3231 - val_loss: 341.7623 - val_mse: 341.7623 - val_mae: 15.2246 - lr: 0.0986\n",
            "Epoch 4/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 301.0658 - mse: 301.0658 - mae: 13.7728\n",
            "Epoch 4: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 300.4292 - mse: 300.4292 - mae: 13.7551 - val_loss: 271.4152 - val_mse: 271.4152 - val_mae: 11.4576 - lr: 0.0986\n",
            "Epoch 5/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 197.4009 - mse: 197.4009 - mae: 10.7967\n",
            "Epoch 5: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 195.1387 - mse: 195.1387 - mae: 10.7107 - val_loss: 133.3953 - val_mse: 133.3953 - val_mae: 8.5939 - lr: 0.0986\n",
            "Epoch 6/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 121.9600 - mse: 121.9600 - mae: 8.2600\n",
            "Epoch 6: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 120.9719 - mse: 120.9719 - mae: 8.2242 - val_loss: 92.4550 - val_mse: 92.4550 - val_mae: 7.5132 - lr: 0.0986\n",
            "Epoch 7/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 84.2980 - mse: 84.2980 - mae: 6.7551\n",
            "Epoch 7: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 84.2980 - mse: 84.2980 - mae: 6.7551 - val_loss: 67.8731 - val_mse: 67.8731 - val_mae: 6.5564 - lr: 0.0986\n",
            "Epoch 8/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 61.6588 - mse: 61.6588 - mae: 5.9337\n",
            "Epoch 8: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 61.4484 - mse: 61.4484 - mae: 5.9084 - val_loss: 47.6809 - val_mse: 47.6809 - val_mae: 5.1552 - lr: 0.0986\n",
            "Epoch 9/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 45.4371 - mse: 45.4371 - mae: 4.9471\n",
            "Epoch 9: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 45.2016 - mse: 45.2016 - mae: 4.9376 - val_loss: 36.5784 - val_mse: 36.5784 - val_mae: 4.6951 - lr: 0.0986\n",
            "Epoch 10/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 32.4339 - mse: 32.4339 - mae: 4.1561\n",
            "Epoch 10: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 31.5498 - mse: 31.5498 - mae: 4.0968 - val_loss: 22.6465 - val_mse: 22.6465 - val_mae: 3.5576 - lr: 0.0986\n",
            "Epoch 11/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 22.5688 - mse: 22.5688 - mae: 3.5271\n",
            "Epoch 11: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 22.3954 - mse: 22.3954 - mae: 3.5231 - val_loss: 16.2967 - val_mse: 16.2967 - val_mae: 2.9017 - lr: 0.0986\n",
            "Epoch 12/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 14.9221 - mse: 14.9221 - mae: 2.8425\n",
            "Epoch 12: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 14.8826 - mse: 14.8826 - mae: 2.8390 - val_loss: 14.1962 - val_mse: 14.1962 - val_mae: 2.7330 - lr: 0.0986\n",
            "Epoch 13/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 12.4509 - mse: 12.4509 - mae: 2.5418\n",
            "Epoch 13: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 12.1880 - mse: 12.1880 - mae: 2.5164 - val_loss: 9.9322 - val_mse: 9.9322 - val_mae: 2.1753 - lr: 0.0986\n",
            "Epoch 14/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 11.8885 - mse: 11.8885 - mae: 2.4962\n",
            "Epoch 14: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 11.8938 - mse: 11.8938 - mae: 2.5011 - val_loss: 8.4068 - val_mse: 8.4068 - val_mae: 2.0009 - lr: 0.0986\n",
            "Epoch 15/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 8.6770 - mse: 8.6770 - mae: 2.0745\n",
            "Epoch 15: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 8.6712 - mse: 8.6712 - mae: 2.0758 - val_loss: 10.4473 - val_mse: 10.4473 - val_mae: 2.5449 - lr: 0.0986\n",
            "Epoch 16/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 7.1251 - mse: 7.1251 - mae: 1.8038\n",
            "Epoch 16: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 7.1548 - mse: 7.1548 - mae: 1.8136 - val_loss: 7.8755 - val_mse: 7.8755 - val_mae: 2.1609 - lr: 0.0986\n",
            "Epoch 17/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 6.6536 - mse: 6.6536 - mae: 1.7649\n",
            "Epoch 17: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 6.5627 - mse: 6.5627 - mae: 1.7568 - val_loss: 5.1260 - val_mse: 5.1260 - val_mae: 1.4569 - lr: 0.0986\n",
            "Epoch 18/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 5.7028 - mse: 5.7028 - mae: 1.6407\n",
            "Epoch 18: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 5.8620 - mse: 5.8620 - mae: 1.6671 - val_loss: 10.8679 - val_mse: 10.8679 - val_mae: 2.5530 - lr: 0.0986\n",
            "Epoch 19/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 5.9926 - mse: 5.9926 - mae: 1.7045\n",
            "Epoch 19: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 5.9879 - mse: 5.9879 - mae: 1.7026 - val_loss: 4.2702 - val_mse: 4.2702 - val_mae: 1.3305 - lr: 0.0986\n",
            "Epoch 20/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 4.7855 - mse: 4.7855 - mae: 1.4882\n",
            "Epoch 20: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 4.8858 - mse: 4.8858 - mae: 1.5055 - val_loss: 4.2921 - val_mse: 4.2921 - val_mae: 1.3025 - lr: 0.0986\n",
            "Epoch 21/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 4.4496 - mse: 4.4496 - mae: 1.4147\n",
            "Epoch 21: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 4.4682 - mse: 4.4682 - mae: 1.4175 - val_loss: 4.0717 - val_mse: 4.0717 - val_mae: 1.4416 - lr: 0.0986\n",
            "Epoch 22/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 5.0101 - mse: 5.0101 - mae: 1.5885\n",
            "Epoch 22: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.9912 - mse: 4.9912 - mae: 1.5844 - val_loss: 3.5766 - val_mse: 3.5766 - val_mae: 1.1613 - lr: 0.0986\n",
            "Epoch 23/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 4.9836 - mse: 4.9836 - mae: 1.5933\n",
            "Epoch 23: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.9636 - mse: 4.9636 - mae: 1.5858 - val_loss: 4.2799 - val_mse: 4.2799 - val_mae: 1.6083 - lr: 0.0986\n",
            "Epoch 24/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 4.6315 - mse: 4.6315 - mae: 1.5405\n",
            "Epoch 24: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.5844 - mse: 4.5844 - mae: 1.5329 - val_loss: 5.0497 - val_mse: 5.0497 - val_mae: 1.6326 - lr: 0.0848\n",
            "Epoch 25/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 4.4632 - mse: 4.4632 - mae: 1.5058\n",
            "Epoch 25: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.4632 - mse: 4.4632 - mae: 1.5058 - val_loss: 3.6567 - val_mse: 3.6567 - val_mae: 1.3065 - lr: 0.0848\n",
            "Epoch 26/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 4.0908 - mse: 4.0908 - mae: 1.4107\n",
            "Epoch 26: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.0909 - mse: 4.0909 - mae: 1.4101 - val_loss: 3.3212 - val_mse: 3.3212 - val_mae: 1.2954 - lr: 0.0729\n",
            "Epoch 27/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 3.4976 - mse: 3.4976 - mae: 1.2699\n",
            "Epoch 27: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.4944 - mse: 3.4944 - mae: 1.2644 - val_loss: 2.9126 - val_mse: 2.9126 - val_mae: 1.0914 - lr: 0.0729\n",
            "Epoch 28/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 3.7805 - mse: 3.7805 - mae: 1.3814\n",
            "Epoch 28: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.8510 - mse: 3.8510 - mae: 1.3982 - val_loss: 4.3197 - val_mse: 4.3197 - val_mae: 1.5049 - lr: 0.0729\n",
            "Epoch 29/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 4.3704 - mse: 4.3704 - mae: 1.4908\n",
            "Epoch 29: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.3345 - mse: 4.3345 - mae: 1.4828 - val_loss: 3.8671 - val_mse: 3.8671 - val_mae: 1.4231 - lr: 0.0729\n",
            "Epoch 30/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 3.0583 - mse: 3.0583 - mae: 1.1880\n",
            "Epoch 30: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.0631 - mse: 3.0631 - mae: 1.1857 - val_loss: 2.5997 - val_mse: 2.5997 - val_mae: 1.0008 - lr: 0.0627\n",
            "Epoch 31/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 3.8012 - mse: 3.8012 - mae: 1.3793\n",
            "Epoch 31: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.7660 - mse: 3.7660 - mae: 1.3682 - val_loss: 2.6976 - val_mse: 2.6976 - val_mae: 1.1406 - lr: 0.0627\n",
            "Epoch 32/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 3.6346 - mse: 3.6346 - mae: 1.3615\n",
            "Epoch 32: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.7086 - mse: 3.7086 - mae: 1.3767 - val_loss: 4.9906 - val_mse: 4.9906 - val_mae: 1.7038 - lr: 0.0627\n",
            "Epoch 33/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 4.7241 - mse: 4.7241 - mae: 1.5423\n",
            "Epoch 33: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 4.7241 - mse: 4.7241 - mae: 1.5423 - val_loss: 2.9422 - val_mse: 2.9422 - val_mae: 1.2200 - lr: 0.0539\n",
            "Epoch 34/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 2.9577 - mse: 2.9577 - mae: 1.1906\n",
            "Epoch 34: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.0412 - mse: 3.0412 - mae: 1.2140 - val_loss: 6.4926 - val_mse: 6.4926 - val_mae: 1.9630 - lr: 0.0539\n",
            "Epoch 35/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 4.1462 - mse: 4.1462 - mae: 1.4652\n",
            "Epoch 35: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.8718 - mse: 3.8718 - mae: 1.3954 - val_loss: 2.2040 - val_mse: 2.2040 - val_mae: 0.8703 - lr: 0.0464\n",
            "Epoch 36/200\n",
            "75/91 [=======================>......] - ETA: 0s - loss: 2.4751 - mse: 2.4751 - mae: 1.0641\n",
            "Epoch 36: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.5740 - mse: 2.5740 - mae: 1.0835 - val_loss: 2.6452 - val_mse: 2.6452 - val_mae: 1.0472 - lr: 0.0464\n",
            "Epoch 37/200\n",
            "75/91 [=======================>......] - ETA: 0s - loss: 2.6130 - mse: 2.6130 - mae: 1.1000\n",
            "Epoch 37: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.9084 - mse: 2.9084 - mae: 1.1756 - val_loss: 3.6963 - val_mse: 3.6963 - val_mae: 1.5999 - lr: 0.0464\n",
            "Epoch 38/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 3.4769 - mse: 3.4769 - mae: 1.3079\n",
            "Epoch 38: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.3420 - mse: 3.3420 - mae: 1.2730 - val_loss: 3.2526 - val_mse: 3.2526 - val_mae: 1.3634 - lr: 0.0464\n",
            "Epoch 39/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 2.9288 - mse: 2.9288 - mae: 1.2048\n",
            "Epoch 39: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.9194 - mse: 2.9194 - mae: 1.1986 - val_loss: 2.1640 - val_mse: 2.1640 - val_mae: 0.9370 - lr: 0.0399\n",
            "Epoch 40/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 2.9207 - mse: 2.9207 - mae: 1.2186\n",
            "Epoch 40: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.9278 - mse: 2.9278 - mae: 1.2213 - val_loss: 6.1462 - val_mse: 6.1462 - val_mae: 1.9684 - lr: 0.0399\n",
            "Epoch 41/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 3.1166 - mse: 3.1166 - mae: 1.3070\n",
            "Epoch 41: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 3.0216 - mse: 3.0216 - mae: 1.2804 - val_loss: 2.1012 - val_mse: 2.1012 - val_mae: 0.9729 - lr: 0.0343\n",
            "Epoch 42/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 2.3694 - mse: 2.3694 - mae: 1.0639\n",
            "Epoch 42: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.3895 - mse: 2.3895 - mae: 1.0703 - val_loss: 4.2447 - val_mse: 4.2447 - val_mae: 1.5534 - lr: 0.0343\n",
            "Epoch 43/200\n",
            "75/91 [=======================>......] - ETA: 0s - loss: 2.5347 - mse: 2.5347 - mae: 1.1320\n",
            "Epoch 43: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.5072 - mse: 2.5072 - mae: 1.1198 - val_loss: 2.5400 - val_mse: 2.5400 - val_mae: 1.2115 - lr: 0.0343\n",
            "Epoch 44/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 2.1358 - mse: 2.1358 - mae: 0.9779\n",
            "Epoch 44: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.1196 - mse: 2.1196 - mae: 0.9789 - val_loss: 3.2813 - val_mse: 3.2813 - val_mae: 1.4193 - lr: 0.0343\n",
            "Epoch 45/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 2.2168 - mse: 2.2168 - mae: 1.0479\n",
            "Epoch 45: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.2551 - mse: 2.2551 - mae: 1.0607 - val_loss: 3.3624 - val_mse: 3.3624 - val_mae: 1.4618 - lr: 0.0343\n",
            "Epoch 46/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 2.3336 - mse: 2.3336 - mae: 1.0805\n",
            "Epoch 46: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.3223 - mse: 2.3223 - mae: 1.0802 - val_loss: 2.0390 - val_mse: 2.0390 - val_mae: 0.9959 - lr: 0.0343\n",
            "Epoch 47/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 2.2623 - mse: 2.2623 - mae: 1.0480\n",
            "Epoch 47: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.2367 - mse: 2.2367 - mae: 1.0413 - val_loss: 1.6458 - val_mse: 1.6458 - val_mae: 0.7633 - lr: 0.0295\n",
            "Epoch 48/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 2.1295 - mse: 2.1295 - mae: 1.0022\n",
            "Epoch 48: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.1368 - mse: 2.1368 - mae: 1.0069 - val_loss: 2.2442 - val_mse: 2.2442 - val_mae: 1.1190 - lr: 0.0295\n",
            "Epoch 49/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 2.2480 - mse: 2.2480 - mae: 1.0380\n",
            "Epoch 49: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 2.2224 - mse: 2.2224 - mae: 1.0340 - val_loss: 2.0079 - val_mse: 2.0079 - val_mae: 0.9156 - lr: 0.0254\n",
            "Epoch 50/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.7391 - mse: 1.7391 - mae: 0.8844\n",
            "Epoch 50: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 5ms/step - loss: 1.7665 - mse: 1.7665 - mae: 0.8926 - val_loss: 1.6034 - val_mse: 1.6034 - val_mae: 0.7850 - lr: 0.0254\n",
            "Epoch 51/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 1.9535 - mse: 1.9535 - mae: 0.9518\n",
            "Epoch 51: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 1.9489 - mse: 1.9489 - mae: 0.9508 - val_loss: 1.6931 - val_mse: 1.6931 - val_mae: 0.8253 - lr: 0.0254\n",
            "Epoch 52/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 1.9817 - mse: 1.9817 - mae: 0.9659\n",
            "Epoch 52: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 1.9732 - mse: 1.9732 - mae: 0.9634 - val_loss: 1.5925 - val_mse: 1.5925 - val_mae: 0.8425 - lr: 0.0254\n",
            "Epoch 53/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.9226 - mse: 1.9226 - mae: 0.9753\n",
            "Epoch 53: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 1.9134 - mse: 1.9134 - mae: 0.9764 - val_loss: 3.0258 - val_mse: 3.0258 - val_mae: 1.2903 - lr: 0.0218\n",
            "Epoch 54/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 2.1171 - mse: 2.1171 - mae: 1.0256\n",
            "Epoch 54: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 2.1030 - mse: 2.1030 - mae: 1.0212 - val_loss: 1.6103 - val_mse: 1.6103 - val_mae: 0.7618 - lr: 0.0218\n",
            "Epoch 55/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 1.8708 - mse: 1.8708 - mae: 0.9610\n",
            "Epoch 55: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 1.8723 - mse: 1.8723 - mae: 0.9596 - val_loss: 1.9662 - val_mse: 1.9662 - val_mae: 0.9545 - lr: 0.0188\n",
            "Epoch 56/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 2.0770 - mse: 2.0770 - mae: 1.0136\n",
            "Epoch 56: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 2.0466 - mse: 2.0466 - mae: 1.0168 - val_loss: 1.9388 - val_mse: 1.9388 - val_mae: 0.9849 - lr: 0.0188\n",
            "Epoch 57/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 1.7624 - mse: 1.7624 - mae: 0.9218\n",
            "Epoch 57: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.7609 - mse: 1.7609 - mae: 0.9204 - val_loss: 1.3897 - val_mse: 1.3897 - val_mae: 0.7204 - lr: 0.0161\n",
            "Epoch 58/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 1.8305 - mse: 1.8305 - mae: 0.9378\n",
            "Epoch 58: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.8305 - mse: 1.8305 - mae: 0.9378 - val_loss: 1.3943 - val_mse: 1.3943 - val_mae: 0.7564 - lr: 0.0161\n",
            "Epoch 59/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.6047 - mse: 1.6047 - mae: 0.8221\n",
            "Epoch 59: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.6041 - mse: 1.6041 - mae: 0.8243 - val_loss: 1.3943 - val_mse: 1.3943 - val_mae: 0.6916 - lr: 0.0139\n",
            "Epoch 60/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.4132 - mse: 1.4132 - mae: 0.7790\n",
            "Epoch 60: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4405 - mse: 1.4405 - mae: 0.7895 - val_loss: 2.0769 - val_mse: 2.0769 - val_mae: 0.9675 - lr: 0.0139\n",
            "Epoch 61/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.4601 - mse: 1.4601 - mae: 0.7886\n",
            "Epoch 61: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4537 - mse: 1.4537 - mae: 0.7856 - val_loss: 1.3220 - val_mse: 1.3220 - val_mae: 0.7139 - lr: 0.0139\n",
            "Epoch 62/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.5307 - mse: 1.5307 - mae: 0.8349\n",
            "Epoch 62: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.5309 - mse: 1.5309 - mae: 0.8323 - val_loss: 1.5785 - val_mse: 1.5785 - val_mae: 0.9038 - lr: 0.0139\n",
            "Epoch 63/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 1.5858 - mse: 1.5858 - mae: 0.8955\n",
            "Epoch 63: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.6394 - mse: 1.6394 - mae: 0.9125 - val_loss: 4.0741 - val_mse: 4.0741 - val_mae: 1.5603 - lr: 0.0139\n",
            "Epoch 64/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.5900 - mse: 1.5900 - mae: 0.8634\n",
            "Epoch 64: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.5740 - mse: 1.5740 - mae: 0.8569 - val_loss: 1.5155 - val_mse: 1.5155 - val_mae: 0.7955 - lr: 0.0119\n",
            "Epoch 65/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 1.4864 - mse: 1.4864 - mae: 0.8362\n",
            "Epoch 65: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.5337 - mse: 1.5337 - mae: 0.8490 - val_loss: 1.7612 - val_mse: 1.7612 - val_mae: 0.9652 - lr: 0.0119\n",
            "Epoch 66/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 1.4224 - mse: 1.4224 - mae: 0.7978\n",
            "Epoch 66: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4357 - mse: 1.4357 - mae: 0.7986 - val_loss: 1.2653 - val_mse: 1.2653 - val_mae: 0.6824 - lr: 0.0103\n",
            "Epoch 67/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 1.5053 - mse: 1.5053 - mae: 0.8326\n",
            "Epoch 67: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.5083 - mse: 1.5083 - mae: 0.8347 - val_loss: 1.5449 - val_mse: 1.5449 - val_mae: 0.8921 - lr: 0.0103\n",
            "Epoch 68/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.4328 - mse: 1.4328 - mae: 0.8076\n",
            "Epoch 68: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4213 - mse: 1.4213 - mae: 0.8029 - val_loss: 1.4782 - val_mse: 1.4782 - val_mae: 0.8841 - lr: 0.0088\n",
            "Epoch 69/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 1.2579 - mse: 1.2579 - mae: 0.7229\n",
            "Epoch 69: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.2612 - mse: 1.2612 - mae: 0.7266 - val_loss: 1.4973 - val_mse: 1.4973 - val_mae: 0.7758 - lr: 0.0088\n",
            "Epoch 70/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 1.2930 - mse: 1.2930 - mae: 0.7621\n",
            "Epoch 70: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.2930 - mse: 1.2930 - mae: 0.7621 - val_loss: 1.3470 - val_mse: 1.3470 - val_mae: 0.8025 - lr: 0.0088\n",
            "Epoch 71/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 1.2750 - mse: 1.2750 - mae: 0.7510\n",
            "Epoch 71: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.2916 - mse: 1.2916 - mae: 0.7597 - val_loss: 1.2708 - val_mse: 1.2708 - val_mae: 0.7812 - lr: 0.0088\n",
            "Epoch 72/200\n",
            "74/91 [=======================>......] - ETA: 0s - loss: 1.1528 - mse: 1.1528 - mae: 0.6870\n",
            "Epoch 72: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.1760 - mse: 1.1760 - mae: 0.6934 - val_loss: 1.4100 - val_mse: 1.4100 - val_mae: 0.8463 - lr: 0.0076\n",
            "Epoch 73/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.3527 - mse: 1.3527 - mae: 0.7821\n",
            "Epoch 73: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.3737 - mse: 1.3737 - mae: 0.7928 - val_loss: 1.7541 - val_mse: 1.7541 - val_mae: 0.9617 - lr: 0.0076\n",
            "Epoch 74/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 1.4410 - mse: 1.4410 - mae: 0.8301\n",
            "Epoch 74: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4376 - mse: 1.4376 - mae: 0.8223 - val_loss: 1.1178 - val_mse: 1.1178 - val_mae: 0.6169 - lr: 0.0076\n",
            "Epoch 75/200\n",
            "75/91 [=======================>......] - ETA: 0s - loss: 1.1309 - mse: 1.1309 - mae: 0.6765\n",
            "Epoch 75: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.1231 - mse: 1.1231 - mae: 0.6764 - val_loss: 1.2881 - val_mse: 1.2881 - val_mae: 0.7432 - lr: 0.0065\n",
            "Epoch 76/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 1.4204 - mse: 1.4204 - mae: 0.8290\n",
            "Epoch 76: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4252 - mse: 1.4252 - mae: 0.8294 - val_loss: 1.5212 - val_mse: 1.5212 - val_mae: 0.8939 - lr: 0.0065\n",
            "Epoch 77/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 1.3435 - mse: 1.3435 - mae: 0.8058\n",
            "Epoch 77: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.4154 - mse: 1.4154 - mae: 0.8274 - val_loss: 2.7864 - val_mse: 2.7864 - val_mae: 1.3422 - lr: 0.0065\n",
            "Epoch 78/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 1.3405 - mse: 1.3405 - mae: 0.7789\n",
            "Epoch 78: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.3358 - mse: 1.3358 - mae: 0.7770 - val_loss: 1.1963 - val_mse: 1.1963 - val_mae: 0.7693 - lr: 0.0056\n",
            "Epoch 79/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.3825 - mse: 1.3825 - mae: 0.8029\n",
            "Epoch 79: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.3757 - mse: 1.3757 - mae: 0.8041 - val_loss: 1.3587 - val_mse: 1.3587 - val_mae: 0.8021 - lr: 0.0056\n",
            "Epoch 80/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.3188 - mse: 1.3188 - mae: 0.7740\n",
            "Epoch 80: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.2938 - mse: 1.2938 - mae: 0.7628 - val_loss: 1.0696 - val_mse: 1.0696 - val_mae: 0.6186 - lr: 0.0048\n",
            "Epoch 81/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 1.0933 - mse: 1.0933 - mae: 0.6874\n",
            "Epoch 81: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.1280 - mse: 1.1280 - mae: 0.7002 - val_loss: 1.1342 - val_mse: 1.1342 - val_mae: 0.6934 - lr: 0.0048\n",
            "Epoch 82/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 1.1175 - mse: 1.1175 - mae: 0.6875\n",
            "Epoch 82: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.1096 - mse: 1.1096 - mae: 0.6837 - val_loss: 1.1491 - val_mse: 1.1491 - val_mae: 0.6685 - lr: 0.0042\n",
            "Epoch 83/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 1.1015 - mse: 1.1015 - mae: 0.6927\n",
            "Epoch 83: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 1.1040 - mse: 1.1040 - mae: 0.6940 - val_loss: 1.1226 - val_mse: 1.1226 - val_mae: 0.6212 - lr: 0.0042\n",
            "Epoch 84/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.0565 - mse: 1.0565 - mae: 0.6619\n",
            "Epoch 84: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 1.0491 - mse: 1.0491 - mae: 0.6611 - val_loss: 1.0413 - val_mse: 1.0413 - val_mae: 0.6247 - lr: 0.0036\n",
            "Epoch 85/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 1.0790 - mse: 1.0790 - mae: 0.6774\n",
            "Epoch 85: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.0844 - mse: 1.0844 - mae: 0.6819 - val_loss: 1.2402 - val_mse: 1.2402 - val_mae: 0.7255 - lr: 0.0036\n",
            "Epoch 86/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 1.1560 - mse: 1.1560 - mae: 0.7223\n",
            "Epoch 86: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.1566 - mse: 1.1566 - mae: 0.7220 - val_loss: 1.1919 - val_mse: 1.1919 - val_mae: 0.7230 - lr: 0.0036\n",
            "Epoch 87/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.0394 - mse: 1.0394 - mae: 0.6452\n",
            "Epoch 87: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.0622 - mse: 1.0622 - mae: 0.6570 - val_loss: 1.2220 - val_mse: 1.2220 - val_mae: 0.6934 - lr: 0.0031\n",
            "Epoch 88/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.0676 - mse: 1.0676 - mae: 0.6585\n",
            "Epoch 88: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 1.0684 - mse: 1.0684 - mae: 0.6608 - val_loss: 1.5572 - val_mse: 1.5572 - val_mae: 0.9902 - lr: 0.0031\n",
            "Epoch 89/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 1.0524 - mse: 1.0524 - mae: 0.6638\n",
            "Epoch 89: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0478 - mse: 1.0478 - mae: 0.6622 - val_loss: 1.1236 - val_mse: 1.1236 - val_mae: 0.7000 - lr: 0.0031\n",
            "Epoch 90/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.0772 - mse: 1.0772 - mae: 0.6645\n",
            "Epoch 90: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0638 - mse: 1.0638 - mae: 0.6630 - val_loss: 1.2475 - val_mse: 1.2475 - val_mae: 0.7651 - lr: 0.0026\n",
            "Epoch 91/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 1.0657 - mse: 1.0657 - mae: 0.6763\n",
            "Epoch 91: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0526 - mse: 1.0526 - mae: 0.6700 - val_loss: 1.0043 - val_mse: 1.0043 - val_mae: 0.5828 - lr: 0.0026\n",
            "Epoch 92/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.9900 - mse: 0.9900 - mae: 0.6150\n",
            "Epoch 92: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9928 - mse: 0.9928 - mae: 0.6188 - val_loss: 1.4730 - val_mse: 1.4730 - val_mae: 0.8456 - lr: 0.0023\n",
            "Epoch 93/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 1.0403 - mse: 1.0403 - mae: 0.6592\n",
            "Epoch 93: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0406 - mse: 1.0406 - mae: 0.6604 - val_loss: 1.0231 - val_mse: 1.0231 - val_mae: 0.6057 - lr: 0.0023\n",
            "Epoch 94/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.0545 - mse: 1.0545 - mae: 0.6793\n",
            "Epoch 94: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0524 - mse: 1.0524 - mae: 0.6766 - val_loss: 1.0948 - val_mse: 1.0948 - val_mae: 0.6851 - lr: 0.0023\n",
            "Epoch 95/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 1.0501 - mse: 1.0501 - mae: 0.6595\n",
            "Epoch 95: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 1.0454 - mse: 1.0454 - mae: 0.6601 - val_loss: 1.0079 - val_mse: 1.0079 - val_mae: 0.5931 - lr: 0.0020\n",
            "Epoch 96/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.9954 - mse: 0.9954 - mae: 0.6245\n",
            "Epoch 96: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9844 - mse: 0.9844 - mae: 0.6193 - val_loss: 1.0354 - val_mse: 1.0354 - val_mae: 0.6082 - lr: 0.0020\n",
            "Epoch 97/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.9747 - mse: 0.9747 - mae: 0.6221\n",
            "Epoch 97: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9830 - mse: 0.9830 - mae: 0.6210 - val_loss: 0.9840 - val_mse: 0.9840 - val_mae: 0.5705 - lr: 0.0017\n",
            "Epoch 98/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.9869 - mse: 0.9869 - mae: 0.6335\n",
            "Epoch 98: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9822 - mse: 0.9822 - mae: 0.6301 - val_loss: 1.0512 - val_mse: 1.0512 - val_mae: 0.6472 - lr: 0.0017\n",
            "Epoch 99/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.9654 - mse: 0.9654 - mae: 0.6052\n",
            "Epoch 99: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9586 - mse: 0.9586 - mae: 0.6080 - val_loss: 1.0219 - val_mse: 1.0219 - val_mae: 0.6115 - lr: 0.0014\n",
            "Epoch 100/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.9344 - mse: 0.9344 - mae: 0.5944\n",
            "Epoch 100: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9404 - mse: 0.9404 - mae: 0.5935 - val_loss: 0.9939 - val_mse: 0.9939 - val_mae: 0.6186 - lr: 0.0014\n",
            "Epoch 101/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.9351 - mse: 0.9351 - mae: 0.6098\n",
            "Epoch 101: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9578 - mse: 0.9578 - mae: 0.6134 - val_loss: 1.0311 - val_mse: 1.0311 - val_mae: 0.6651 - lr: 0.0014\n",
            "Epoch 102/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.9576 - mse: 0.9576 - mae: 0.6192\n",
            "Epoch 102: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9600 - mse: 0.9600 - mae: 0.6167 - val_loss: 1.0256 - val_mse: 1.0256 - val_mae: 0.6418 - lr: 0.0014\n",
            "Epoch 103/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.9451 - mse: 0.9451 - mae: 0.6254\n",
            "Epoch 103: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9630 - mse: 0.9630 - mae: 0.6243 - val_loss: 1.0689 - val_mse: 1.0689 - val_mae: 0.7022 - lr: 0.0012\n",
            "Epoch 104/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.9914 - mse: 0.9914 - mae: 0.6429\n",
            "Epoch 104: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9771 - mse: 0.9771 - mae: 0.6322 - val_loss: 1.0257 - val_mse: 1.0257 - val_mae: 0.6341 - lr: 0.0012\n",
            "Epoch 105/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.9478 - mse: 0.9478 - mae: 0.6044\n",
            "Epoch 105: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9495 - mse: 0.9495 - mae: 0.6076 - val_loss: 0.9855 - val_mse: 0.9855 - val_mae: 0.6150 - lr: 0.0011\n",
            "Epoch 106/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.9497 - mse: 0.9497 - mae: 0.6033\n",
            "Epoch 106: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9508 - mse: 0.9508 - mae: 0.6044 - val_loss: 1.0194 - val_mse: 1.0194 - val_mae: 0.6292 - lr: 0.0011\n",
            "Epoch 107/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.9403 - mse: 0.9403 - mae: 0.6019\n",
            "Epoch 107: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9357 - mse: 0.9357 - mae: 0.5991 - val_loss: 0.9766 - val_mse: 0.9766 - val_mae: 0.5845 - lr: 9.1866e-04\n",
            "Epoch 108/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 0.9356 - mse: 0.9356 - mae: 0.6020\n",
            "Epoch 108: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9279 - mse: 0.9279 - mae: 0.5995 - val_loss: 1.1569 - val_mse: 1.1569 - val_mae: 0.6833 - lr: 9.1866e-04\n",
            "Epoch 109/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.9224 - mse: 0.9224 - mae: 0.5999\n",
            "Epoch 109: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9330 - mse: 0.9330 - mae: 0.6017 - val_loss: 1.0235 - val_mse: 1.0235 - val_mae: 0.5855 - lr: 7.9004e-04\n",
            "Epoch 110/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.9151 - mse: 0.9151 - mae: 0.5887\n",
            "Epoch 110: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9191 - mse: 0.9191 - mae: 0.5879 - val_loss: 0.9710 - val_mse: 0.9710 - val_mae: 0.6083 - lr: 7.9004e-04\n",
            "Epoch 111/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.9240 - mse: 0.9240 - mae: 0.5928\n",
            "Epoch 111: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9240 - mse: 0.9240 - mae: 0.5928 - val_loss: 1.0827 - val_mse: 1.0827 - val_mae: 0.7100 - lr: 7.9004e-04\n",
            "Epoch 112/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 0.9488 - mse: 0.9488 - mae: 0.6131\n",
            "Epoch 112: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9534 - mse: 0.9534 - mae: 0.6147 - val_loss: 1.0267 - val_mse: 1.0267 - val_mae: 0.5833 - lr: 7.9004e-04\n",
            "Epoch 113/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.8844 - mse: 0.8844 - mae: 0.5628\n",
            "Epoch 113: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8967 - mse: 0.8967 - mae: 0.5678 - val_loss: 0.9618 - val_mse: 0.9618 - val_mae: 0.5991 - lr: 6.7944e-04\n",
            "Epoch 114/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.8973 - mse: 0.8973 - mae: 0.5763\n",
            "Epoch 114: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8971 - mse: 0.8971 - mae: 0.5771 - val_loss: 0.9693 - val_mse: 0.9693 - val_mae: 0.6113 - lr: 6.7944e-04\n",
            "Epoch 115/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8995 - mse: 0.8995 - mae: 0.5856\n",
            "Epoch 115: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.9140 - mse: 0.9140 - mae: 0.5902 - val_loss: 1.0249 - val_mse: 1.0249 - val_mae: 0.6580 - lr: 6.7944e-04\n",
            "Epoch 116/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.9294 - mse: 0.9294 - mae: 0.6012\n",
            "Epoch 116: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.9179 - mse: 0.9179 - mae: 0.5962 - val_loss: 0.9762 - val_mse: 0.9762 - val_mae: 0.6109 - lr: 5.8432e-04\n",
            "Epoch 117/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8955 - mse: 0.8955 - mae: 0.5781\n",
            "Epoch 117: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8955 - mse: 0.8955 - mae: 0.5781 - val_loss: 0.9387 - val_mse: 0.9387 - val_mae: 0.5514 - lr: 5.8432e-04\n",
            "Epoch 118/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.9035 - mse: 0.9035 - mae: 0.5808\n",
            "Epoch 118: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8986 - mse: 0.8986 - mae: 0.5786 - val_loss: 0.9432 - val_mse: 0.9432 - val_mae: 0.5554 - lr: 5.0251e-04\n",
            "Epoch 119/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.9228 - mse: 0.9228 - mae: 0.5940\n",
            "Epoch 119: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.9149 - mse: 0.9149 - mae: 0.5936 - val_loss: 0.9476 - val_mse: 0.9476 - val_mae: 0.5662 - lr: 5.0251e-04\n",
            "Epoch 120/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.9135 - mse: 0.9135 - mae: 0.5877\n",
            "Epoch 120: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.9124 - mse: 0.9124 - mae: 0.5874 - val_loss: 0.9604 - val_mse: 0.9604 - val_mae: 0.6147 - lr: 4.3216e-04\n",
            "Epoch 121/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 0.8857 - mse: 0.8857 - mae: 0.5717\n",
            "Epoch 121: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8898 - mse: 0.8898 - mae: 0.5726 - val_loss: 0.9818 - val_mse: 0.9818 - val_mae: 0.5869 - lr: 4.3216e-04\n",
            "Epoch 122/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.8883 - mse: 0.8883 - mae: 0.5724\n",
            "Epoch 122: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8897 - mse: 0.8897 - mae: 0.5736 - val_loss: 0.9394 - val_mse: 0.9394 - val_mae: 0.5477 - lr: 3.7166e-04\n",
            "Epoch 123/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.9130 - mse: 0.9130 - mae: 0.5863\n",
            "Epoch 123: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.9000 - mse: 0.9000 - mae: 0.5854 - val_loss: 0.9379 - val_mse: 0.9379 - val_mae: 0.5560 - lr: 3.7166e-04\n",
            "Epoch 124/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8765 - mse: 0.8765 - mae: 0.5687\n",
            "Epoch 124: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8803 - mse: 0.8803 - mae: 0.5708 - val_loss: 0.9318 - val_mse: 0.9318 - val_mae: 0.5654 - lr: 3.1963e-04\n",
            "Epoch 125/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8939 - mse: 0.8939 - mae: 0.5809\n",
            "Epoch 125: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8852 - mse: 0.8852 - mae: 0.5754 - val_loss: 0.9452 - val_mse: 0.9452 - val_mae: 0.5945 - lr: 3.1963e-04\n",
            "Epoch 126/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8943 - mse: 0.8943 - mae: 0.5748\n",
            "Epoch 126: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8787 - mse: 0.8787 - mae: 0.5681 - val_loss: 1.0096 - val_mse: 1.0096 - val_mae: 0.6278 - lr: 2.7488e-04\n",
            "Epoch 127/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8913 - mse: 0.8913 - mae: 0.5748\n",
            "Epoch 127: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8834 - mse: 0.8834 - mae: 0.5741 - val_loss: 0.9389 - val_mse: 0.9389 - val_mae: 0.5550 - lr: 2.7488e-04\n",
            "Epoch 128/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8664 - mse: 0.8664 - mae: 0.5624\n",
            "Epoch 128: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8776 - mse: 0.8776 - mae: 0.5663 - val_loss: 0.9366 - val_mse: 0.9366 - val_mae: 0.5407 - lr: 2.3640e-04\n",
            "Epoch 129/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.8717 - mse: 0.8717 - mae: 0.5602\n",
            "Epoch 129: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8740 - mse: 0.8740 - mae: 0.5606 - val_loss: 0.9629 - val_mse: 0.9629 - val_mae: 0.5929 - lr: 2.3640e-04\n",
            "Epoch 130/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 0.8595 - mse: 0.8595 - mae: 0.5570\n",
            "Epoch 130: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8684 - mse: 0.8684 - mae: 0.5594 - val_loss: 0.9290 - val_mse: 0.9290 - val_mae: 0.5517 - lr: 2.3640e-04\n",
            "Epoch 131/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8738 - mse: 0.8738 - mae: 0.5584\n",
            "Epoch 131: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8764 - mse: 0.8764 - mae: 0.5603 - val_loss: 0.9766 - val_mse: 0.9766 - val_mae: 0.5939 - lr: 2.3640e-04\n",
            "Epoch 132/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8786 - mse: 0.8786 - mae: 0.5818\n",
            "Epoch 132: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8822 - mse: 0.8822 - mae: 0.5805 - val_loss: 0.9274 - val_mse: 0.9274 - val_mae: 0.5603 - lr: 2.3640e-04\n",
            "Epoch 133/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.8689 - mse: 0.8689 - mae: 0.5588\n",
            "Epoch 133: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8655 - mse: 0.8655 - mae: 0.5581 - val_loss: 0.9349 - val_mse: 0.9349 - val_mae: 0.5550 - lr: 2.0330e-04\n",
            "Epoch 134/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8537 - mse: 0.8537 - mae: 0.5543\n",
            "Epoch 134: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8640 - mse: 0.8640 - mae: 0.5527 - val_loss: 0.9263 - val_mse: 0.9263 - val_mae: 0.5599 - lr: 2.0330e-04\n",
            "Epoch 135/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 0.8606 - mse: 0.8606 - mae: 0.5561\n",
            "Epoch 135: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8652 - mse: 0.8652 - mae: 0.5588 - val_loss: 0.9396 - val_mse: 0.9396 - val_mae: 0.5603 - lr: 2.0330e-04\n",
            "Epoch 136/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8972 - mse: 0.8972 - mae: 0.5800\n",
            "Epoch 136: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8807 - mse: 0.8807 - mae: 0.5711 - val_loss: 0.9580 - val_mse: 0.9580 - val_mae: 0.5656 - lr: 2.0330e-04\n",
            "Epoch 137/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8632 - mse: 0.8632 - mae: 0.5570\n",
            "Epoch 137: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8612 - mse: 0.8612 - mae: 0.5563 - val_loss: 0.9168 - val_mse: 0.9168 - val_mae: 0.5422 - lr: 1.7484e-04\n",
            "Epoch 138/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 0.8516 - mse: 0.8516 - mae: 0.5508\n",
            "Epoch 138: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8595 - mse: 0.8595 - mae: 0.5527 - val_loss: 0.9356 - val_mse: 0.9356 - val_mae: 0.5886 - lr: 1.7484e-04\n",
            "Epoch 139/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.8630 - mse: 0.8630 - mae: 0.5529\n",
            "Epoch 139: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8573 - mse: 0.8573 - mae: 0.5521 - val_loss: 0.9173 - val_mse: 0.9173 - val_mae: 0.5454 - lr: 1.5036e-04\n",
            "Epoch 140/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.8664 - mse: 0.8664 - mae: 0.5549\n",
            "Epoch 140: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8574 - mse: 0.8574 - mae: 0.5494 - val_loss: 0.9194 - val_mse: 0.9194 - val_mae: 0.5613 - lr: 1.5036e-04\n",
            "Epoch 141/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 0.8446 - mse: 0.8446 - mae: 0.5466\n",
            "Epoch 141: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8559 - mse: 0.8559 - mae: 0.5516 - val_loss: 0.9886 - val_mse: 0.9886 - val_mae: 0.6083 - lr: 1.5036e-04\n",
            "Epoch 142/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 0.8556 - mse: 0.8556 - mae: 0.5628\n",
            "Epoch 142: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8658 - mse: 0.8658 - mae: 0.5639 - val_loss: 0.9271 - val_mse: 0.9271 - val_mae: 0.5825 - lr: 1.5036e-04\n",
            "Epoch 143/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.8711 - mse: 0.8711 - mae: 0.5635\n",
            "Epoch 143: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8623 - mse: 0.8623 - mae: 0.5604 - val_loss: 0.9226 - val_mse: 0.9226 - val_mae: 0.5489 - lr: 1.2931e-04\n",
            "Epoch 144/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8645 - mse: 0.8645 - mae: 0.5629\n",
            "Epoch 144: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8636 - mse: 0.8636 - mae: 0.5630 - val_loss: 0.9282 - val_mse: 0.9282 - val_mae: 0.5620 - lr: 1.2931e-04\n",
            "Epoch 145/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8625 - mse: 0.8625 - mae: 0.5470\n",
            "Epoch 145: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8506 - mse: 0.8506 - mae: 0.5467 - val_loss: 0.9136 - val_mse: 0.9136 - val_mae: 0.5474 - lr: 1.1121e-04\n",
            "Epoch 146/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.8505 - mse: 0.8505 - mae: 0.5434\n",
            "Epoch 146: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8442 - mse: 0.8442 - mae: 0.5397 - val_loss: 0.9109 - val_mse: 0.9109 - val_mae: 0.5399 - lr: 1.1121e-04\n",
            "Epoch 147/200\n",
            "78/91 [========================>.....] - ETA: 0s - loss: 0.8430 - mse: 0.8430 - mae: 0.5464\n",
            "Epoch 147: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8527 - mse: 0.8527 - mae: 0.5522 - val_loss: 0.9204 - val_mse: 0.9204 - val_mae: 0.5530 - lr: 1.1121e-04\n",
            "Epoch 148/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8778 - mse: 0.8778 - mae: 0.5713\n",
            "Epoch 148: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8627 - mse: 0.8627 - mae: 0.5658 - val_loss: 0.9291 - val_mse: 0.9291 - val_mae: 0.5454 - lr: 1.1121e-04\n",
            "Epoch 149/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 0.8506 - mse: 0.8506 - mae: 0.5472\n",
            "Epoch 149: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8471 - mse: 0.8471 - mae: 0.5464 - val_loss: 0.9470 - val_mse: 0.9470 - val_mae: 0.5647 - lr: 9.5638e-05\n",
            "Epoch 150/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8566 - mse: 0.8566 - mae: 0.5496\n",
            "Epoch 150: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8530 - mse: 0.8530 - mae: 0.5483 - val_loss: 0.9234 - val_mse: 0.9234 - val_mae: 0.5630 - lr: 9.5638e-05\n",
            "Epoch 151/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 0.8401 - mse: 0.8401 - mae: 0.5416\n",
            "Epoch 151: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8444 - mse: 0.8444 - mae: 0.5428 - val_loss: 0.9337 - val_mse: 0.9337 - val_mae: 0.5603 - lr: 8.2249e-05\n",
            "Epoch 152/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8494 - mse: 0.8494 - mae: 0.5467\n",
            "Epoch 152: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8457 - mse: 0.8456 - mae: 0.5473 - val_loss: 0.9176 - val_mse: 0.9176 - val_mae: 0.5530 - lr: 8.2249e-05\n",
            "Epoch 153/200\n",
            "88/91 [============================>.] - ETA: 0s - loss: 0.8409 - mse: 0.8409 - mae: 0.5433\n",
            "Epoch 153: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8444 - mse: 0.8444 - mae: 0.5453 - val_loss: 0.9269 - val_mse: 0.9269 - val_mae: 0.5735 - lr: 7.0734e-05\n",
            "Epoch 154/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8404 - mse: 0.8404 - mae: 0.5402\n",
            "Epoch 154: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8439 - mse: 0.8439 - mae: 0.5406 - val_loss: 0.9083 - val_mse: 0.9083 - val_mae: 0.5443 - lr: 7.0734e-05\n",
            "Epoch 155/200\n",
            "84/91 [==========================>...] - ETA: 0s - loss: 0.8448 - mse: 0.8448 - mae: 0.5353\n",
            "Epoch 155: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8434 - mse: 0.8434 - mae: 0.5375 - val_loss: 0.9080 - val_mse: 0.9080 - val_mae: 0.5374 - lr: 6.0831e-05\n",
            "Epoch 156/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 0.8453 - mse: 0.8453 - mae: 0.5421\n",
            "Epoch 156: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8417 - mse: 0.8417 - mae: 0.5422 - val_loss: 0.9438 - val_mse: 0.9438 - val_mae: 0.5743 - lr: 6.0831e-05\n",
            "Epoch 157/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8433 - mse: 0.8433 - mae: 0.5415\n",
            "Epoch 157: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8399 - mse: 0.8399 - mae: 0.5400 - val_loss: 0.9060 - val_mse: 0.9060 - val_mae: 0.5440 - lr: 6.0831e-05\n",
            "Epoch 158/200\n",
            "78/91 [========================>.....] - ETA: 0s - loss: 0.8359 - mse: 0.8359 - mae: 0.5308\n",
            "Epoch 158: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8372 - mse: 0.8372 - mae: 0.5309 - val_loss: 0.9074 - val_mse: 0.9074 - val_mae: 0.5402 - lr: 5.2315e-05\n",
            "Epoch 159/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8377 - mse: 0.8377 - mae: 0.5474\n",
            "Epoch 159: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8456 - mse: 0.8456 - mae: 0.5462 - val_loss: 0.9118 - val_mse: 0.9118 - val_mae: 0.5662 - lr: 5.2315e-05\n",
            "Epoch 160/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8421 - mse: 0.8421 - mae: 0.5435\n",
            "Epoch 160: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8421 - mse: 0.8421 - mae: 0.5435 - val_loss: 0.9303 - val_mse: 0.9303 - val_mae: 0.5760 - lr: 5.2315e-05\n",
            "Epoch 161/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 0.8392 - mse: 0.8392 - mae: 0.5344\n",
            "Epoch 161: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8370 - mse: 0.8370 - mae: 0.5339 - val_loss: 0.9045 - val_mse: 0.9045 - val_mae: 0.5383 - lr: 4.4991e-05\n",
            "Epoch 162/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8352 - mse: 0.8352 - mae: 0.5321\n",
            "Epoch 162: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8360 - mse: 0.8360 - mae: 0.5323 - val_loss: 0.9041 - val_mse: 0.9041 - val_mae: 0.5414 - lr: 4.4991e-05\n",
            "Epoch 163/200\n",
            "79/91 [=========================>....] - ETA: 0s - loss: 0.8289 - mse: 0.8289 - mae: 0.5320\n",
            "Epoch 163: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8386 - mse: 0.8386 - mae: 0.5350 - val_loss: 0.9035 - val_mse: 0.9035 - val_mae: 0.5344 - lr: 3.8692e-05\n",
            "Epoch 164/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8339 - mse: 0.8339 - mae: 0.5316\n",
            "Epoch 164: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8330 - mse: 0.8330 - mae: 0.5317 - val_loss: 0.9092 - val_mse: 0.9092 - val_mae: 0.5367 - lr: 3.8692e-05\n",
            "Epoch 165/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.8364 - mse: 0.8364 - mae: 0.5347\n",
            "Epoch 165: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8331 - mse: 0.8331 - mae: 0.5334 - val_loss: 0.9071 - val_mse: 0.9071 - val_mae: 0.5381 - lr: 3.3275e-05\n",
            "Epoch 166/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8365 - mse: 0.8365 - mae: 0.5322\n",
            "Epoch 166: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8321 - mse: 0.8321 - mae: 0.5342 - val_loss: 0.9208 - val_mse: 0.9208 - val_mae: 0.5482 - lr: 3.3275e-05\n",
            "Epoch 167/200\n",
            "76/91 [========================>.....] - ETA: 0s - loss: 0.8184 - mse: 0.8184 - mae: 0.5246\n",
            "Epoch 167: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8316 - mse: 0.8316 - mae: 0.5283 - val_loss: 0.9023 - val_mse: 0.9023 - val_mae: 0.5335 - lr: 2.8617e-05\n",
            "Epoch 168/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8167 - mse: 0.8167 - mae: 0.5262\n",
            "Epoch 168: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8309 - mse: 0.8309 - mae: 0.5312 - val_loss: 0.9054 - val_mse: 0.9054 - val_mae: 0.5400 - lr: 2.8617e-05\n",
            "Epoch 169/200\n",
            "85/91 [===========================>..] - ETA: 0s - loss: 0.8310 - mse: 0.8310 - mae: 0.5304\n",
            "Epoch 169: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8315 - mse: 0.8315 - mae: 0.5289 - val_loss: 0.9119 - val_mse: 0.9119 - val_mae: 0.5406 - lr: 2.8617e-05\n",
            "Epoch 170/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8278 - mse: 0.8278 - mae: 0.5278\n",
            "Epoch 170: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8298 - mse: 0.8298 - mae: 0.5266 - val_loss: 0.9068 - val_mse: 0.9068 - val_mae: 0.5421 - lr: 2.4610e-05\n",
            "Epoch 171/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8168 - mse: 0.8168 - mae: 0.5233\n",
            "Epoch 171: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8290 - mse: 0.8290 - mae: 0.5249 - val_loss: 0.9021 - val_mse: 0.9021 - val_mae: 0.5428 - lr: 2.4610e-05\n",
            "Epoch 172/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.8502 - mse: 0.8502 - mae: 0.5363\n",
            "Epoch 172: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8335 - mse: 0.8335 - mae: 0.5326 - val_loss: 0.9013 - val_mse: 0.9013 - val_mae: 0.5398 - lr: 2.4610e-05\n",
            "Epoch 173/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8241 - mse: 0.8241 - mae: 0.5248\n",
            "Epoch 173: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 8ms/step - loss: 0.8290 - mse: 0.8290 - mae: 0.5260 - val_loss: 0.9020 - val_mse: 0.9020 - val_mae: 0.5394 - lr: 2.4610e-05\n",
            "Epoch 174/200\n",
            "78/91 [========================>.....] - ETA: 0s - loss: 0.8340 - mse: 0.8340 - mae: 0.5252\n",
            "Epoch 174: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8283 - mse: 0.8283 - mae: 0.5236 - val_loss: 0.9084 - val_mse: 0.9084 - val_mae: 0.5396 - lr: 2.1165e-05\n",
            "Epoch 175/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8413 - mse: 0.8413 - mae: 0.5375\n",
            "Epoch 175: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8321 - mse: 0.8321 - mae: 0.5352 - val_loss: 0.9022 - val_mse: 0.9022 - val_mae: 0.5339 - lr: 2.1165e-05\n",
            "Epoch 176/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8302 - mse: 0.8302 - mae: 0.5296\n",
            "Epoch 176: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8307 - mse: 0.8307 - mae: 0.5292 - val_loss: 0.9054 - val_mse: 0.9054 - val_mae: 0.5355 - lr: 2.1165e-05\n",
            "Epoch 177/200\n",
            "86/91 [===========================>..] - ETA: 0s - loss: 0.8287 - mse: 0.8287 - mae: 0.5212\n",
            "Epoch 177: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8273 - mse: 0.8273 - mae: 0.5216 - val_loss: 0.9011 - val_mse: 0.9011 - val_mae: 0.5313 - lr: 1.8202e-05\n",
            "Epoch 178/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8259 - mse: 0.8259 - mae: 0.5264\n",
            "Epoch 178: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8283 - mse: 0.8283 - mae: 0.5260 - val_loss: 0.9002 - val_mse: 0.9002 - val_mae: 0.5384 - lr: 1.8202e-05\n",
            "Epoch 179/200\n",
            "79/91 [=========================>....] - ETA: 0s - loss: 0.8172 - mse: 0.8172 - mae: 0.5208\n",
            "Epoch 179: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8274 - mse: 0.8274 - mae: 0.5241 - val_loss: 0.9004 - val_mse: 0.9004 - val_mae: 0.5351 - lr: 1.8202e-05\n",
            "Epoch 180/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8263 - mse: 0.8263 - mae: 0.5247\n",
            "Epoch 180: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8263 - mse: 0.8263 - mae: 0.5247 - val_loss: 0.9040 - val_mse: 0.9040 - val_mae: 0.5371 - lr: 1.5653e-05\n",
            "Epoch 181/200\n",
            "91/91 [==============================] - ETA: 0s - loss: 0.8271 - mse: 0.8271 - mae: 0.5255\n",
            "Epoch 181: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.8271 - mse: 0.8271 - mae: 0.5255 - val_loss: 0.9020 - val_mse: 0.9020 - val_mae: 0.5314 - lr: 1.5653e-05\n",
            "Epoch 182/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8287 - mse: 0.8287 - mae: 0.5212\n",
            "Epoch 182: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 7ms/step - loss: 0.8256 - mse: 0.8256 - mae: 0.5227 - val_loss: 0.9010 - val_mse: 0.9010 - val_mae: 0.5309 - lr: 1.3462e-05\n",
            "Epoch 183/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8317 - mse: 0.8317 - mae: 0.5257\n",
            "Epoch 183: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8255 - mse: 0.8255 - mae: 0.5224 - val_loss: 0.9049 - val_mse: 0.9049 - val_mae: 0.5367 - lr: 1.3462e-05\n",
            "Epoch 184/200\n",
            "89/91 [============================>.] - ETA: 0s - loss: 0.8239 - mse: 0.8239 - mae: 0.5220\n",
            "Epoch 184: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8251 - mse: 0.8251 - mae: 0.5224 - val_loss: 0.9047 - val_mse: 0.9047 - val_mae: 0.5348 - lr: 1.1577e-05\n",
            "Epoch 185/200\n",
            "81/91 [=========================>....] - ETA: 0s - loss: 0.8319 - mse: 0.8319 - mae: 0.5253\n",
            "Epoch 185: saving model to model_weights.h5\n",
            "91/91 [==============================] - 1s 6ms/step - loss: 0.8261 - mse: 0.8261 - mae: 0.5242 - val_loss: 0.9056 - val_mse: 0.9056 - val_mae: 0.5422 - lr: 1.1577e-05\n",
            "Epoch 186/200\n",
            "90/91 [============================>.] - ETA: 0s - loss: 0.8248 - mse: 0.8248 - mae: 0.5226\n",
            "Epoch 186: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8256 - mse: 0.8256 - mae: 0.5226 - val_loss: 0.9047 - val_mse: 0.9047 - val_mae: 0.5353 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8228 - mse: 0.8228 - mae: 0.5222\n",
            "Epoch 187: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8257 - mse: 0.8257 - mae: 0.5229 - val_loss: 0.9002 - val_mse: 0.9002 - val_mae: 0.5320 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8308 - mse: 0.8308 - mae: 0.5224\n",
            "Epoch 188: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8241 - mse: 0.8241 - mae: 0.5217 - val_loss: 0.9101 - val_mse: 0.9101 - val_mae: 0.5406 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "83/91 [==========================>...] - ETA: 0s - loss: 0.8326 - mse: 0.8326 - mae: 0.5250\n",
            "Epoch 189: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8252 - mse: 0.8252 - mae: 0.5237 - val_loss: 0.8991 - val_mse: 0.8991 - val_mae: 0.5350 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "78/91 [========================>.....] - ETA: 0s - loss: 0.8266 - mse: 0.8266 - mae: 0.5235\n",
            "Epoch 190: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8242 - mse: 0.8242 - mae: 0.5219 - val_loss: 0.9050 - val_mse: 0.9050 - val_mae: 0.5357 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "79/91 [=========================>....] - ETA: 0s - loss: 0.8252 - mse: 0.8252 - mae: 0.5218\n",
            "Epoch 191: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8253 - mse: 0.8253 - mae: 0.5226 - val_loss: 0.8992 - val_mse: 0.8992 - val_mae: 0.5346 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8187 - mse: 0.8187 - mae: 0.5180\n",
            "Epoch 192: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8247 - mse: 0.8247 - mae: 0.5213 - val_loss: 0.8993 - val_mse: 0.8993 - val_mae: 0.5376 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "80/91 [=========================>....] - ETA: 0s - loss: 0.8309 - mse: 0.8309 - mae: 0.5243\n",
            "Epoch 193: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8243 - mse: 0.8243 - mae: 0.5231 - val_loss: 0.9024 - val_mse: 0.9024 - val_mae: 0.5345 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8159 - mse: 0.8159 - mae: 0.5208\n",
            "Epoch 194: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8245 - mse: 0.8245 - mae: 0.5220 - val_loss: 0.9006 - val_mse: 0.9006 - val_mae: 0.5304 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "82/91 [==========================>...] - ETA: 0s - loss: 0.8174 - mse: 0.8174 - mae: 0.5243\n",
            "Epoch 195: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8234 - mse: 0.8234 - mae: 0.5211 - val_loss: 0.9041 - val_mse: 0.9041 - val_mae: 0.5329 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "78/91 [========================>.....] - ETA: 0s - loss: 0.8284 - mse: 0.8284 - mae: 0.5220\n",
            "Epoch 196: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8243 - mse: 0.8243 - mae: 0.5215 - val_loss: 0.9018 - val_mse: 0.9018 - val_mae: 0.5309 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.8311 - mse: 0.8311 - mae: 0.5251\n",
            "Epoch 197: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8246 - mse: 0.8246 - mae: 0.5232 - val_loss: 0.9014 - val_mse: 0.9014 - val_mae: 0.5337 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.8363 - mse: 0.8363 - mae: 0.5244\n",
            "Epoch 198: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8239 - mse: 0.8239 - mae: 0.5228 - val_loss: 0.8991 - val_mse: 0.8991 - val_mae: 0.5450 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "77/91 [========================>.....] - ETA: 0s - loss: 0.8337 - mse: 0.8337 - mae: 0.5240\n",
            "Epoch 199: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 4ms/step - loss: 0.8244 - mse: 0.8244 - mae: 0.5220 - val_loss: 0.9073 - val_mse: 0.9073 - val_mae: 0.5426 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "87/91 [===========================>..] - ETA: 0s - loss: 0.8290 - mse: 0.8290 - mae: 0.5228\n",
            "Epoch 200: saving model to model_weights.h5\n",
            "91/91 [==============================] - 0s 5ms/step - loss: 0.8242 - mse: 0.8242 - mae: 0.5221 - val_loss: 0.8977 - val_mse: 0.8977 - val_mae: 0.5351 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Capturing learning history per epoch\n",
        "hist  = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "\n",
        "# Plotting accuracy at different epochs\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.legend((\"train\" , \"valid\") , loc =0)\n",
        "\n",
        "#Printing results\n",
        "results = model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "0Euq3UbPtmRI",
        "outputId": "677b5e87-a588-4e81-fc51-0adc8aa889e9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 2ms/step - loss: 976808170225664.0000 - mse: 976808170225664.0000 - mae: 28052912.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1QUlEQVR4nO3de3RV5Z3/8c85gZxwSwICCZGrgCAIKCAxbXVsSQmUoSC2ImRVoBSVCR01VfnRqYC0UxywXtoBnE5rcaZqhS6vgLgi1yoRNBJF0FQYMCgcUGgSwiW38/z+0LPhEC4JJPkSzvu11lmLs/eTfZ6dLZyPz/7u5/E555wAAACikN+6AwAAAFYIQgAAIGoRhAAAQNQiCAEAgKhFEAIAAFGLIAQAAKIWQQgAAEQtghAAAIhaTaw7cDELhULau3evWrVqJZ/PZ90dAABQA845HT58WCkpKfL7zz7mQxA6i71796pTp07W3QAAAOdhz5496tix41nbEITOolWrVpK++kXGx8cb9wYAANRESUmJOnXq5H2Pnw1B6CzCt8Pi4+MJQgAANDI1KWuhWBoAAEQtghAAAIhaBCEAABC1qBECAKCBOedUWVmpqqoq6640Wk2bNlVMTMwFH4cgBABAAyovL9e+fft09OhR6640aj6fTx07dlTLli0v6DgEIQAAGkgoFNKuXbsUExOjlJQUxcbGMmHveXDO6YsvvtBnn32mnj17XtDIEEEIAIAGUl5erlAopE6dOql58+bW3WnU2rVrp927d6uiouKCghDF0gAANLBzLfuAc6urkTSuBAAAiFoEIQAAELUIQgAAoEF17dpVjz/+uHU3JFEsDQAAauCmm27SNddcUycB5p133lGLFi0uvFN1gCBk4IvDZVq4doeaxcZoxvDe1t0BAOCCOedUVVWlJk3OHS3atWvXAD2qGW6NGSg5XqElG3fr2U2F1l0BABhyzuloeaXJyzlX435OmjRJ69ev1xNPPCGfzyefz6clS5bI5/Pptdde06BBgxQIBPTmm29q586dGj16tJKSktSyZUtdd911euONNyKOd+qtMZ/Ppz/84Q+6+eab1bx5c/Xs2VOvvPJKXf2az4oRIQP+rx/5C9XiP0IAwKXnWEWV+sx63eSzt8/NUPPYmsWAJ554Qn//+9919dVXa+7cuZKkbdu2SZL+3//7f3rkkUd0xRVXqHXr1tqzZ4++973v6d///d8VCAT0P//zPxo1apQKCgrUuXPnM37GQw89pPnz52vBggX63e9+p8zMTH366adq06bNhZ/sWTAiZMD/9dQH5CAAQGOQkJCg2NhYNW/eXMnJyUpOTvYmMZw7d66++93vqnv37mrTpo0GDBigO++8U1dffbV69uypX/7yl+revfs5R3gmTZqk8ePHq0ePHvr1r3+t0tJSbd68ud7PjREhAz4xIgQAkJo1jdH2uRlmn10XBg8eHPG+tLRUc+bM0YoVK7Rv3z5VVlbq2LFjKiw8ezlI//79vT+3aNFC8fHxOnDgQJ308WwIQgZ8jAgBAPRVbUxNb09drE59+uu+++5TTk6OHnnkEfXo0UPNmjXTD37wA5WXl5/1OE2bNo147/P5FAqF6ry/p2rcv/1Gyu9nRAgA0LjExsaqqqrqnO3eeustTZo0STfffLOkr0aIdu/eXc+9O3/UCBmgRggA0Nh07dpVmzZt0u7du/Xll1+ecbSmZ8+eeuGFF5Sfn6/3339fEyZMaJCRnfNFEDJAjRAAoLG57777FBMToz59+qhdu3ZnrPl59NFH1bp1a33jG9/QqFGjlJGRoYEDBzZwb2uOW2MGvBEh224AAFBjV155pXJzcyO2TZo0qVq7rl27as2aNRHbsrKyIt6feqvsdHMaFRUVnVc/a4sRIQM+5hECAOCiQBAycHKNUG1m9gQAAHWLIGQgPCIkUTANAIAlgpAB/4kcRJ0QAACGCEIGTh4Rok4IAAA7tQpC8+bN03XXXadWrVqpffv2GjNmjAoKCiLaHD9+XFlZWbrsssvUsmVL3XLLLdq/f39Em8LCQo0cOVLNmzdX+/btdf/996uysjKizbp16zRw4EAFAgH16NFDS5YsqdafhQsXqmvXroqLi1Nqamq1NUlq0hcLJ+UgghAAAIZqFYTWr1+vrKwsvf3228rJyVFFRYWGDRumI0eOeG3uvfdevfrqq1q2bJnWr1+vvXv3auzYsd7+qqoqjRw5UuXl5dq4caOefvppLVmyRLNmzfLa7Nq1SyNHjtS3v/1t5efn65577tFPfvITvf76iRV6n3/+eWVnZ2v27Nl67733NGDAAGVkZESsS3KuvljxUyMEAMDFwV2AAwcOOElu/fr1zjnnioqKXNOmTd2yZcu8Nh999JGT5HJzc51zzq1cudL5/X4XDAa9NosXL3bx8fGurKzMOefcAw884Pr27RvxWePGjXMZGRne+yFDhrisrCzvfVVVlUtJSXHz5s2rcV/Opbi42ElyxcXFNWpfU0fKKlyXGctdlxnL3dGyyjo9NgDg4nXs2DG3fft2d+zYMeuuNHpn+13W5vv7gmqEiouLJUlt2rSRJOXl5amiokLp6elem969e6tz587eJEy5ubnq16+fkpKSvDYZGRkqKSnRtm3bvDYnHyPcJnyM8vJy5eXlRbTx+/1KT0/32tSkL6cqKytTSUlJxKs++KkRAgBEma5du+rxxx/33vt8Pr300ktnbL979275fD7l5+fXa7/OOwiFQiHdc889+uY3v6mrr75akhQMBhUbG6vExMSItklJSQoGg16bk0NQeH9439nalJSU6NixY/ryyy9VVVV12jYnH+NcfTnVvHnzlJCQ4L06depUw9/G+SMIAQCi0b59+zRixAjrbpx/EMrKytKHH36ov/zlL3XZH1MzZ85UcXGx99qzZ0+9fE5EjVC9fAIAABe35ORkBQIB626cXxCaPn26li9frrVr16pjx47e9uTkZJWXl1dbH2T//v1KTk722pz65Fb4/bnaxMfHq1mzZmrbtq1iYmJO2+bkY5yrL6cKBAKKj4+PeNWHiHmELt4FeQEAkCT9/ve/V0pKSrVV5EePHq0f//jH2rlzp0aPHq2kpCS1bNlS1113nd54442zHvPUW2ObN2/Wtddeq7i4OA0ePFhbtmypj1OpplZByDmn6dOn68UXX9SaNWvUrVu3iP2DBg1S06ZNtXr1am9bQUGBCgsLlZaWJklKS0vT1q1bI57uysnJUXx8vPr06eO1OfkY4TbhY8TGxmrQoEERbUKhkFavXu21qUlfrFAjBACQ9NWjw+VHbF61+P754Q9/qIMHD2rt2rXetkOHDmnVqlXKzMxUaWmpvve972n16tXasmWLhg8frlGjRp1xhfpTlZaW6p//+Z/Vp08f5eXlac6cObrvvvtq/es8H7VafT4rK0vPPvusXn75ZbVq1cqrtUlISFCzZs2UkJCgKVOmKDs7W23atFF8fLx++tOfKi0tTddff70kadiwYerTp49+9KMfaf78+QoGg/rFL36hrKwsb4jsrrvu0n/+53/qgQce0I9//GOtWbNGS5cu1YoVK7y+ZGdna+LEiRo8eLCGDBmixx9/XEeOHNHkyZO9Pp2rL1aYRwgAIEmqOCr9OsXms3++V4ptUaOmrVu31ogRI/Tss89q6NChkqS//vWvatu2rb797W/L7/drwIABXvtf/vKXevHFF/XKK69o+vTp5zz+s88+q1AopD/+8Y+Ki4tT37599dlnn2natGnnd261UKsgtHjxYknSTTfdFLH9T3/6kyZNmiRJeuyxx+T3+3XLLbeorKxMGRkZWrRokdc2JiZGy5cv17Rp05SWlqYWLVpo4sSJmjt3rtemW7duWrFihe6991498cQT6tixo/7whz8oIyPDazNu3Dh98cUXmjVrloLBoK655hqtWrUqooD6XH2x4qNGCADQyGRmZmrq1KlatGiRAoGAnnnmGd12223y+/0qLS3VnDlztGLFCu3bt0+VlZU6duxYjUeEPvroI/Xv319xcXHetoa6e1OrIORqMHoRFxenhQsXauHChWds06VLF61cufKsx7npppvOeX9w+vTpZ02aNemLFb9PCjlGhAAgqjVt/tXIjNVn18KoUaPknNOKFSt03XXX6W9/+5see+wxSdJ9992nnJwcPfLII+rRo4eaNWumH/zgByovL6+PntepWgUh1B2fzyc5x8zSABDNfL4a356yFhcXp7Fjx+qZZ57Rjh071KtXLw0cOFCS9NZbb2nSpEm6+eabJX1V87N79+4aH/uqq67S//7v/+r48ePeqNDbb79d5+dwOiy6aiT85BgjQgCAxiIzM1MrVqzQU089pczMTG97z5499cILLyg/P1/vv/++JkyYUO0Js7OZMGGCfD6fpk6dqu3bt2vlypV65JFH6uMUqiEIGQnXCZGDAACNxXe+8x21adNGBQUFmjBhgrf90UcfVevWrfWNb3xDo0aNUkZGhjdaVBMtW7bUq6++qq1bt+raa6/Vv/3bv+k//uM/6uMUquHWmBFGhAAAjY3f79fevdVrmrp27ao1a9ZEbMvKyop4f+qtslPrjq+//vpqy2nUpDb5QjEiZMQnRoQAALBGEDISHhEiCAEAYIcgZCQ8uzS3xgAAsEMQMuKjRggAAHMEISM+b0TIuCMAAEQxgpCREyvQk4QAINo0xNNQl7q6+h0ShIz4GRECgKjTtGlTSdLRo0eNe9L4hZfviImJuaDjMI+QEWqEACD6xMTEKDExUQcOHJAkNW/ePGIhbtRMKBTSF198oebNm6tJkwuLMgQhI16NUM1nIAcAXAKSk5MlyQtDOD9+v1+dO3e+4CBJEDLizSNEjRAARBWfz6cOHTqoffv2qqiosO5OoxUbGyu//8IrfAhCRvysNQYAUS0mJuaC61tw4SiWNhIeyKNGCAAAOwQhI8wjBACAPYKQkfBtTeaSAADADkHICPMIAQBgjyBkJFwjxIgQAAB2CEJGvKfGjPsBAEA0IwgZ8WaW5t4YAABmCEJGqBECAMAeQchIeESIGiEAAOwQhIxQIwQAgD2CkJETEyoShQAAsEIQMnJiiQ3TbgAAENUIQkbCM0szIgQAgB2CkBG/Vy1t2w8AAKIZQcgINUIAANgjCBmhRggAAHsEISP+8MzSjAgBAGCGIGTEm0eIHAQAgBmCkJETQYgkBACAFYKQFe/WmG03AACIZgQhI37v6XmSEAAAVghCRlh9HgAAewQhI6w+DwCAPYKQET8TKgIAYI4gZMTH4/MAAJgjCBnx89QYAADmCEJGTiyxQRICAMAKQcgIEyoCAGCPIGSEGiEAAOwRhIxQIwQAgD2CkBEfq88DAGCOIGSEGiEAAOwRhIx4Qci4HwAARDOCkBHv1hhFQgAAmCEIGfGx6CoAAOYIQkbCT42RgwAAsEMQMkKxNAAA9ghCRlhiAwAAewQhI9QIAQBgjyBkxKsRIggBAGCGIGTE740IkYQAALBCEDLi80aECEIAAFghCBmhRggAAHsEISPUCAEAYI8gZIQaIQAA7BGEjFAjBACAPYKQEVafBwDAHkHIiLf6PCNCAACYIQgZ8YmnxgAAsEYQMuJnRAgAAHMEISN+7/l5234AABDNCEJGqBECAMAeQcgINUIAANirdRDasGGDRo0apZSUFPl8Pr300ksR+ydNmiSfzxfxGj58eESbQ4cOKTMzU/Hx8UpMTNSUKVNUWloa0eaDDz7QDTfcoLi4OHXq1Enz58+v1pdly5apd+/eiouLU79+/bRy5cqI/c45zZo1Sx06dFCzZs2Unp6uTz75pLanXC+oEQIAwF6tg9CRI0c0YMAALVy48Ixthg8frn379nmv5557LmJ/Zmamtm3bppycHC1fvlwbNmzQHXfc4e0vKSnRsGHD1KVLF+Xl5WnBggWaM2eOfv/733ttNm7cqPHjx2vKlCnasmWLxowZozFjxujDDz/02syfP1+//e1v9eSTT2rTpk1q0aKFMjIydPz48dqedp3z5hEiBwEAYMddAEnuxRdfjNg2ceJEN3r06DP+zPbt250k984773jbXnvtNefz+dznn3/unHNu0aJFrnXr1q6srMxrM2PGDNerVy/v/a233upGjhwZcezU1FR35513OuecC4VCLjk52S1YsMDbX1RU5AKBgHvuuedqdH7FxcVOkisuLq5R+9r4zesfuy4zlrtZL22t82MDABDNavP9XS81QuvWrVP79u3Vq1cvTZs2TQcPHvT25ebmKjExUYMHD/a2paeny+/3a9OmTV6bG2+8UbGxsV6bjIwMFRQU6B//+IfXJj09PeJzMzIylJubK0natWuXgsFgRJuEhASlpqZ6bUyx+jwAAOaa1PUBhw8frrFjx6pbt27auXOnfv7zn2vEiBHKzc1VTEyMgsGg2rdvH9mJJk3Upk0bBYNBSVIwGFS3bt0i2iQlJXn7WrdurWAw6G07uc3Jxzj5507X5lRlZWUqKyvz3peUlNT29GuMGiEAAOzVeRC67bbbvD/369dP/fv3V/fu3bVu3ToNHTq0rj+uTs2bN08PPfRQg3wWa40BAGCv3h+fv+KKK9S2bVvt2LFDkpScnKwDBw5EtKmsrNShQ4eUnJzstdm/f39Em/D7c7U5ef/JP3e6NqeaOXOmiouLvdeePXtqfb415Wf1eQAAzNV7EPrss8908OBBdejQQZKUlpamoqIi5eXleW3WrFmjUCik1NRUr82GDRtUUVHhtcnJyVGvXr3UunVrr83q1asjPisnJ0dpaWmSpG7duik5OTmiTUlJiTZt2uS1OVUgEFB8fHzEq774wjVCoXr7CAAAcA61DkKlpaXKz89Xfn6+pK+KkvPz81VYWKjS0lLdf//9evvtt7V7926tXr1ao0ePVo8ePZSRkSFJuuqqqzR8+HBNnTpVmzdv1ltvvaXp06frtttuU0pKiiRpwoQJio2N1ZQpU7Rt2zY9//zzeuKJJ5Sdne314+6779aqVav0m9/8Rh9//LHmzJmjd999V9OnT5f0VdC455579Ktf/UqvvPKKtm7dqttvv10pKSkaM2bMBf7aLpzPW2GDESEAAMzU9pG0tWvXOn1V2hLxmjhxojt69KgbNmyYa9eunWvatKnr0qWLmzp1qgsGgxHHOHjwoBs/frxr2bKli4+Pd5MnT3aHDx+OaPP++++7b33rWy4QCLjLL7/cPfzww9X6snTpUnfllVe62NhY17dvX7dixYqI/aFQyD344IMuKSnJBQIBN3ToUFdQUFDjc63Px+cXr9vhusxY7n62NL/Ojw0AQDSrzfe3zzmKVM6kpKRECQkJKi4urvPbZP+1fqfmvfaxxg68XI/eek2dHhsAgGhWm+9v1hozwszSAADYIwgZ8fHUGAAA5ghCRvzMLA0AgDmCkBEfM0sDAGCOIGSEGiEAAOwRhIz4mUcIAABzBCEjzCwNAIA9gpARaoQAALBHEDLCU2MAANgjCBkJ1wiJGiEAAMwQhIz4xIgQAADWCEJGqBECAMAeQcgI8wgBAGCPIGTE//VvnhEhAADsEISMhGuEyEEAANghCBmhRggAAHsEISPUCAEAYI8gZOTEhIokIQAArBCEjIRvjZGDAACwQxAy4qdGCAAAcwQhI+HV54lBAADYIQgZoUYIAAB7BCEj4TVXWWsMAAA7BCEj4ZmlHSNCAACYIQgZ8TGPEAAA5ghCRk7cGiMJAQBghSBk5ESxtHFHAACIYgQhIyeW2CAJAQBghSBkxM/M0gAAmCMIWWFmaQAAzBGEjDChIgAA9ghCRvwssQEAgDmCkBFqhAAAsEcQMuKjRggAAHMEISM+aoQAADBHEDLiZ4kNAADMEYSMhJfYIAgBAGCHIGSEx+cBALBHEDJCsTQAAPYIQkaoEQIAwB5ByMiJESHbfgAAEM0IQkZYfR4AAHsEISPezNK23QAAIKoRhIwwoSIAAPYIQka8GiGKhAAAMEMQMsJTYwAA2CMIGaFGCAAAewQhI8wsDQCAPYKQMYIQAAB2CEJG/P7wiJBxRwAAiGIEISN+b/l5024AABDVCEJGfKJGCAAAawQhI35WnwcAwBxByMiJmaWNOwIAQBQjCBnxaoTEwqsAAFghCBkJjwhJzC4NAIAVgpCRk0eEqBMCAMAGQchIxIiQYT8AAIhmBCEjjAgBAGCPIGSEGiEAAOwRhIwwIgQAgD2CkBE/I0IAAJgjCF0EGBECAMAGQcjIySNCzC4NAIANgpARZpYGAMAeQcgINUIAANgjCBnx8dQYAADmCEJGfNQIAQBgjiBkKFwn5FhkAwAAE7UOQhs2bNCoUaOUkpIin8+nl156KWK/c06zZs1Shw4d1KxZM6Wnp+uTTz6JaHPo0CFlZmYqPj5eiYmJmjJlikpLSyPafPDBB7rhhhsUFxenTp06af78+dX6smzZMvXu3VtxcXHq16+fVq5cWeu+WArXCXFnDAAAG7UOQkeOHNGAAQO0cOHC0+6fP3++fvvb3+rJJ5/Upk2b1KJFC2VkZOj48eNem8zMTG3btk05OTlavny5NmzYoDvuuMPbX1JSomHDhqlLly7Ky8vTggULNGfOHP3+97/32mzcuFHjx4/XlClTtGXLFo0ZM0ZjxozRhx9+WKu+WArfHaNGCAAAI+4CSHIvvvii9z4UCrnk5GS3YMECb1tRUZELBALuueeec845t337difJvfPOO16b1157zfl8Pvf5558755xbtGiRa926tSsrK/PazJgxw/Xq1ct7f+utt7qRI0dG9Cc1NdXdeeedNe7LuRQXFztJrri4uEbta6vnv610XWYsd5/942i9HB8AgGhUm+/vOq0R2rVrl4LBoNLT071tCQkJSk1NVW5uriQpNzdXiYmJGjx4sNcmPT1dfr9fmzZt8trceOONio2N9dpkZGSooKBA//jHP7w2J39OuE34c2rSl1OVlZWppKQk4lWfvBohRoQAADBRp0EoGAxKkpKSkiK2JyUlefuCwaDat28fsb9JkyZq06ZNRJvTHePkzzhTm5P3n6svp5o3b54SEhK8V6dOnWpw1uePGiEAAGzx1NhJZs6cqeLiYu+1Z8+eev288AP01AgBAGCjToNQcnKyJGn//v0R2/fv3+/tS05O1oEDByL2V1ZW6tChQxFtTneMkz/jTG1O3n+uvpwqEAgoPj4+4lWfwiNCzCMEAICNOg1C3bp1U3JyslavXu1tKykp0aZNm5SWliZJSktLU1FRkfLy8rw2a9asUSgUUmpqqtdmw4YNqqio8Nrk5OSoV69eat26tdfm5M8Jtwl/Tk36Ys1HjRAAAKZqHYRKS0uVn5+v/Px8SV8VJefn56uwsFA+n0/33HOPfvWrX+mVV17R1q1bdfvttyslJUVjxoyRJF111VUaPny4pk6dqs2bN+utt97S9OnTddtttyklJUWSNGHCBMXGxmrKlCnatm2bnn/+eT3xxBPKzs72+nH33Xdr1apV+s1vfqOPP/5Yc+bM0bvvvqvp06dLUo36Ys3HiBAAALZq+0ja2rVrnaRqr4kTJzrnvnps/cEHH3RJSUkuEAi4oUOHuoKCgohjHDx40I0fP961bNnSxcfHu8mTJ7vDhw9HtHn//ffdt771LRcIBNzll1/uHn744Wp9Wbp0qbvyyitdbGys69u3r1uxYkXE/pr05Wzq+/H5ax563XWZsdz9PVhSL8cHACAa1eb72+cc92XOpKSkRAkJCSouLq6XeqFBv8zRwSPlev2eG9UruVWdHx8AgGhUm+9vnhozFL41xlpjAADYIAgZ8pbYCNn2AwCAaEUQMuRnrTEAAEwRhAyF5xECAAA2CEKGTkyoyIgQAAAWCEIXAeYRAgDABkHIkP/r3z4jQgAA2CAIGWL1eQAAbBGEDIVLpZnTEgAAGwQhQ6w+DwCALYKQIR/zCAEAYIogZIgaIQAAbBGEDIVHhKgRAgDABkHIEDVCAADYIggZ8jGzNAAApghChsKLrhKDAACwQRAyxFNjAADYIggZOvHUGEEIAAALBCFDPh6fBwDAFEHIUHiJDZ4aAwDABkHIkJ8aIQAATBGEDFEjBACALYKQIZbYAADAFkHIkndrzLYbAABEK4KQIWqEAACwRRAy5GeJDQAATBGEDIWDEAAAsEEQMsQSGwAA2CIIGfJWnw8ZdwQAgChFEDJEsTQAALYIQoa8eYSM+wEAQLQiCBkKl0ozszQAADYIQoa8GiFyEAAAJghChsI1QgwIAQBggyBkiMfnAQCwRRAyxOrzAADYIggZ8lMjBACAKYKQIZ9XI0QSAgDAAkHIEE+NAQBgiyBkiJmlAQCwRRAydKJY2rgjAABEKYKQIa9GiEU2AAAwQRAy5BM1QgAAWCIIGaJGCAAAWwQhQ9QIAQBgiyBkiHmEAACwRRAyxDxCAADYIggZokYIAABbBCFD1AgBAGCLIGSIGiEAAGwRhAyx+jwAALYIQoZ81AgBAGCKIGTIqxEy7gcAANGKIGTo6wEhRoQAADBCEDLk9/PUGAAAlghChrwaIaqlAQAwQRAyRI0QAAC2CEKGqBECAMAWQcgQM0sDAGCLIGSItcYAALBFELLEiBAAAKYIQoYYEQIAwBZByBBrjQEAYIsgZCg8IsQD9AAA2CAIGfKFR4RCxh0BACBKEYQMsfo8AAC2CEKGqBECAMAWQchQuEbIUSMEAIAJgpAhn5hHCAAAS3UehObMmSOfzxfx6t27t7f/+PHjysrK0mWXXaaWLVvqlltu0f79+yOOUVhYqJEjR6p58+Zq37697r//flVWVka0WbdunQYOHKhAIKAePXpoyZIl1fqycOFCde3aVXFxcUpNTdXmzZvr+nQvCDVCAADYqpcRob59+2rfvn3e68033/T23XvvvXr11Ve1bNkyrV+/Xnv37tXYsWO9/VVVVRo5cqTKy8u1ceNGPf3001qyZIlmzZrltdm1a5dGjhypb3/728rPz9c999yjn/zkJ3r99de9Ns8//7yys7M1e/ZsvffeexowYIAyMjJ04MCB+jjl80KNEAAAxlwdmz17thswYMBp9xUVFbmmTZu6ZcuWeds++ugjJ8nl5uY655xbuXKl8/v9LhgMem0WL17s4uPjXVlZmXPOuQceeMD17ds34tjjxo1zGRkZ3vshQ4a4rKws731VVZVLSUlx8+bNq/G5FBcXO0muuLi4xj9TG0+9+X+uy4zlLuuZvHo5PgAA0ag239/1MiL0ySefKCUlRVdccYUyMzNVWFgoScrLy1NFRYXS09O9tr1791bnzp2Vm5srScrNzVW/fv2UlJTktcnIyFBJSYm2bdvmtTn5GOE24WOUl5crLy8voo3f71d6errX5nTKyspUUlIS8apPrD4PAICtOg9CqampWrJkiVatWqXFixdr165duuGGG3T48GEFg0HFxsYqMTEx4meSkpIUDAYlScFgMCIEhfeH952tTUlJiY4dO6Yvv/xSVVVVp20TPsbpzJs3TwkJCd6rU6dO5/U7qCnWGgMAwFaTuj7giBEjvD/3799fqamp6tKli5YuXapmzZrV9cfVqZkzZyo7O9t7X1JSUq9hyMeIEAAApur98fnExERdeeWV2rFjh5KTk1VeXq6ioqKINvv371dycrIkKTk5udpTZOH352oTHx+vZs2aqW3btoqJiTltm/AxTicQCCg+Pj7iVZ94agwAAFv1HoRKS0u1c+dOdejQQYMGDVLTpk21evVqb39BQYEKCwuVlpYmSUpLS9PWrVsjnu7KyclRfHy8+vTp47U5+RjhNuFjxMbGatCgQRFtQqGQVq9e7bW5GPDUGAAAtuo8CN13331av369du/erY0bN+rmm29WTEyMxo8fr4SEBE2ZMkXZ2dlau3at8vLyNHnyZKWlpen666+XJA0bNkx9+vTRj370I73//vt6/fXX9Ytf/EJZWVkKBAKSpLvuukv/93//pwceeEAff/yxFi1apKVLl+ree+/1+pGdna3//u//1tNPP62PPvpI06ZN05EjRzR58uS6PuXz5s0szYgQAAAm6rxG6LPPPtP48eN18OBBtWvXTt/61rf09ttvq127dpKkxx57TH6/X7fccovKysqUkZGhRYsWeT8fExOj5cuXa9q0aUpLS1OLFi00ceJEzZ0712vTrVs3rVixQvfee6+eeOIJdezYUX/4wx+UkZHhtRk3bpy++OILzZo1S8FgUNdcc41WrVpVrYDaklcjZNwPAACilc8xHHFGJSUlSkhIUHFxcb3UCy17d4/u/+sHuqlXOy2ZPKTOjw8AQDSqzfc3a40ZokYIAABbBCFD/q9/+wzKAQBggyBkiJmlAQCwRRC6CDCPEAAANghChk7UCBGEAACwQBAyRLE0AAC2CEKGwktsMJEQAAA2CEKGWH0eAABbBCFDPmqEAAAwRRAy5GeJDQAATBGEDIVLhCiWBgDABkHIEDNLAwBgiyBkiBohAABsEYQMscQGAAC2CEKGqBECAMAWQcjQiREhkhAAABYIQoaYUBEAAFsEIUtfByFyEAAANghChlh9HgAAWwQhQzw1BgCALYKQIWqEAACwRRAy5AvXCNl2AwCAqEUQMsTM0gAA2CIIGfKKpUPGHQEAIEoRhAyFa4QAAIANgpAhn7g1BgCAJYKQIR9PjQEAYIogZOjEhIrGHQEAIEoRhAz5v/7tMyAEAIANgpChcI0Qq88DAGCDIGSImaUBALBFEDLko0YIAABTBCFD3hIbjAgBAGCCIGSI1ecBALBFEDJEjRAAALYIQoaYRwgAAFsEoYuAE0kIAAALBCFDfj8jQgAAWCIIGfLz1BgAAKYIQoZ4agwAAFsEIUNfDwjx1BgAAEYIQoaYWRoAAFsEIUPhGiGJOiEAACwQhAyFR4Qk6oQAALBAEDJ08ogQdUIAADQ8gpChk0eEqBMCAKDhEYQMMSIEAIAtgpChk0eEAABAwyMIGWJECAAAWwQhQ35qhAAAMEUQMuRjRAgAAFMEIUM+MY8QAACWCEKGmFkaAABbBCFD1AgBAGCLIGTIx4gQAACmCEKGmFkaAABbBCFj4TohRoQAAGh4BCFj4TohRoQAAGh4BCFj4btjTiQhAAAaGkHImI8RIQAAzBCEjIVrhEIkIQAAGhxByFi4RohaaQAAGh5ByFj4AXpqhAAAaHgEIWM8NQYAgB2CkLHwU2OsPg8AQMMjCBnz+8M1QgQhAAAaGkHImFcjRA4CAKDBEYSMUSMEAICdqAhCCxcuVNeuXRUXF6fU1FRt3rzZukueExMqkoQAAGhol3wQev7555Wdna3Zs2frvffe04ABA5SRkaEDBw5Yd03SSUtskIMAAGhwl3wQevTRRzV16lRNnjxZffr00ZNPPqnmzZvrqaeesutUZbm0KE16OUvfC61Xd9/n+nTX3/V/hYXaf/CQjpVVUDwNAEADaGLdgfpUXl6uvLw8zZw509vm9/uVnp6u3Nzcau3LyspUVlbmvS8pKamfjn2eJx3YLh3YrockKSApJ7LJIddSh3ytdczfQvI3kfM3kfPFKORropDv6z9/vU0+/1e32Hxf59rwMJN8cvKd5r2896du83bplPe+U/c0fq7a2QI4N/7eoBZq8p9L83a6ftKv670rZ3JJB6Evv/xSVVVVSkpKitielJSkjz/+uFr7efPm6aGHHqr/jnXoL2X+Vdq1QQc/fENxJbsVq3I1VaXXpI2vVG1UKoX01QsAgEtQof9ySQShi8LMmTOVnZ3tvS8pKVGnTp3q/oNiW0g9vyv1/K4uG/bLE9tDVXIVR3X0SKmO/mOfyv6xT2VHS3SsrFwV5WVyVZVyoUq5qgrp6z+rqlLOVck5p1AoJN/Xi3X4nCS5r17h22zOndgv99VuuRPLe5zhblz93aSzu/3nY0kT1JFouovN3xvURk3/a/E1v0yd67UnZ3dJB6G2bdsqJiZG+/fvj9i+f/9+JScnV2sfCAQUCAQaqnvV+WPkC7RSi0ArtWjTwa4fAABEiUu6WDo2NlaDBg3S6tWrvW2hUEirV69WWlqaYc8AAMDF4JIeEZKk7OxsTZw4UYMHD9aQIUP0+OOP68iRI5o8ebJ11wAAgLFLPgiNGzdOX3zxhWbNmqVgMKhrrrlGq1atqlZADQAAoo/PMWHNGZWUlCghIUHFxcWKj4+37g4AAKiB2nx/X9I1QgAAAGdDEAIAAFGLIAQAAKIWQQgAAEQtghAAAIhaBCEAABC1CEIAACBqEYQAAEDUIggBAICodckvsXEhwpNul5SUGPcEAADUVPh7uyaLZxCEzuLw4cOSpE6dOhn3BAAA1Nbhw4eVkJBw1jasNXYWoVBIe/fuVatWreTz+er02CUlJerUqZP27Nlzya5jdqmf46V+ftKlf46X+vlJnOOl4FI/P6nuz9E5p8OHDyslJUV+/9mrgBgROgu/36+OHTvW62fEx8dfsv9hh13q53ipn5906Z/jpX5+Eud4KbjUz0+q23M810hQGMXSAAAgahGEAABA1CIIGQkEApo9e7YCgYB1V+rNpX6Ol/r5SZf+OV7q5ydxjpeCS/38JNtzpFgaAABELUaEAABA1CIIAQCAqEUQAgAAUYsgBAAAohZByMDChQvVtWtXxcXFKTU1VZs3b7bu0nmbN2+errvuOrVq1Urt27fXmDFjVFBQENHmpptuks/ni3jdddddRj2unTlz5lTre+/evb39x48fV1ZWli677DK1bNlSt9xyi/bv32/Y49rr2rVrtXP0+XzKysqS1Div34YNGzRq1CilpKTI5/PppZdeitjvnNOsWbPUoUMHNWvWTOnp6frkk08i2hw6dEiZmZmKj49XYmKipkyZotLS0gY8i7M72zlWVFRoxowZ6tevn1q0aKGUlBTdfvvt2rt3b8QxTnftH3744QY+k9M71zWcNGlStb4PHz48ok1jvoaSTvv30ufzacGCBV6bi/ka1uT7oSb/hhYWFmrkyJFq3ry52rdvr/vvv1+VlZV11k+CUAN7/vnnlZ2drdmzZ+u9997TgAEDlJGRoQMHDlh37bysX79eWVlZevvtt5WTk6OKigoNGzZMR44ciWg3depU7du3z3vNnz/fqMe117dv34i+v/nmm96+e++9V6+++qqWLVum9evXa+/evRo7dqxhb2vvnXfeiTi/nJwcSdIPf/hDr01ju35HjhzRgAEDtHDhwtPunz9/vn7729/qySef1KZNm9SiRQtlZGTo+PHjXpvMzExt27ZNOTk5Wr58uTZs2KA77rijoU7hnM52jkePHtV7772nBx98UO+9955eeOEFFRQU6Pvf/361tnPnzo24tj/96U8bovvndK5rKEnDhw+P6Ptzzz0Xsb8xX0NJEee2b98+PfXUU/L5fLrlllsi2l2s17Am3w/n+je0qqpKI0eOVHl5uTZu3Kinn35aS5Ys0axZs+quow4NasiQIS4rK8t7X1VV5VJSUty8efMMe1V3Dhw44CS59evXe9v+6Z/+yd199912nboAs2fPdgMGDDjtvqKiIte0aVO3bNkyb9tHH33kJLnc3NwG6mHdu/vuu1337t1dKBRyzjXu6+ecc5Lciy++6L0PhUIuOTnZLViwwNtWVFTkAoGAe+6555xzzm3fvt1Jcu+8847X5rXXXnM+n899/vnnDdb3mjr1HE9n8+bNTpL79NNPvW1dunRxjz32WP12rg6c7vwmTpzoRo8efcafuRSv4ejRo913vvOdiG2N5Ro6V/37oSb/hq5cudL5/X4XDAa9NosXL3bx8fGurKysTvrFiFADKi8vV15entLT071tfr9f6enpys3NNexZ3SkuLpYktWnTJmL7M888o7Zt2+rqq6/WzJkzdfToUYvunZdPPvlEKSkpuuKKK5SZmanCwkJJUl5enioqKiKuZ+/evdW5c+dGez3Ly8v15z//WT/+8Y8jFhpuzNfvVLt27VIwGIy4bgkJCUpNTfWuW25urhITEzV48GCvTXp6uvx+vzZt2tTgfa4LxcXF8vl8SkxMjNj+8MMP67LLLtO1116rBQsW1Okth/q2bt06tW/fXr169dK0adN08OBBb9+ldg3379+vFStWaMqUKdX2NZZreOr3Q03+Dc3NzVW/fv2UlJTktcnIyFBJSYm2bdtWJ/1i0dUG9OWXX6qqqirigkpSUlKSPv74Y6Ne1Z1QKKR77rlH3/zmN3X11Vd72ydMmKAuXbooJSVFH3zwgWbMmKGCggK98MILhr2tmdTUVC1ZskS9evXSvn379NBDD+mGG27Qhx9+qGAwqNjY2GpfLElJSQoGgzYdvkAvvfSSioqKNGnSJG9bY75+pxO+Nqf7exjeFwwG1b59+4j9TZo0UZs2bRrltT1+/LhmzJih8ePHRyxo+a//+q8aOHCg2rRpo40bN2rmzJnat2+fHn30UcPe1szw4cM1duxYdevWTTt37tTPf/5zjRgxQrm5uYqJibnkruHTTz+tVq1aVbv13liu4em+H2ryb2gwGDzt39XwvrpAEEKdycrK0ocffhhRQyMp4p58v3791KFDBw0dOlQ7d+5U9+7dG7qbtTJixAjvz/3791dqaqq6dOmipUuXqlmzZoY9qx9//OMfNWLECKWkpHjbGvP1w1eF07feequcc1q8eHHEvuzsbO/P/fv3V2xsrO68807Nmzfvol/O4bbbbvP+3K9fP/Xv31/du3fXunXrNHToUMOe1Y+nnnpKmZmZiouLi9jeWK7hmb4fLgbcGmtAbdu2VUxMTLWK+P379ys5OdmoV3Vj+vTpWr58udauXauOHTuetW1qaqokaceOHQ3RtTqVmJioK6+8Ujt27FBycrLKy8tVVFQU0aaxXs9PP/1Ub7zxhn7yk5+ctV1jvn6SvGtztr+HycnJ1R5gqKys1KFDhxrVtQ2HoE8//VQ5OTkRo0Gnk5qaqsrKSu3evbthOliHrrjiCrVt29b77/JSuYaS9Le//U0FBQXn/LspXZzX8EzfDzX5NzQ5Ofm0f1fD++oCQagBxcbGatCgQVq9erW3LRQKafXq1UpLSzPs2flzzmn69Ol68cUXtWbNGnXr1u2cP5Ofny9J6tChQz33ru6VlpZq586d6tChgwYNGqSmTZtGXM+CggIVFhY2yuv5pz/9Se3bt9fIkSPP2q4xXz9J6tatm5KTkyOuW0lJiTZt2uRdt7S0NBUVFSkvL89rs2bNGoVCIS8IXuzCIeiTTz7RG2+8ocsuu+ycP5Ofny+/31/tllJj8Nlnn+ngwYPef5eXwjUM++Mf/6hBgwZpwIAB52x7MV3Dc30/1OTf0LS0NG3dujUi1IZDfZ8+feqso2hAf/nLX1wgEHBLlixx27dvd3fccYdLTEyMqIhvTKZNm+YSEhLcunXr3L59+7zX0aNHnXPO7dixw82dO9e9++67bteuXe7ll192V1xxhbvxxhuNe14zP/vZz9y6devcrl273FtvveXS09Nd27Zt3YEDB5xzzt11112uc+fObs2aNe7dd991aWlpLi0tzbjXtVdVVeU6d+7sZsyYEbG9sV6/w4cPuy1btrgtW7Y4Se7RRx91W7Zs8Z6Yevjhh11iYqJ7+eWX3QcffOBGjx7tunXr5o4dO+YdY/jw4e7aa691mzZtcm+++abr2bOnGz9+vNUpVXO2cywvL3ff//73XceOHV1+fn7E383wkzYbN250jz32mMvPz3c7d+50f/7zn127du3c7bffbnxmXznb+R0+fNjdd999Ljc31+3atcu98cYbbuDAga5nz57u+PHj3jEa8zUMKy4uds2bN3eLFy+u9vMX+zU81/eDc+f+N7SystJdffXVbtiwYS4/P9+tWrXKtWvXzs2cObPO+kkQMvC73/3Ode7c2cXGxrohQ4a4t99+27pL503SaV9/+tOfnHPOFRYWuhtvvNG1adPGBQIB16NHD3f//fe74uJi247X0Lhx41yHDh1cbGysu/zyy924cePcjh07vP3Hjh1z//Iv/+Jat27tmjdv7m6++Wa3b98+wx6fn9dff91JcgUFBRHbG+v1W7t27Wn/u5w4caJz7qtH6B988EGXlJTkAoGAGzp0aLVzP3jwoBs/frxr2bKli4+Pd5MnT3aHDx82OJvTO9s57tq164x/N9euXeuccy4vL8+lpqa6hIQEFxcX56666ir361//OiJIWDrb+R09etQNGzbMtWvXzjVt2tR16dLFTZ06tdr/UDbmaxj2X//1X65Zs2auqKio2s9f7NfwXN8PztXs39Ddu3e7ESNGuGbNmrm2bdu6n/3sZ66ioqLO+un7urMAAABRhxohAAAQtQhCAAAgahGEAABA1CIIAQCAqEUQAgAAUYsgBAAAohZBCAAARC2CEAAAiFoEIQAAELUIQgAAIGoRhAAAQNQiCAEAgKj1/wFpIhw7jxximQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters tunning"
      ],
      "metadata": {
        "id": "qfixQ2bXw_m2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_v5(lr,batch_size):  \n",
        "  np.random.seed(1337)\n",
        "  model = Sequential()\n",
        "\n",
        "  # This adds the input layer (by specifying input dimension)\n",
        "  model.add(InputLayer(input_shape=X_train.shape[1]))\n",
        "  #Add 1st hidden layer\n",
        "  model.add(Dense(3200, activation='relu',kernel_initializer='normal'))\n",
        "  # Adding the output layer\n",
        "  # Notice that we do not need to specify input dim. \n",
        "  # we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n",
        "  # We use the linear function because we want numerical outcomes\n",
        "  model.add(Dense(1, activation = 'linear')) \n",
        "  #compile model\n",
        "  model.compile(loss=losses.MeanSquaredError(), optimizer=optimizers.Adam(learning_rate=lr), metrics=['mse','mae']) ### Loss function = MeanSquaredError()\n",
        "  return model"
      ],
      "metadata": {
        "id": "9hnhY0H_yqv0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're using Grid Search to optimize two hyperparameters - **Batch Size** & **Learning Rate**. \n",
        "\n",
        "You can also optimize the other hyperparameters as mentioned above."
      ],
      "metadata": {
        "id": "RJlZGD68y0WE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras_estimator = KerasRegressor(build_fn=create_model_v5, verbose=1)\n",
        "# define the grid search parameters\n",
        "param_grid = {\n",
        "    'batch_size':[64,32,70,128,3200,2800,5000],\n",
        "    \"lr\":[0.8,0.0616*1.7,0.1,0.001],}\n",
        "# param_grid = {\n",
        "#     'batch_size':[64,32,70,128,3200,2800,5000],\n",
        "#     \"lr\":[0.8,0.0616*1.7,0.1,0.001],\"neuron_1\":[32,64,128,2000,2500,3200,5000],\"kernel_initializer\":[\"normal\",\"he_normal\",\"gorot_uniform\",\"uniform\"]}\n",
        "kfold_splits = 5\n",
        "grid = GridSearchCV(estimator=keras_estimator,  \n",
        "                    verbose=1,\n",
        "                    cv=kfold_splits,  \n",
        "                    param_grid=param_grid,n_jobs=-1)"
      ],
      "metadata": {
        "id": "dUvslK3bzOP0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "  \n",
        "# store starting time\n",
        "begin = time.time()\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\",monitor='mae',\n",
        "                            save_weights_only=True, mode='min',verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='mae',factor=0.86,patience=2,min_lr=0.00001,model='auto')\n",
        "\n",
        "callbacks = [checkpoint,reduce_lr]\n",
        "\n",
        "grid_result = grid.fit(X_train, y_train,epochs=1,validation_split=0.2,callbacks=callbacks,verbose=1) \n",
        "\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "time.sleep(1)\n",
        "# store end time\n",
        "end = time.time()\n",
        "  \n",
        "# total time taken\n",
        "print(f\"Total runtime of the program is {end - begin}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgnSCNwJ0FNm",
        "outputId": "5f0a7a75-cadf-4837-9c34-904a9994e1b1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
            "114/130 [=========================>....] - ETA: 0s - loss: 2481695.5000 - mse: 2481695.5000 - mae: 850.9438\n",
            "Epoch 1: saving model to model_weights.h5\n",
            "130/130 [==============================] - 2s 4ms/step - loss: 2195113.5000 - mse: 2195113.5000 - mae: 780.0162 - val_loss: 94851.5859 - val_mse: 94851.5859 - val_mae: 250.4559 - lr: 0.0010\n",
            "Best: -96310.467188 using {'batch_size': 70, 'lr': 0.001}\n",
            "Total runtime of the program is 270.36895537376404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trial summary\n",
        "- Hyperparameters:\n",
        "- number of layers in the model: 1\n",
        "- number of neurons in layer_0: 3200\n",
        "- Activation function for layer_0: relu\n",
        "- Kernel_initializer for layer_0: normal\n",
        "- Number of units in the output layer: 2\n",
        "- Activation function for the output layer: linear\n",
        "- Kernel_initializer for output layer: uniform\n",
        "- Optimizer for the model: Adam\n",
        "- Loss for the model: MeanSquaredError\n",
        "- Model evaluation metric: Mean absolute error/ R2"
      ],
      "metadata": {
        "id": "vIKIEOjo7r1o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azbjms5LWEM1",
        "outputId": "afce1f87-b6a1-4818-b9d6-c4a66811f30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 108197.2188 - mse: 108197.2188 - mae: 131.3669\n",
            "Epoch 1: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 105145.2422 - mse: 105145.2422 - mae: 128.1131 - lr: 0.1047\n",
            "Epoch 2/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 344.3181 - mse: 344.3181 - mae: 14.7859\n",
            "Epoch 2: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 343.6282 - mse: 343.6282 - mae: 14.7939 - lr: 0.1047\n",
            "Epoch 3/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 202.4178 - mse: 202.4178 - mae: 10.8890\n",
            "Epoch 3: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 198.3125 - mse: 198.3125 - mae: 10.7590 - lr: 0.1047\n",
            "Epoch 4/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 90.4385 - mse: 90.4385 - mae: 7.0450\n",
            "Epoch 4: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 89.6372 - mse: 89.6372 - mae: 7.0144 - lr: 0.1047\n",
            "Epoch 5/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 52.5404 - mse: 52.5404 - mae: 5.3903\n",
            "Epoch 5: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 51.4685 - mse: 51.4685 - mae: 5.3388 - lr: 0.1047\n",
            "Epoch 6/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 28.3577 - mse: 28.3577 - mae: 3.9787\n",
            "Epoch 6: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 27.9497 - mse: 27.9497 - mae: 3.9502 - lr: 0.1047\n",
            "Epoch 7/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 17.3952 - mse: 17.3952 - mae: 3.0500\n",
            "Epoch 7: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 17.3368 - mse: 17.3368 - mae: 3.0460 - lr: 0.1047\n",
            "Epoch 8/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 10.6913 - mse: 10.6913 - mae: 2.2938\n",
            "Epoch 8: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 11.2376 - mse: 11.2376 - mae: 2.3658 - lr: 0.1047\n",
            "Epoch 9/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 12.0524 - mse: 12.0524 - mae: 2.5150\n",
            "Epoch 9: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 12.4720 - mse: 12.4720 - mae: 2.5610 - lr: 0.1047\n",
            "Epoch 10/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 7.3569 - mse: 7.3569 - mae: 1.9171\n",
            "Epoch 10: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 7.2996 - mse: 7.2996 - mae: 1.9047 - lr: 0.1047\n",
            "Epoch 11/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 6.1006 - mse: 6.1006 - mae: 1.7680\n",
            "Epoch 11: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 6.1279 - mse: 6.1279 - mae: 1.7702 - lr: 0.1047\n",
            "Epoch 12/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 6.2612 - mse: 6.2612 - mae: 1.7914\n",
            "Epoch 12: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 6.1046 - mse: 6.1046 - mae: 1.7690 - lr: 0.1047\n",
            "Epoch 13/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 5.3297 - mse: 5.3297 - mae: 1.6291\n",
            "Epoch 13: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 5.4134 - mse: 5.4134 - mae: 1.6469 - lr: 0.1047\n",
            "Epoch 14/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 5.9749 - mse: 5.9749 - mae: 1.7334\n",
            "Epoch 14: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 6.0107 - mse: 6.0107 - mae: 1.7421 - lr: 0.1047\n",
            "Epoch 15/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 10.8436 - mse: 10.8436 - mae: 2.3629\n",
            "Epoch 15: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 10.7722 - mse: 10.7722 - mae: 2.3532 - lr: 0.1047\n",
            "Epoch 16/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 6.0090 - mse: 6.0090 - mae: 1.8329\n",
            "Epoch 16: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 5.9480 - mse: 5.9480 - mae: 1.8206 - lr: 0.0890\n",
            "Epoch 17/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 5.7085 - mse: 5.7085 - mae: 1.7672\n",
            "Epoch 17: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 5.6572 - mse: 5.6572 - mae: 1.7619 - lr: 0.0890\n",
            "Epoch 18/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 6.4652 - mse: 6.4652 - mae: 1.8733\n",
            "Epoch 18: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 6.3656 - mse: 6.3656 - mae: 1.8582 - lr: 0.0757\n",
            "Epoch 19/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 13.0691 - mse: 13.0691 - mae: 2.4538\n",
            "Epoch 19: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 12.5210 - mse: 12.5210 - mae: 2.4043 - lr: 0.0757\n",
            "Epoch 20/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 8.1912 - mse: 8.1912 - mae: 2.0210\n",
            "Epoch 20: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 8.1912 - mse: 8.1912 - mae: 2.0210 - lr: 0.0643\n",
            "Epoch 21/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 3.8894 - mse: 3.8894 - mae: 1.4612\n",
            "Epoch 21: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 4.1325 - mse: 4.1325 - mae: 1.4906 - lr: 0.0643\n",
            "Epoch 22/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 6.9928 - mse: 6.9928 - mae: 1.9206\n",
            "Epoch 22: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 7.0942 - mse: 7.0942 - mae: 1.9343 - lr: 0.0643\n",
            "Epoch 23/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 79.1633 - mse: 79.1633 - mae: 5.9213\n",
            "Epoch 23: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 76.4911 - mse: 76.4911 - mae: 5.7964 - lr: 0.0643\n",
            "Epoch 24/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 4.9653 - mse: 4.9653 - mae: 1.6318\n",
            "Epoch 24: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 4.9613 - mse: 4.9613 - mae: 1.6319 - lr: 0.0547\n",
            "Epoch 25/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 17.6118 - mse: 17.6118 - mae: 2.9570\n",
            "Epoch 25: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 16.4611 - mse: 16.4611 - mae: 2.8405 - lr: 0.0547\n",
            "Epoch 26/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 3.4164 - mse: 3.4164 - mae: 1.3750\n",
            "Epoch 26: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.2971 - mse: 3.2971 - mae: 1.3425 - lr: 0.0465\n",
            "Epoch 27/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 4.4442 - mse: 4.4442 - mae: 1.6110\n",
            "Epoch 27: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 4.9885 - mse: 4.9885 - mae: 1.7090 - lr: 0.0465\n",
            "Epoch 28/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 3.3205 - mse: 3.3205 - mae: 1.3552\n",
            "Epoch 28: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.3924 - mse: 3.3924 - mae: 1.3690 - lr: 0.0465\n",
            "Epoch 29/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 6.3667 - mse: 6.3667 - mae: 1.7915\n",
            "Epoch 29: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 6.2206 - mse: 6.2206 - mae: 1.7839 - lr: 0.0395\n",
            "Epoch 30/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 3.6800 - mse: 3.6800 - mae: 1.4617\n",
            "Epoch 30: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.7071 - mse: 3.7071 - mae: 1.4685 - lr: 0.0395\n",
            "Epoch 31/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 4.9185 - mse: 4.9185 - mae: 1.6671\n",
            "Epoch 31: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 4.7563 - mse: 4.7563 - mae: 1.6331 - lr: 0.0336\n",
            "Epoch 32/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 4.4817 - mse: 4.4817 - mae: 1.6174\n",
            "Epoch 32: saving model to model_weights.h5\n",
            "167/167 [==============================] - 0s 3ms/step - loss: 4.4536 - mse: 4.4536 - mae: 1.6121 - lr: 0.0336\n",
            "Epoch 33/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 2.5109 - mse: 2.5109 - mae: 1.1820\n",
            "Epoch 33: saving model to model_weights.h5\n",
            "167/167 [==============================] - 0s 3ms/step - loss: 2.5756 - mse: 2.5756 - mae: 1.1976 - lr: 0.0285\n",
            "Epoch 34/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 3.7056 - mse: 3.7056 - mae: 1.4560\n",
            "Epoch 34: saving model to model_weights.h5\n",
            "167/167 [==============================] - 0s 3ms/step - loss: 3.6415 - mse: 3.6415 - mae: 1.4413 - lr: 0.0285\n",
            "Epoch 35/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 12.2784 - mse: 12.2784 - mae: 2.6401\n",
            "Epoch 35: saving model to model_weights.h5\n",
            "167/167 [==============================] - 0s 3ms/step - loss: 12.4610 - mse: 12.4610 - mae: 2.6592 - lr: 0.0285\n",
            "Epoch 36/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 3.9520 - mse: 3.9520 - mae: 1.4900\n",
            "Epoch 36: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.8267 - mse: 3.8267 - mae: 1.4661 - lr: 0.0243\n",
            "Epoch 37/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 2.8323 - mse: 2.8323 - mae: 1.2550\n",
            "Epoch 37: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 2.8844 - mse: 2.8844 - mae: 1.2675 - lr: 0.0243\n",
            "Epoch 38/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 3.9527 - mse: 3.9527 - mae: 1.4998\n",
            "Epoch 38: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 3.8894 - mse: 3.8894 - mae: 1.4875 - lr: 0.0206\n",
            "Epoch 39/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 4.2683 - mse: 4.2683 - mae: 1.5883\n",
            "Epoch 39: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 4.2122 - mse: 4.2122 - mae: 1.5748 - lr: 0.0206\n",
            "Epoch 40/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 2.1667 - mse: 2.1667 - mae: 1.1051\n",
            "Epoch 40: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 2.1667 - mse: 2.1667 - mae: 1.1051 - lr: 0.0175\n",
            "Epoch 41/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 1.7519 - mse: 1.7519 - mae: 0.9818\n",
            "Epoch 41: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 1.7519 - mse: 1.7519 - mae: 0.9818 - lr: 0.0175\n",
            "Epoch 42/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 2.5609 - mse: 2.5609 - mae: 1.2283\n",
            "Epoch 42: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 2.4851 - mse: 2.4851 - mae: 1.2002 - lr: 0.0175\n",
            "Epoch 43/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 19.1359 - mse: 19.1359 - mae: 3.1466\n",
            "Epoch 43: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 18.5297 - mse: 18.5297 - mae: 3.0818 - lr: 0.0175\n",
            "Epoch 44/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 2.8060 - mse: 2.8060 - mae: 1.2846\n",
            "Epoch 44: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 2.7252 - mse: 2.7252 - mae: 1.2565 - lr: 0.0149\n",
            "Epoch 45/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 2.9247 - mse: 2.9247 - mae: 1.2731\n",
            "Epoch 45: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 2.8179 - mse: 2.8179 - mae: 1.2457 - lr: 0.0149\n",
            "Epoch 46/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 1.5843 - mse: 1.5843 - mae: 0.9405\n",
            "Epoch 46: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.5825 - mse: 1.5825 - mae: 0.9416 - lr: 0.0127\n",
            "Epoch 47/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 2.0087 - mse: 2.0087 - mae: 1.0782\n",
            "Epoch 47: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.9977 - mse: 1.9977 - mae: 1.0772 - lr: 0.0127\n",
            "Epoch 48/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 2.7104 - mse: 2.7104 - mae: 1.2535\n",
            "Epoch 48: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 2.6843 - mse: 2.6843 - mae: 1.2474 - lr: 0.0127\n",
            "Epoch 49/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 1.2767 - mse: 1.2767 - mae: 0.8134\n",
            "Epoch 49: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.3141 - mse: 1.3141 - mae: 0.8291 - lr: 0.0108\n",
            "Epoch 50/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 3.4983 - mse: 3.4983 - mae: 1.4829\n",
            "Epoch 50: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.4510 - mse: 3.4510 - mae: 1.4754 - lr: 0.0108\n",
            "Epoch 51/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 3.0906 - mse: 3.0906 - mae: 1.3080\n",
            "Epoch 51: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 3.1373 - mse: 3.1373 - mae: 1.3200 - lr: 0.0108\n",
            "Epoch 52/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 1.8079 - mse: 1.8079 - mae: 1.0361\n",
            "Epoch 52: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.7705 - mse: 1.7705 - mae: 1.0205 - lr: 0.0091\n",
            "Epoch 53/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 1.4700 - mse: 1.4700 - mae: 0.8992\n",
            "Epoch 53: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.4700 - mse: 1.4700 - mae: 0.8992 - lr: 0.0091\n",
            "Epoch 54/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 1.3777 - mse: 1.3777 - mae: 0.8407\n",
            "Epoch 54: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.3786 - mse: 1.3786 - mae: 0.8406 - lr: 0.0078\n",
            "Epoch 55/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 1.3024 - mse: 1.3024 - mae: 0.8333\n",
            "Epoch 55: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.2960 - mse: 1.2960 - mae: 0.8303 - lr: 0.0078\n",
            "Epoch 56/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 1.0639 - mse: 1.0639 - mae: 0.7383\n",
            "Epoch 56: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.0663 - mse: 1.0663 - mae: 0.7378 - lr: 0.0066\n",
            "Epoch 57/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 1.3452 - mse: 1.3452 - mae: 0.8642\n",
            "Epoch 57: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.3457 - mse: 1.3457 - mae: 0.8638 - lr: 0.0066\n",
            "Epoch 58/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 2.0154 - mse: 2.0154 - mae: 1.0953\n",
            "Epoch 58: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 2.0341 - mse: 2.0341 - mae: 1.1025 - lr: 0.0066\n",
            "Epoch 59/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 1.2192 - mse: 1.2192 - mae: 0.7922\n",
            "Epoch 59: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.2173 - mse: 1.2173 - mae: 0.7910 - lr: 0.0056\n",
            "Epoch 60/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 1.9978 - mse: 1.9978 - mae: 1.0365\n",
            "Epoch 60: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.9940 - mse: 1.9940 - mae: 1.0356 - lr: 0.0056\n",
            "Epoch 61/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 1.1660 - mse: 1.1660 - mae: 0.7803\n",
            "Epoch 61: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 1.1648 - mse: 1.1648 - mae: 0.7802 - lr: 0.0048\n",
            "Epoch 62/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 1.2611 - mse: 1.2611 - mae: 0.8311\n",
            "Epoch 62: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 1.2853 - mse: 1.2853 - mae: 0.8392 - lr: 0.0048\n",
            "Epoch 63/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.9622 - mse: 0.9622 - mae: 0.6714\n",
            "Epoch 63: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.9601 - mse: 0.9601 - mae: 0.6708 - lr: 0.0041\n",
            "Epoch 64/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.9127 - mse: 0.9127 - mae: 0.6493\n",
            "Epoch 64: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.9301 - mse: 0.9301 - mae: 0.6556 - lr: 0.0041\n",
            "Epoch 65/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 1.1043 - mse: 1.1043 - mae: 0.7546\n",
            "Epoch 65: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 1.1064 - mse: 1.1064 - mae: 0.7551 - lr: 0.0041\n",
            "Epoch 66/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 1.2366 - mse: 1.2366 - mae: 0.8012\n",
            "Epoch 66: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 1.2378 - mse: 1.2378 - mae: 0.8022 - lr: 0.0041\n",
            "Epoch 67/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 1.0011 - mse: 1.0011 - mae: 0.6953\n",
            "Epoch 67: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.0007 - mse: 1.0007 - mae: 0.6920 - lr: 0.0035\n",
            "Epoch 68/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 1.3155 - mse: 1.3155 - mae: 0.8182\n",
            "Epoch 68: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.3093 - mse: 1.3093 - mae: 0.8192 - lr: 0.0035\n",
            "Epoch 69/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.9858 - mse: 0.9858 - mae: 0.7004\n",
            "Epoch 69: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9962 - mse: 0.9962 - mae: 0.7060 - lr: 0.0029\n",
            "Epoch 70/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.9817 - mse: 0.9817 - mae: 0.6994\n",
            "Epoch 70: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 1.0068 - mse: 1.0068 - mae: 0.7113 - lr: 0.0029\n",
            "Epoch 71/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.9826 - mse: 0.9826 - mae: 0.6843\n",
            "Epoch 71: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9770 - mse: 0.9770 - mae: 0.6823 - lr: 0.0025\n",
            "Epoch 72/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.9858 - mse: 0.9858 - mae: 0.7012\n",
            "Epoch 72: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9846 - mse: 0.9846 - mae: 0.7005 - lr: 0.0025\n",
            "Epoch 73/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.8471 - mse: 0.8471 - mae: 0.6154\n",
            "Epoch 73: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8504 - mse: 0.8504 - mae: 0.6138 - lr: 0.0021\n",
            "Epoch 74/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.9355 - mse: 0.9355 - mae: 0.6684\n",
            "Epoch 74: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9622 - mse: 0.9622 - mae: 0.6801 - lr: 0.0021\n",
            "Epoch 75/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.9088 - mse: 0.9088 - mae: 0.6472\n",
            "Epoch 75: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9089 - mse: 0.9089 - mae: 0.6452 - lr: 0.0021\n",
            "Epoch 76/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.8694 - mse: 0.8694 - mae: 0.6281\n",
            "Epoch 76: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8742 - mse: 0.8742 - mae: 0.6324 - lr: 0.0018\n",
            "Epoch 77/500\n",
            "150/167 [=========================>....] - ETA: 0s - loss: 0.9270 - mse: 0.9270 - mae: 0.6588\n",
            "Epoch 77: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9162 - mse: 0.9162 - mae: 0.6564 - lr: 0.0018\n",
            "Epoch 78/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.8605 - mse: 0.8605 - mae: 0.6083\n",
            "Epoch 78: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8459 - mse: 0.8459 - mae: 0.6046 - lr: 0.0015\n",
            "Epoch 79/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.8602 - mse: 0.8602 - mae: 0.6221\n",
            "Epoch 79: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8648 - mse: 0.8648 - mae: 0.6242 - lr: 0.0015\n",
            "Epoch 80/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.9245 - mse: 0.9245 - mae: 0.6576\n",
            "Epoch 80: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.9253 - mse: 0.9253 - mae: 0.6567 - lr: 0.0015\n",
            "Epoch 81/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.8511 - mse: 0.8511 - mae: 0.6182\n",
            "Epoch 81: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8538 - mse: 0.8538 - mae: 0.6236 - lr: 0.0013\n",
            "Epoch 82/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.8689 - mse: 0.8689 - mae: 0.6469\n",
            "Epoch 82: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8574 - mse: 0.8574 - mae: 0.6365 - lr: 0.0013\n",
            "Epoch 83/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.8334 - mse: 0.8334 - mae: 0.6051\n",
            "Epoch 83: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.8390 - mse: 0.8390 - mae: 0.6096 - lr: 0.0011\n",
            "Epoch 84/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.8137 - mse: 0.8137 - mae: 0.5916\n",
            "Epoch 84: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.8124 - mse: 0.8124 - mae: 0.5906 - lr: 0.0011\n",
            "Epoch 85/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.7831 - mse: 0.7831 - mae: 0.5737\n",
            "Epoch 85: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.7830 - mse: 0.7830 - mae: 0.5733 - lr: 0.0011\n",
            "Epoch 86/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.7934 - mse: 0.7934 - mae: 0.5722\n",
            "Epoch 86: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.8008 - mse: 0.8008 - mae: 0.5785 - lr: 0.0011\n",
            "Epoch 87/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.7848 - mse: 0.7848 - mae: 0.5702\n",
            "Epoch 87: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.7848 - mse: 0.7848 - mae: 0.5702 - lr: 0.0011\n",
            "Epoch 88/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.7786 - mse: 0.7786 - mae: 0.5599\n",
            "Epoch 88: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.7793 - mse: 0.7793 - mae: 0.5609 - lr: 0.0011\n",
            "Epoch 89/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 1.0343 - mse: 1.0343 - mae: 0.7159\n",
            "Epoch 89: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 1.0122 - mse: 1.0122 - mae: 0.7053 - lr: 0.0011\n",
            "Epoch 90/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.7878 - mse: 0.7878 - mae: 0.5671\n",
            "Epoch 90: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7826 - mse: 0.7826 - mae: 0.5648 - lr: 0.0011\n",
            "Epoch 91/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.7647 - mse: 0.7647 - mae: 0.5608\n",
            "Epoch 91: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7629 - mse: 0.7629 - mae: 0.5601 - lr: 9.4011e-04\n",
            "Epoch 92/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.7327 - mse: 0.7327 - mae: 0.5236\n",
            "Epoch 92: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7270 - mse: 0.7270 - mae: 0.5219 - lr: 9.4011e-04\n",
            "Epoch 93/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.7551 - mse: 0.7551 - mae: 0.5474\n",
            "Epoch 93: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7555 - mse: 0.7555 - mae: 0.5474 - lr: 9.4011e-04\n",
            "Epoch 94/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.7591 - mse: 0.7591 - mae: 0.5604\n",
            "Epoch 94: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7571 - mse: 0.7571 - mae: 0.5597 - lr: 9.4011e-04\n",
            "Epoch 95/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.7446 - mse: 0.7446 - mae: 0.5414\n",
            "Epoch 95: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7453 - mse: 0.7453 - mae: 0.5415 - lr: 7.9909e-04\n",
            "Epoch 96/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.7705 - mse: 0.7705 - mae: 0.5588\n",
            "Epoch 96: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7665 - mse: 0.7665 - mae: 0.5557 - lr: 7.9909e-04\n",
            "Epoch 97/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.7524 - mse: 0.7524 - mae: 0.5453\n",
            "Epoch 97: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7482 - mse: 0.7482 - mae: 0.5447 - lr: 6.7923e-04\n",
            "Epoch 98/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.7423 - mse: 0.7423 - mae: 0.5562\n",
            "Epoch 98: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7536 - mse: 0.7536 - mae: 0.5591 - lr: 6.7923e-04\n",
            "Epoch 99/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.7143 - mse: 0.7143 - mae: 0.5151\n",
            "Epoch 99: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7143 - mse: 0.7143 - mae: 0.5151 - lr: 5.7734e-04\n",
            "Epoch 100/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.7115 - mse: 0.7115 - mae: 0.5139\n",
            "Epoch 100: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7105 - mse: 0.7105 - mae: 0.5141 - lr: 5.7734e-04\n",
            "Epoch 101/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.7466 - mse: 0.7466 - mae: 0.5435\n",
            "Epoch 101: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7390 - mse: 0.7390 - mae: 0.5388 - lr: 5.7734e-04\n",
            "Epoch 102/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.7181 - mse: 0.7181 - mae: 0.5216\n",
            "Epoch 102: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.7135 - mse: 0.7135 - mae: 0.5228 - lr: 5.7734e-04\n",
            "Epoch 103/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.7001 - mse: 0.7001 - mae: 0.5029\n",
            "Epoch 103: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6990 - mse: 0.6990 - mae: 0.5033 - lr: 4.9074e-04\n",
            "Epoch 104/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.7089 - mse: 0.7089 - mae: 0.5123\n",
            "Epoch 104: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.7071 - mse: 0.7071 - mae: 0.5103 - lr: 4.9074e-04\n",
            "Epoch 105/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6810 - mse: 0.6810 - mae: 0.4827\n",
            "Epoch 105: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6850 - mse: 0.6850 - mae: 0.4887 - lr: 4.9074e-04\n",
            "Epoch 106/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.7051 - mse: 0.7051 - mae: 0.5038\n",
            "Epoch 106: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6950 - mse: 0.6950 - mae: 0.5025 - lr: 4.9074e-04\n",
            "Epoch 107/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.7218 - mse: 0.7218 - mae: 0.5319\n",
            "Epoch 107: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.7241 - mse: 0.7241 - mae: 0.5317 - lr: 4.9074e-04\n",
            "Epoch 108/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.7003 - mse: 0.7003 - mae: 0.5046\n",
            "Epoch 108: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.7003 - mse: 0.7003 - mae: 0.5050 - lr: 4.1713e-04\n",
            "Epoch 109/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6706 - mse: 0.6706 - mae: 0.4742\n",
            "Epoch 109: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6708 - mse: 0.6708 - mae: 0.4754 - lr: 4.1713e-04\n",
            "Epoch 110/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.7125 - mse: 0.7125 - mae: 0.5226\n",
            "Epoch 110: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.7092 - mse: 0.7092 - mae: 0.5216 - lr: 4.1713e-04\n",
            "Epoch 111/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6753 - mse: 0.6753 - mae: 0.4812\n",
            "Epoch 111: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6753 - mse: 0.6753 - mae: 0.4812 - lr: 4.1713e-04\n",
            "Epoch 112/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6854 - mse: 0.6854 - mae: 0.4934\n",
            "Epoch 112: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6854 - mse: 0.6854 - mae: 0.4934 - lr: 3.5456e-04\n",
            "Epoch 113/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6789 - mse: 0.6789 - mae: 0.4973\n",
            "Epoch 113: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6834 - mse: 0.6834 - mae: 0.4981 - lr: 3.5456e-04\n",
            "Epoch 114/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6902 - mse: 0.6902 - mae: 0.5021\n",
            "Epoch 114: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6893 - mse: 0.6893 - mae: 0.5017 - lr: 3.0138e-04\n",
            "Epoch 115/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6693 - mse: 0.6693 - mae: 0.4769\n",
            "Epoch 115: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6693 - mse: 0.6693 - mae: 0.4769 - lr: 3.0138e-04\n",
            "Epoch 116/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6642 - mse: 0.6642 - mae: 0.4717\n",
            "Epoch 116: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6674 - mse: 0.6674 - mae: 0.4716 - lr: 2.5617e-04\n",
            "Epoch 117/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6675 - mse: 0.6675 - mae: 0.4806\n",
            "Epoch 117: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6713 - mse: 0.6713 - mae: 0.4822 - lr: 2.5617e-04\n",
            "Epoch 118/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6930 - mse: 0.6930 - mae: 0.4856\n",
            "Epoch 118: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6716 - mse: 0.6716 - mae: 0.4768 - lr: 2.5617e-04\n",
            "Epoch 119/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6652 - mse: 0.6652 - mae: 0.4652\n",
            "Epoch 119: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6566 - mse: 0.6566 - mae: 0.4619 - lr: 2.1775e-04\n",
            "Epoch 120/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6627 - mse: 0.6627 - mae: 0.4751\n",
            "Epoch 120: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6674 - mse: 0.6674 - mae: 0.4755 - lr: 2.1775e-04\n",
            "Epoch 121/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6609 - mse: 0.6609 - mae: 0.4707\n",
            "Epoch 121: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6584 - mse: 0.6584 - mae: 0.4710 - lr: 2.1775e-04\n",
            "Epoch 122/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6479 - mse: 0.6479 - mae: 0.4481\n",
            "Epoch 122: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6477 - mse: 0.6477 - mae: 0.4476 - lr: 1.8508e-04\n",
            "Epoch 123/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6715 - mse: 0.6715 - mae: 0.4787\n",
            "Epoch 123: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6697 - mse: 0.6697 - mae: 0.4779 - lr: 1.8508e-04\n",
            "Epoch 124/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6596 - mse: 0.6596 - mae: 0.4644\n",
            "Epoch 124: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6599 - mse: 0.6599 - mae: 0.4640 - lr: 1.8508e-04\n",
            "Epoch 125/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6598 - mse: 0.6598 - mae: 0.4573\n",
            "Epoch 125: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6513 - mse: 0.6513 - mae: 0.4575 - lr: 1.5732e-04\n",
            "Epoch 126/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6567 - mse: 0.6567 - mae: 0.4566\n",
            "Epoch 126: saving model to model_weights.h5\n",
            "167/167 [==============================] - 0s 3ms/step - loss: 0.6510 - mse: 0.6510 - mae: 0.4546 - lr: 1.5732e-04\n",
            "Epoch 127/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6407 - mse: 0.6407 - mae: 0.4425\n",
            "Epoch 127: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6382 - mse: 0.6382 - mae: 0.4402 - lr: 1.3372e-04\n",
            "Epoch 128/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6491 - mse: 0.6491 - mae: 0.4529\n",
            "Epoch 128: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6466 - mse: 0.6466 - mae: 0.4530 - lr: 1.3372e-04\n",
            "Epoch 129/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6442 - mse: 0.6442 - mae: 0.4521\n",
            "Epoch 129: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6476 - mse: 0.6476 - mae: 0.4521 - lr: 1.3372e-04\n",
            "Epoch 130/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6539 - mse: 0.6539 - mae: 0.4584\n",
            "Epoch 130: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6481 - mse: 0.6481 - mae: 0.4562 - lr: 1.1366e-04\n",
            "Epoch 131/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6465 - mse: 0.6465 - mae: 0.4484\n",
            "Epoch 131: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6441 - mse: 0.6441 - mae: 0.4465 - lr: 1.1366e-04\n",
            "Epoch 132/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6391 - mse: 0.6391 - mae: 0.4391\n",
            "Epoch 132: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6373 - mse: 0.6373 - mae: 0.4419 - lr: 9.6615e-05\n",
            "Epoch 133/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6358 - mse: 0.6358 - mae: 0.4403\n",
            "Epoch 133: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6369 - mse: 0.6369 - mae: 0.4420 - lr: 9.6615e-05\n",
            "Epoch 134/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6400 - mse: 0.6400 - mae: 0.4482\n",
            "Epoch 134: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6421 - mse: 0.6421 - mae: 0.4490 - lr: 8.2123e-05\n",
            "Epoch 135/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6429 - mse: 0.6429 - mae: 0.4485\n",
            "Epoch 135: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6425 - mse: 0.6425 - mae: 0.4485 - lr: 8.2123e-05\n",
            "Epoch 136/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6374 - mse: 0.6374 - mae: 0.4391\n",
            "Epoch 136: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6374 - mse: 0.6374 - mae: 0.4391 - lr: 6.9804e-05\n",
            "Epoch 137/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6324 - mse: 0.6324 - mae: 0.4299\n",
            "Epoch 137: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6322 - mse: 0.6322 - mae: 0.4296 - lr: 6.9804e-05\n",
            "Epoch 138/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6327 - mse: 0.6327 - mae: 0.4351\n",
            "Epoch 138: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6353 - mse: 0.6353 - mae: 0.4346 - lr: 6.9804e-05\n",
            "Epoch 139/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6251 - mse: 0.6251 - mae: 0.4214\n",
            "Epoch 139: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6297 - mse: 0.6297 - mae: 0.4237 - lr: 6.9804e-05\n",
            "Epoch 140/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6449 - mse: 0.6449 - mae: 0.4350\n",
            "Epoch 140: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6340 - mse: 0.6340 - mae: 0.4359 - lr: 6.9804e-05\n",
            "Epoch 141/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6294 - mse: 0.6294 - mae: 0.4253\n",
            "Epoch 141: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6309 - mse: 0.6309 - mae: 0.4256 - lr: 6.9804e-05\n",
            "Epoch 142/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6331 - mse: 0.6331 - mae: 0.4337\n",
            "Epoch 142: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6311 - mse: 0.6311 - mae: 0.4337 - lr: 5.9334e-05\n",
            "Epoch 143/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6317 - mse: 0.6317 - mae: 0.4299\n",
            "Epoch 143: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6299 - mse: 0.6299 - mae: 0.4291 - lr: 5.9334e-05\n",
            "Epoch 144/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6388 - mse: 0.6388 - mae: 0.4290\n",
            "Epoch 144: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6309 - mse: 0.6309 - mae: 0.4281 - lr: 5.0433e-05\n",
            "Epoch 145/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6330 - mse: 0.6330 - mae: 0.4273\n",
            "Epoch 145: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6306 - mse: 0.6306 - mae: 0.4277 - lr: 5.0433e-05\n",
            "Epoch 146/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6259 - mse: 0.6259 - mae: 0.4292\n",
            "Epoch 146: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6287 - mse: 0.6287 - mae: 0.4280 - lr: 4.2868e-05\n",
            "Epoch 147/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6337 - mse: 0.6337 - mae: 0.4260\n",
            "Epoch 147: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6307 - mse: 0.6307 - mae: 0.4249 - lr: 4.2868e-05\n",
            "Epoch 148/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6406 - mse: 0.6406 - mae: 0.4265\n",
            "Epoch 148: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6274 - mse: 0.6274 - mae: 0.4228 - lr: 3.6438e-05\n",
            "Epoch 149/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6360 - mse: 0.6360 - mae: 0.4313\n",
            "Epoch 149: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6316 - mse: 0.6316 - mae: 0.4302 - lr: 3.6438e-05\n",
            "Epoch 150/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6235 - mse: 0.6235 - mae: 0.4253\n",
            "Epoch 150: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6298 - mse: 0.6298 - mae: 0.4265 - lr: 3.6438e-05\n",
            "Epoch 151/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6241 - mse: 0.6241 - mae: 0.4165\n",
            "Epoch 151: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6241 - mse: 0.6241 - mae: 0.4165 - lr: 3.0972e-05\n",
            "Epoch 152/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6276 - mse: 0.6276 - mae: 0.4170\n",
            "Epoch 152: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6252 - mse: 0.6252 - mae: 0.4170 - lr: 3.0972e-05\n",
            "Epoch 153/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6259 - mse: 0.6259 - mae: 0.4247\n",
            "Epoch 153: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6271 - mse: 0.6271 - mae: 0.4255 - lr: 3.0972e-05\n",
            "Epoch 154/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6252 - mse: 0.6252 - mae: 0.4221\n",
            "Epoch 154: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6265 - mse: 0.6265 - mae: 0.4221 - lr: 2.6327e-05\n",
            "Epoch 155/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6249 - mse: 0.6249 - mae: 0.4193\n",
            "Epoch 155: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6281 - mse: 0.6281 - mae: 0.4225 - lr: 2.6327e-05\n",
            "Epoch 156/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6212 - mse: 0.6212 - mae: 0.4253\n",
            "Epoch 156: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6268 - mse: 0.6268 - mae: 0.4256 - lr: 2.2378e-05\n",
            "Epoch 157/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6286 - mse: 0.6286 - mae: 0.4181\n",
            "Epoch 157: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6255 - mse: 0.6255 - mae: 0.4181 - lr: 2.2378e-05\n",
            "Epoch 158/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6219 - mse: 0.6219 - mae: 0.4128\n",
            "Epoch 158: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6219 - mse: 0.6219 - mae: 0.4128 - lr: 1.9021e-05\n",
            "Epoch 159/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6167 - mse: 0.6167 - mae: 0.4124\n",
            "Epoch 159: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6222 - mse: 0.6222 - mae: 0.4142 - lr: 1.9021e-05\n",
            "Epoch 160/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6093 - mse: 0.6093 - mae: 0.4121\n",
            "Epoch 160: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6225 - mse: 0.6225 - mae: 0.4139 - lr: 1.9021e-05\n",
            "Epoch 161/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6206 - mse: 0.6206 - mae: 0.4104\n",
            "Epoch 161: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6217 - mse: 0.6217 - mae: 0.4115 - lr: 1.6168e-05\n",
            "Epoch 162/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6227 - mse: 0.6227 - mae: 0.4081\n",
            "Epoch 162: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6224 - mse: 0.6224 - mae: 0.4092 - lr: 1.6168e-05\n",
            "Epoch 163/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6190 - mse: 0.6190 - mae: 0.4099\n",
            "Epoch 163: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6205 - mse: 0.6205 - mae: 0.4095 - lr: 1.6168e-05\n",
            "Epoch 164/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6223 - mse: 0.6223 - mae: 0.4116\n",
            "Epoch 164: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6223 - mse: 0.6223 - mae: 0.4116 - lr: 1.6168e-05\n",
            "Epoch 165/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6236 - mse: 0.6236 - mae: 0.4146\n",
            "Epoch 165: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6228 - mse: 0.6228 - mae: 0.4145 - lr: 1.3743e-05\n",
            "Epoch 166/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6207 - mse: 0.6207 - mae: 0.4068\n",
            "Epoch 166: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6207 - mse: 0.6207 - mae: 0.4068 - lr: 1.3743e-05\n",
            "Epoch 167/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6205 - mse: 0.6205 - mae: 0.4124\n",
            "Epoch 167: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6205 - mse: 0.6205 - mae: 0.4124 - lr: 1.3743e-05\n",
            "Epoch 168/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6235 - mse: 0.6235 - mae: 0.4062\n",
            "Epoch 168: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6201 - mse: 0.6201 - mae: 0.4062 - lr: 1.3743e-05\n",
            "Epoch 169/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6225 - mse: 0.6225 - mae: 0.4112\n",
            "Epoch 169: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6218 - mse: 0.6218 - mae: 0.4112 - lr: 1.3743e-05\n",
            "Epoch 170/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6170 - mse: 0.6170 - mae: 0.4110\n",
            "Epoch 170: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6213 - mse: 0.6213 - mae: 0.4123 - lr: 1.3743e-05\n",
            "Epoch 171/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6216 - mse: 0.6216 - mae: 0.4083\n",
            "Epoch 171: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6217 - mse: 0.6217 - mae: 0.4086 - lr: 1.1681e-05\n",
            "Epoch 172/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6213 - mse: 0.6213 - mae: 0.4073\n",
            "Epoch 172: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6212 - mse: 0.6212 - mae: 0.4073 - lr: 1.1681e-05\n",
            "Epoch 173/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6234 - mse: 0.6234 - mae: 0.4082\n",
            "Epoch 173: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6206 - mse: 0.6206 - mae: 0.4078 - lr: 1.0000e-05\n",
            "Epoch 174/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6198 - mse: 0.6198 - mae: 0.4063\n",
            "Epoch 174: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6200 - mse: 0.6200 - mae: 0.4061 - lr: 1.0000e-05\n",
            "Epoch 175/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6266 - mse: 0.6266 - mae: 0.4107\n",
            "Epoch 175: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6206 - mse: 0.6206 - mae: 0.4093 - lr: 1.0000e-05\n",
            "Epoch 176/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6194 - mse: 0.6194 - mae: 0.4064\n",
            "Epoch 176: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6193 - mse: 0.6193 - mae: 0.4056 - lr: 1.0000e-05\n",
            "Epoch 177/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6214 - mse: 0.6214 - mae: 0.4060\n",
            "Epoch 177: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6195 - mse: 0.6195 - mae: 0.4051 - lr: 1.0000e-05\n",
            "Epoch 178/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6110 - mse: 0.6110 - mae: 0.4062\n",
            "Epoch 178: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6201 - mse: 0.6201 - mae: 0.4070 - lr: 1.0000e-05\n",
            "Epoch 179/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6184 - mse: 0.6184 - mae: 0.4098\n",
            "Epoch 179: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6205 - mse: 0.6205 - mae: 0.4094 - lr: 1.0000e-05\n",
            "Epoch 180/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6216 - mse: 0.6216 - mae: 0.4069\n",
            "Epoch 180: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6195 - mse: 0.6195 - mae: 0.4076 - lr: 1.0000e-05\n",
            "Epoch 181/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6194 - mse: 0.6194 - mae: 0.4054\n",
            "Epoch 181: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6196 - mse: 0.6196 - mae: 0.4057 - lr: 1.0000e-05\n",
            "Epoch 182/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6192 - mse: 0.6192 - mae: 0.4063\n",
            "Epoch 182: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6199 - mse: 0.6199 - mae: 0.4073 - lr: 1.0000e-05\n",
            "Epoch 183/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6217 - mse: 0.6217 - mae: 0.4076\n",
            "Epoch 183: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6196 - mse: 0.6196 - mae: 0.4068 - lr: 1.0000e-05\n",
            "Epoch 184/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6208 - mse: 0.6208 - mae: 0.4072\n",
            "Epoch 184: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6196 - mse: 0.6196 - mae: 0.4074 - lr: 1.0000e-05\n",
            "Epoch 185/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6183 - mse: 0.6183 - mae: 0.4066\n",
            "Epoch 185: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6202 - mse: 0.6202 - mae: 0.4075 - lr: 1.0000e-05\n",
            "Epoch 186/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6194 - mse: 0.6194 - mae: 0.4058\n",
            "Epoch 186: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6194 - mse: 0.6194 - mae: 0.4058 - lr: 1.0000e-05\n",
            "Epoch 187/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6182 - mse: 0.6182 - mae: 0.4085\n",
            "Epoch 187: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6193 - mse: 0.6193 - mae: 0.4079 - lr: 1.0000e-05\n",
            "Epoch 188/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6141 - mse: 0.6141 - mae: 0.4081\n",
            "Epoch 188: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6198 - mse: 0.6198 - mae: 0.4092 - lr: 1.0000e-05\n",
            "Epoch 189/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6230 - mse: 0.6230 - mae: 0.4104\n",
            "Epoch 189: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6190 - mse: 0.6190 - mae: 0.4092 - lr: 1.0000e-05\n",
            "Epoch 190/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6216 - mse: 0.6216 - mae: 0.4084\n",
            "Epoch 190: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6199 - mse: 0.6199 - mae: 0.4078 - lr: 1.0000e-05\n",
            "Epoch 191/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6203 - mse: 0.6203 - mae: 0.4055\n",
            "Epoch 191: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6192 - mse: 0.6192 - mae: 0.4053 - lr: 1.0000e-05\n",
            "Epoch 192/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6278 - mse: 0.6278 - mae: 0.4145\n",
            "Epoch 192: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6188 - mse: 0.6188 - mae: 0.4111 - lr: 1.0000e-05\n",
            "Epoch 193/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6167 - mse: 0.6167 - mae: 0.4066\n",
            "Epoch 193: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6189 - mse: 0.6189 - mae: 0.4066 - lr: 1.0000e-05\n",
            "Epoch 194/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6125 - mse: 0.6125 - mae: 0.4056\n",
            "Epoch 194: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6185 - mse: 0.6185 - mae: 0.4057 - lr: 1.0000e-05\n",
            "Epoch 195/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6181 - mse: 0.6181 - mae: 0.4090\n",
            "Epoch 195: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6186 - mse: 0.6186 - mae: 0.4087 - lr: 1.0000e-05\n",
            "Epoch 196/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6090 - mse: 0.6090 - mae: 0.4026\n",
            "Epoch 196: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6177 - mse: 0.6177 - mae: 0.4045 - lr: 1.0000e-05\n",
            "Epoch 197/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6162 - mse: 0.6162 - mae: 0.4047\n",
            "Epoch 197: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6180 - mse: 0.6180 - mae: 0.4045 - lr: 1.0000e-05\n",
            "Epoch 198/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6219 - mse: 0.6219 - mae: 0.4073\n",
            "Epoch 198: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6181 - mse: 0.6181 - mae: 0.4062 - lr: 1.0000e-05\n",
            "Epoch 199/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6196 - mse: 0.6196 - mae: 0.4098\n",
            "Epoch 199: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6187 - mse: 0.6187 - mae: 0.4096 - lr: 1.0000e-05\n",
            "Epoch 200/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6098 - mse: 0.6098 - mae: 0.4024\n",
            "Epoch 200: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6180 - mse: 0.6180 - mae: 0.4043 - lr: 1.0000e-05\n",
            "Epoch 201/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6171 - mse: 0.6171 - mae: 0.4071\n",
            "Epoch 201: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6181 - mse: 0.6181 - mae: 0.4058 - lr: 1.0000e-05\n",
            "Epoch 202/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6187 - mse: 0.6187 - mae: 0.4072\n",
            "Epoch 202: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6194 - mse: 0.6194 - mae: 0.4080 - lr: 1.0000e-05\n",
            "Epoch 203/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6150 - mse: 0.6150 - mae: 0.4048\n",
            "Epoch 203: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6174 - mse: 0.6174 - mae: 0.4057 - lr: 1.0000e-05\n",
            "Epoch 204/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6154 - mse: 0.6154 - mae: 0.4059\n",
            "Epoch 204: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6179 - mse: 0.6179 - mae: 0.4053 - lr: 1.0000e-05\n",
            "Epoch 205/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6194 - mse: 0.6194 - mae: 0.4053\n",
            "Epoch 205: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6173 - mse: 0.6173 - mae: 0.4047 - lr: 1.0000e-05\n",
            "Epoch 206/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6196 - mse: 0.6196 - mae: 0.4066\n",
            "Epoch 206: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6179 - mse: 0.6179 - mae: 0.4063 - lr: 1.0000e-05\n",
            "Epoch 207/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6244 - mse: 0.6244 - mae: 0.4107\n",
            "Epoch 207: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6189 - mse: 0.6189 - mae: 0.4088 - lr: 1.0000e-05\n",
            "Epoch 208/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6171 - mse: 0.6171 - mae: 0.4048\n",
            "Epoch 208: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6181 - mse: 0.6181 - mae: 0.4062 - lr: 1.0000e-05\n",
            "Epoch 209/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6208 - mse: 0.6208 - mae: 0.4039\n",
            "Epoch 209: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6179 - mse: 0.6179 - mae: 0.4026 - lr: 1.0000e-05\n",
            "Epoch 210/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6194 - mse: 0.6194 - mae: 0.4081\n",
            "Epoch 210: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6175 - mse: 0.6175 - mae: 0.4088 - lr: 1.0000e-05\n",
            "Epoch 211/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6198 - mse: 0.6198 - mae: 0.4099\n",
            "Epoch 211: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6187 - mse: 0.6187 - mae: 0.4094 - lr: 1.0000e-05\n",
            "Epoch 212/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6229 - mse: 0.6229 - mae: 0.4076\n",
            "Epoch 212: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6179 - mse: 0.6179 - mae: 0.4063 - lr: 1.0000e-05\n",
            "Epoch 213/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6212 - mse: 0.6212 - mae: 0.4057\n",
            "Epoch 213: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6178 - mse: 0.6178 - mae: 0.4041 - lr: 1.0000e-05\n",
            "Epoch 214/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6129 - mse: 0.6129 - mae: 0.4024\n",
            "Epoch 214: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6165 - mse: 0.6165 - mae: 0.4040 - lr: 1.0000e-05\n",
            "Epoch 215/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6141 - mse: 0.6141 - mae: 0.4059\n",
            "Epoch 215: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6182 - mse: 0.6182 - mae: 0.4064 - lr: 1.0000e-05\n",
            "Epoch 216/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6186 - mse: 0.6186 - mae: 0.4092\n",
            "Epoch 216: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6185 - mse: 0.6185 - mae: 0.4093 - lr: 1.0000e-05\n",
            "Epoch 217/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6151 - mse: 0.6151 - mae: 0.4052\n",
            "Epoch 217: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6176 - mse: 0.6176 - mae: 0.4042 - lr: 1.0000e-05\n",
            "Epoch 218/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6127 - mse: 0.6127 - mae: 0.4030\n",
            "Epoch 218: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6169 - mse: 0.6169 - mae: 0.4047 - lr: 1.0000e-05\n",
            "Epoch 219/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6196 - mse: 0.6196 - mae: 0.4066\n",
            "Epoch 219: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6169 - mse: 0.6169 - mae: 0.4064 - lr: 1.0000e-05\n",
            "Epoch 220/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6188 - mse: 0.6188 - mae: 0.4053\n",
            "Epoch 220: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6169 - mse: 0.6169 - mae: 0.4052 - lr: 1.0000e-05\n",
            "Epoch 221/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6209 - mse: 0.6209 - mae: 0.4080\n",
            "Epoch 221: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6182 - mse: 0.6182 - mae: 0.4076 - lr: 1.0000e-05\n",
            "Epoch 222/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6185 - mse: 0.6185 - mae: 0.4093\n",
            "Epoch 222: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6168 - mse: 0.6168 - mae: 0.4090 - lr: 1.0000e-05\n",
            "Epoch 223/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6101 - mse: 0.6101 - mae: 0.4004\n",
            "Epoch 223: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6162 - mse: 0.6162 - mae: 0.4024 - lr: 1.0000e-05\n",
            "Epoch 224/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6189 - mse: 0.6189 - mae: 0.4076\n",
            "Epoch 224: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6175 - mse: 0.6175 - mae: 0.4061 - lr: 1.0000e-05\n",
            "Epoch 225/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6222 - mse: 0.6222 - mae: 0.4066\n",
            "Epoch 225: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6167 - mse: 0.6167 - mae: 0.4056 - lr: 1.0000e-05\n",
            "Epoch 226/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6184 - mse: 0.6184 - mae: 0.4071\n",
            "Epoch 226: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6172 - mse: 0.6172 - mae: 0.4070 - lr: 1.0000e-05\n",
            "Epoch 227/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6165 - mse: 0.6165 - mae: 0.4021\n",
            "Epoch 227: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6159 - mse: 0.6159 - mae: 0.4020 - lr: 1.0000e-05\n",
            "Epoch 228/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6150 - mse: 0.6150 - mae: 0.4030\n",
            "Epoch 228: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6168 - mse: 0.6168 - mae: 0.4033 - lr: 1.0000e-05\n",
            "Epoch 229/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6172 - mse: 0.6172 - mae: 0.4028\n",
            "Epoch 229: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6167 - mse: 0.6167 - mae: 0.4027 - lr: 1.0000e-05\n",
            "Epoch 230/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6229 - mse: 0.6229 - mae: 0.4120\n",
            "Epoch 230: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6180 - mse: 0.6180 - mae: 0.4115 - lr: 1.0000e-05\n",
            "Epoch 231/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6148 - mse: 0.6148 - mae: 0.4031\n",
            "Epoch 231: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6162 - mse: 0.6162 - mae: 0.4037 - lr: 1.0000e-05\n",
            "Epoch 232/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6151 - mse: 0.6151 - mae: 0.4044\n",
            "Epoch 232: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6167 - mse: 0.6167 - mae: 0.4036 - lr: 1.0000e-05\n",
            "Epoch 233/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6171 - mse: 0.6171 - mae: 0.4032\n",
            "Epoch 233: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6166 - mse: 0.6166 - mae: 0.4031 - lr: 1.0000e-05\n",
            "Epoch 234/500\n",
            "151/167 [==========================>...] - ETA: 0s - loss: 0.6106 - mse: 0.6106 - mae: 0.4056\n",
            "Epoch 234: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6163 - mse: 0.6163 - mae: 0.4055 - lr: 1.0000e-05\n",
            "Epoch 235/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6067 - mse: 0.6067 - mae: 0.4005\n",
            "Epoch 235: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6168 - mse: 0.6168 - mae: 0.4034 - lr: 1.0000e-05\n",
            "Epoch 236/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6216 - mse: 0.6216 - mae: 0.4099\n",
            "Epoch 236: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6161 - mse: 0.6161 - mae: 0.4082 - lr: 1.0000e-05\n",
            "Epoch 237/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6084 - mse: 0.6084 - mae: 0.4005\n",
            "Epoch 237: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6158 - mse: 0.6158 - mae: 0.4024 - lr: 1.0000e-05\n",
            "Epoch 238/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6089 - mse: 0.6089 - mae: 0.4031\n",
            "Epoch 238: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6167 - mse: 0.6167 - mae: 0.4057 - lr: 1.0000e-05\n",
            "Epoch 239/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6149 - mse: 0.6149 - mae: 0.4036\n",
            "Epoch 239: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6166 - mse: 0.6166 - mae: 0.4039 - lr: 1.0000e-05\n",
            "Epoch 240/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6158 - mse: 0.6158 - mae: 0.4018\n",
            "Epoch 240: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6156 - mse: 0.6156 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 241/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6181 - mse: 0.6181 - mae: 0.4097\n",
            "Epoch 241: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6178 - mse: 0.6178 - mae: 0.4100 - lr: 1.0000e-05\n",
            "Epoch 242/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6165 - mse: 0.6165 - mae: 0.4048\n",
            "Epoch 242: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6163 - mse: 0.6163 - mae: 0.4046 - lr: 1.0000e-05\n",
            "Epoch 243/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6167 - mse: 0.6167 - mae: 0.4048\n",
            "Epoch 243: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6161 - mse: 0.6161 - mae: 0.4051 - lr: 1.0000e-05\n",
            "Epoch 244/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6187 - mse: 0.6187 - mae: 0.4059\n",
            "Epoch 244: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6165 - mse: 0.6165 - mae: 0.4061 - lr: 1.0000e-05\n",
            "Epoch 245/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6183 - mse: 0.6183 - mae: 0.4043\n",
            "Epoch 245: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6160 - mse: 0.6160 - mae: 0.4040 - lr: 1.0000e-05\n",
            "Epoch 246/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6140 - mse: 0.6140 - mae: 0.4059\n",
            "Epoch 246: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6151 - mse: 0.6151 - mae: 0.4053 - lr: 1.0000e-05\n",
            "Epoch 247/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6156 - mse: 0.6156 - mae: 0.4020\n",
            "Epoch 247: saving model to model_weights.h5\n",
            "167/167 [==============================] - 2s 11ms/step - loss: 0.6149 - mse: 0.6149 - mae: 0.4020 - lr: 1.0000e-05\n",
            "Epoch 248/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6166 - mse: 0.6166 - mae: 0.4024\n",
            "Epoch 248: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 8ms/step - loss: 0.6161 - mse: 0.6161 - mae: 0.4024 - lr: 1.0000e-05\n",
            "Epoch 249/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6163 - mse: 0.6163 - mae: 0.4063\n",
            "Epoch 249: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.6167 - mse: 0.6167 - mae: 0.4067 - lr: 1.0000e-05\n",
            "Epoch 250/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6159 - mse: 0.6159 - mae: 0.4033\n",
            "Epoch 250: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.6153 - mse: 0.6153 - mae: 0.4030 - lr: 1.0000e-05\n",
            "Epoch 251/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6175 - mse: 0.6175 - mae: 0.4036\n",
            "Epoch 251: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 7ms/step - loss: 0.6154 - mse: 0.6154 - mae: 0.4035 - lr: 1.0000e-05\n",
            "Epoch 252/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6038 - mse: 0.6038 - mae: 0.4014\n",
            "Epoch 252: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 0.6155 - mse: 0.6155 - mae: 0.4042 - lr: 1.0000e-05\n",
            "Epoch 253/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6185 - mse: 0.6185 - mae: 0.4047\n",
            "Epoch 253: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6159 - mse: 0.6159 - mae: 0.4046 - lr: 1.0000e-05\n",
            "Epoch 254/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6142 - mse: 0.6142 - mae: 0.4034\n",
            "Epoch 254: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6155 - mse: 0.6155 - mae: 0.4038 - lr: 1.0000e-05\n",
            "Epoch 255/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6146 - mse: 0.6146 - mae: 0.4064\n",
            "Epoch 255: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6157 - mse: 0.6157 - mae: 0.4070 - lr: 1.0000e-05\n",
            "Epoch 256/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6105 - mse: 0.6105 - mae: 0.4049\n",
            "Epoch 256: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6153 - mse: 0.6153 - mae: 0.4051 - lr: 1.0000e-05\n",
            "Epoch 257/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6227 - mse: 0.6227 - mae: 0.4070\n",
            "Epoch 257: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6150 - mse: 0.6150 - mae: 0.4049 - lr: 1.0000e-05\n",
            "Epoch 258/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6154 - mse: 0.6154 - mae: 0.4049\n",
            "Epoch 258: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6157 - mse: 0.6157 - mae: 0.4053 - lr: 1.0000e-05\n",
            "Epoch 259/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6151 - mse: 0.6151 - mae: 0.4027\n",
            "Epoch 259: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6153 - mse: 0.6153 - mae: 0.4024 - lr: 1.0000e-05\n",
            "Epoch 260/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6154 - mse: 0.6154 - mae: 0.4072\n",
            "Epoch 260: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6158 - mse: 0.6158 - mae: 0.4076 - lr: 1.0000e-05\n",
            "Epoch 261/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6178 - mse: 0.6178 - mae: 0.4019\n",
            "Epoch 261: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6147 - mse: 0.6147 - mae: 0.4005 - lr: 1.0000e-05\n",
            "Epoch 262/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6108 - mse: 0.6108 - mae: 0.4039\n",
            "Epoch 262: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6156 - mse: 0.6156 - mae: 0.4063 - lr: 1.0000e-05\n",
            "Epoch 263/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6236 - mse: 0.6236 - mae: 0.4050\n",
            "Epoch 263: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6142 - mse: 0.6142 - mae: 0.4034 - lr: 1.0000e-05\n",
            "Epoch 264/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6152 - mse: 0.6152 - mae: 0.4058\n",
            "Epoch 264: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6152 - mse: 0.6152 - mae: 0.4058 - lr: 1.0000e-05\n",
            "Epoch 265/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6156 - mse: 0.6156 - mae: 0.4024\n",
            "Epoch 265: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6140 - mse: 0.6140 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 266/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.5978 - mse: 0.5978 - mae: 0.3997\n",
            "Epoch 266: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6138 - mse: 0.6138 - mae: 0.4026 - lr: 1.0000e-05\n",
            "Epoch 267/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6216 - mse: 0.6216 - mae: 0.4083\n",
            "Epoch 267: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6145 - mse: 0.6145 - mae: 0.4069 - lr: 1.0000e-05\n",
            "Epoch 268/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6145 - mse: 0.6145 - mae: 0.4064\n",
            "Epoch 268: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6153 - mse: 0.6153 - mae: 0.4055 - lr: 1.0000e-05\n",
            "Epoch 269/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6144 - mse: 0.6144 - mae: 0.4047\n",
            "Epoch 269: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6155 - mse: 0.6155 - mae: 0.4059 - lr: 1.0000e-05\n",
            "Epoch 270/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6126 - mse: 0.6126 - mae: 0.4008\n",
            "Epoch 270: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6143 - mse: 0.6143 - mae: 0.4016 - lr: 1.0000e-05\n",
            "Epoch 271/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6158 - mse: 0.6158 - mae: 0.4035\n",
            "Epoch 271: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6149 - mse: 0.6149 - mae: 0.4034 - lr: 1.0000e-05\n",
            "Epoch 272/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6178 - mse: 0.6178 - mae: 0.4022\n",
            "Epoch 272: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6136 - mse: 0.6136 - mae: 0.4014 - lr: 1.0000e-05\n",
            "Epoch 273/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6136 - mse: 0.6136 - mae: 0.4018\n",
            "Epoch 273: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6138 - mse: 0.6138 - mae: 0.4032 - lr: 1.0000e-05\n",
            "Epoch 274/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6114 - mse: 0.6114 - mae: 0.4019\n",
            "Epoch 274: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6146 - mse: 0.6146 - mae: 0.4026 - lr: 1.0000e-05\n",
            "Epoch 275/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6105 - mse: 0.6105 - mae: 0.4007\n",
            "Epoch 275: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6141 - mse: 0.6141 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 276/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6188 - mse: 0.6188 - mae: 0.4030\n",
            "Epoch 276: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6140 - mse: 0.6140 - mae: 0.4026 - lr: 1.0000e-05\n",
            "Epoch 277/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6044 - mse: 0.6044 - mae: 0.4023\n",
            "Epoch 277: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6147 - mse: 0.6147 - mae: 0.4035 - lr: 1.0000e-05\n",
            "Epoch 278/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6109 - mse: 0.6109 - mae: 0.4016\n",
            "Epoch 278: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6141 - mse: 0.6141 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 279/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6106 - mse: 0.6106 - mae: 0.4015\n",
            "Epoch 279: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6128 - mse: 0.6128 - mae: 0.4016 - lr: 1.0000e-05\n",
            "Epoch 280/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6153 - mse: 0.6153 - mae: 0.4011\n",
            "Epoch 280: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6131 - mse: 0.6131 - mae: 0.4002 - lr: 1.0000e-05\n",
            "Epoch 281/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6110 - mse: 0.6110 - mae: 0.3991\n",
            "Epoch 281: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6134 - mse: 0.6134 - mae: 0.3996 - lr: 1.0000e-05\n",
            "Epoch 282/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6179 - mse: 0.6179 - mae: 0.4075\n",
            "Epoch 282: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6140 - mse: 0.6140 - mae: 0.4052 - lr: 1.0000e-05\n",
            "Epoch 283/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6068 - mse: 0.6068 - mae: 0.4000\n",
            "Epoch 283: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6127 - mse: 0.6127 - mae: 0.4010 - lr: 1.0000e-05\n",
            "Epoch 284/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6150 - mse: 0.6150 - mae: 0.4030\n",
            "Epoch 284: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6142 - mse: 0.6142 - mae: 0.4028 - lr: 1.0000e-05\n",
            "Epoch 285/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6073 - mse: 0.6073 - mae: 0.3995\n",
            "Epoch 285: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6136 - mse: 0.6136 - mae: 0.4011 - lr: 1.0000e-05\n",
            "Epoch 286/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6147 - mse: 0.6147 - mae: 0.4016\n",
            "Epoch 286: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6137 - mse: 0.6137 - mae: 0.4016 - lr: 1.0000e-05\n",
            "Epoch 287/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6095 - mse: 0.6095 - mae: 0.4011\n",
            "Epoch 287: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6135 - mse: 0.6135 - mae: 0.4014 - lr: 1.0000e-05\n",
            "Epoch 288/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6072 - mse: 0.6072 - mae: 0.4058\n",
            "Epoch 288: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6135 - mse: 0.6135 - mae: 0.4060 - lr: 1.0000e-05\n",
            "Epoch 289/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6086 - mse: 0.6086 - mae: 0.4066\n",
            "Epoch 289: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6135 - mse: 0.6135 - mae: 0.4056 - lr: 1.0000e-05\n",
            "Epoch 290/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6119 - mse: 0.6119 - mae: 0.4009\n",
            "Epoch 290: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6125 - mse: 0.6125 - mae: 0.4009 - lr: 1.0000e-05\n",
            "Epoch 291/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6221 - mse: 0.6221 - mae: 0.4061\n",
            "Epoch 291: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6140 - mse: 0.6140 - mae: 0.4038 - lr: 1.0000e-05\n",
            "Epoch 292/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6168 - mse: 0.6168 - mae: 0.4052\n",
            "Epoch 292: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6131 - mse: 0.6131 - mae: 0.4037 - lr: 1.0000e-05\n",
            "Epoch 293/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6169 - mse: 0.6169 - mae: 0.3983\n",
            "Epoch 293: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6122 - mse: 0.6122 - mae: 0.3978 - lr: 1.0000e-05\n",
            "Epoch 294/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6131 - mse: 0.6131 - mae: 0.4032\n",
            "Epoch 294: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6131 - mse: 0.6131 - mae: 0.4032 - lr: 1.0000e-05\n",
            "Epoch 295/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6127 - mse: 0.6127 - mae: 0.4014\n",
            "Epoch 295: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6127 - mse: 0.6127 - mae: 0.4014 - lr: 1.0000e-05\n",
            "Epoch 296/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6133 - mse: 0.6133 - mae: 0.4001\n",
            "Epoch 296: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6121 - mse: 0.6121 - mae: 0.3994 - lr: 1.0000e-05\n",
            "Epoch 297/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6170 - mse: 0.6170 - mae: 0.4030\n",
            "Epoch 297: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6126 - mse: 0.6126 - mae: 0.4019 - lr: 1.0000e-05\n",
            "Epoch 298/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6013 - mse: 0.6013 - mae: 0.3997\n",
            "Epoch 298: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6129 - mse: 0.6129 - mae: 0.4015 - lr: 1.0000e-05\n",
            "Epoch 299/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6017 - mse: 0.6017 - mae: 0.3997\n",
            "Epoch 299: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6130 - mse: 0.6130 - mae: 0.4016 - lr: 1.0000e-05\n",
            "Epoch 300/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6155 - mse: 0.6155 - mae: 0.4046\n",
            "Epoch 300: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6133 - mse: 0.6133 - mae: 0.4039 - lr: 1.0000e-05\n",
            "Epoch 301/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6107 - mse: 0.6107 - mae: 0.4011\n",
            "Epoch 301: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6126 - mse: 0.6126 - mae: 0.4018 - lr: 1.0000e-05\n",
            "Epoch 302/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6131 - mse: 0.6131 - mae: 0.4027\n",
            "Epoch 302: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6122 - mse: 0.6122 - mae: 0.4019 - lr: 1.0000e-05\n",
            "Epoch 303/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6176 - mse: 0.6176 - mae: 0.4037\n",
            "Epoch 303: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6123 - mse: 0.6123 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 304/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6156 - mse: 0.6156 - mae: 0.4053\n",
            "Epoch 304: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6134 - mse: 0.6134 - mae: 0.4052 - lr: 1.0000e-05\n",
            "Epoch 305/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6115 - mse: 0.6115 - mae: 0.4036\n",
            "Epoch 305: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6131 - mse: 0.6131 - mae: 0.4034 - lr: 1.0000e-05\n",
            "Epoch 306/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6250 - mse: 0.6250 - mae: 0.4020\n",
            "Epoch 306: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6120 - mse: 0.6120 - mae: 0.3990 - lr: 1.0000e-05\n",
            "Epoch 307/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6095 - mse: 0.6095 - mae: 0.4013\n",
            "Epoch 307: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6119 - mse: 0.6119 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 308/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6150 - mse: 0.6150 - mae: 0.4037\n",
            "Epoch 308: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6122 - mse: 0.6122 - mae: 0.4038 - lr: 1.0000e-05\n",
            "Epoch 309/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6223 - mse: 0.6223 - mae: 0.4022\n",
            "Epoch 309: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6116 - mse: 0.6116 - mae: 0.3989 - lr: 1.0000e-05\n",
            "Epoch 310/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6046 - mse: 0.6046 - mae: 0.4007\n",
            "Epoch 310: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6119 - mse: 0.6119 - mae: 0.4023 - lr: 1.0000e-05\n",
            "Epoch 311/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6158 - mse: 0.6158 - mae: 0.4036\n",
            "Epoch 311: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6123 - mse: 0.6123 - mae: 0.4024 - lr: 1.0000e-05\n",
            "Epoch 312/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6112 - mse: 0.6112 - mae: 0.4007\n",
            "Epoch 312: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6112 - mse: 0.6112 - mae: 0.4007 - lr: 1.0000e-05\n",
            "Epoch 313/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6125 - mse: 0.6125 - mae: 0.4083\n",
            "Epoch 313: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6125 - mse: 0.6125 - mae: 0.4083 - lr: 1.0000e-05\n",
            "Epoch 314/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.5971 - mse: 0.5971 - mae: 0.3945\n",
            "Epoch 314: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6114 - mse: 0.6114 - mae: 0.3982 - lr: 1.0000e-05\n",
            "Epoch 315/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6124 - mse: 0.6124 - mae: 0.4011\n",
            "Epoch 315: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6117 - mse: 0.6117 - mae: 0.4011 - lr: 1.0000e-05\n",
            "Epoch 316/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.5961 - mse: 0.5961 - mae: 0.3989\n",
            "Epoch 316: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6121 - mse: 0.6121 - mae: 0.4018 - lr: 1.0000e-05\n",
            "Epoch 317/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6150 - mse: 0.6150 - mae: 0.4062\n",
            "Epoch 317: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6127 - mse: 0.6127 - mae: 0.4053 - lr: 1.0000e-05\n",
            "Epoch 318/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6083 - mse: 0.6083 - mae: 0.4002\n",
            "Epoch 318: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6123 - mse: 0.6123 - mae: 0.4014 - lr: 1.0000e-05\n",
            "Epoch 319/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6118 - mse: 0.6118 - mae: 0.4018\n",
            "Epoch 319: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6122 - mse: 0.6122 - mae: 0.4016 - lr: 1.0000e-05\n",
            "Epoch 320/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6083 - mse: 0.6083 - mae: 0.3989\n",
            "Epoch 320: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6109 - mse: 0.6109 - mae: 0.4003 - lr: 1.0000e-05\n",
            "Epoch 321/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6221 - mse: 0.6221 - mae: 0.4029\n",
            "Epoch 321: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6119 - mse: 0.6119 - mae: 0.4011 - lr: 1.0000e-05\n",
            "Epoch 322/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6105 - mse: 0.6105 - mae: 0.4003\n",
            "Epoch 322: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6105 - mse: 0.6105 - mae: 0.4003 - lr: 1.0000e-05\n",
            "Epoch 323/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6152 - mse: 0.6152 - mae: 0.4023\n",
            "Epoch 323: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6112 - mse: 0.6112 - mae: 0.4012 - lr: 1.0000e-05\n",
            "Epoch 324/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6168 - mse: 0.6168 - mae: 0.4041\n",
            "Epoch 324: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6115 - mse: 0.6115 - mae: 0.4027 - lr: 1.0000e-05\n",
            "Epoch 325/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6177 - mse: 0.6177 - mae: 0.4011\n",
            "Epoch 325: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6108 - mse: 0.6108 - mae: 0.3994 - lr: 1.0000e-05\n",
            "Epoch 326/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6008 - mse: 0.6008 - mae: 0.3950\n",
            "Epoch 326: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6099 - mse: 0.6099 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 327/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6061 - mse: 0.6061 - mae: 0.3994\n",
            "Epoch 327: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6102 - mse: 0.6102 - mae: 0.3998 - lr: 1.0000e-05\n",
            "Epoch 328/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6077 - mse: 0.6077 - mae: 0.3995\n",
            "Epoch 328: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6110 - mse: 0.6110 - mae: 0.4000 - lr: 1.0000e-05\n",
            "Epoch 329/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6131 - mse: 0.6131 - mae: 0.4032\n",
            "Epoch 329: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6117 - mse: 0.6117 - mae: 0.4028 - lr: 1.0000e-05\n",
            "Epoch 330/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6136 - mse: 0.6136 - mae: 0.4031\n",
            "Epoch 330: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6113 - mse: 0.6113 - mae: 0.4028 - lr: 1.0000e-05\n",
            "Epoch 331/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6050 - mse: 0.6050 - mae: 0.3987\n",
            "Epoch 331: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6106 - mse: 0.6106 - mae: 0.4001 - lr: 1.0000e-05\n",
            "Epoch 332/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6109 - mse: 0.6109 - mae: 0.4006\n",
            "Epoch 332: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6105 - mse: 0.6105 - mae: 0.3998 - lr: 1.0000e-05\n",
            "Epoch 333/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6047 - mse: 0.6047 - mae: 0.3987\n",
            "Epoch 333: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6109 - mse: 0.6109 - mae: 0.3997 - lr: 1.0000e-05\n",
            "Epoch 334/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6090 - mse: 0.6090 - mae: 0.3975\n",
            "Epoch 334: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6101 - mse: 0.6101 - mae: 0.3977 - lr: 1.0000e-05\n",
            "Epoch 335/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.5968 - mse: 0.5968 - mae: 0.3992\n",
            "Epoch 335: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6105 - mse: 0.6105 - mae: 0.4026 - lr: 1.0000e-05\n",
            "Epoch 336/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.3985\n",
            "Epoch 336: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6104 - mse: 0.6104 - mae: 0.3995 - lr: 1.0000e-05\n",
            "Epoch 337/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6068 - mse: 0.6068 - mae: 0.3972\n",
            "Epoch 337: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6098 - mse: 0.6098 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 338/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6096 - mse: 0.6096 - mae: 0.4013\n",
            "Epoch 338: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6106 - mse: 0.6106 - mae: 0.4025 - lr: 1.0000e-05\n",
            "Epoch 339/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6125 - mse: 0.6125 - mae: 0.4035\n",
            "Epoch 339: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6106 - mse: 0.6106 - mae: 0.4018 - lr: 1.0000e-05\n",
            "Epoch 340/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6024 - mse: 0.6024 - mae: 0.3994\n",
            "Epoch 340: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6107 - mse: 0.6107 - mae: 0.4013 - lr: 1.0000e-05\n",
            "Epoch 341/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6090 - mse: 0.6090 - mae: 0.4053\n",
            "Epoch 341: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6110 - mse: 0.6110 - mae: 0.4048 - lr: 1.0000e-05\n",
            "Epoch 342/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6120 - mse: 0.6120 - mae: 0.4005\n",
            "Epoch 342: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6103 - mse: 0.6103 - mae: 0.3991 - lr: 1.0000e-05\n",
            "Epoch 343/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.5984 - mse: 0.5984 - mae: 0.3981\n",
            "Epoch 343: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6098 - mse: 0.6098 - mae: 0.4003 - lr: 1.0000e-05\n",
            "Epoch 344/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6074 - mse: 0.6074 - mae: 0.4015\n",
            "Epoch 344: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6126 - mse: 0.6126 - mae: 0.4038 - lr: 1.0000e-05\n",
            "Epoch 345/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6089 - mse: 0.6089 - mae: 0.4004\n",
            "Epoch 345: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6106 - mse: 0.6106 - mae: 0.4011 - lr: 1.0000e-05\n",
            "Epoch 346/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6088 - mse: 0.6088 - mae: 0.3985\n",
            "Epoch 346: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6092 - mse: 0.6092 - mae: 0.3984 - lr: 1.0000e-05\n",
            "Epoch 347/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6132 - mse: 0.6132 - mae: 0.4005\n",
            "Epoch 347: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6095 - mse: 0.6095 - mae: 0.4007 - lr: 1.0000e-05\n",
            "Epoch 348/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6084 - mse: 0.6084 - mae: 0.3979\n",
            "Epoch 348: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6088 - mse: 0.6088 - mae: 0.3973 - lr: 1.0000e-05\n",
            "Epoch 349/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6084 - mse: 0.6084 - mae: 0.3992\n",
            "Epoch 349: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6094 - mse: 0.6094 - mae: 0.3992 - lr: 1.0000e-05\n",
            "Epoch 350/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6145 - mse: 0.6145 - mae: 0.3994\n",
            "Epoch 350: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6097 - mse: 0.6097 - mae: 0.3977 - lr: 1.0000e-05\n",
            "Epoch 351/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6077 - mse: 0.6077 - mae: 0.3987\n",
            "Epoch 351: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6092 - mse: 0.6092 - mae: 0.3984 - lr: 1.0000e-05\n",
            "Epoch 352/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6061 - mse: 0.6061 - mae: 0.4032\n",
            "Epoch 352: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6109 - mse: 0.6109 - mae: 0.4030 - lr: 1.0000e-05\n",
            "Epoch 353/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.5993 - mse: 0.5993 - mae: 0.3975\n",
            "Epoch 353: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6093 - mse: 0.6093 - mae: 0.4004 - lr: 1.0000e-05\n",
            "Epoch 354/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.4013\n",
            "Epoch 354: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6104 - mse: 0.6104 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 355/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6175 - mse: 0.6175 - mae: 0.3997\n",
            "Epoch 355: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6086 - mse: 0.6086 - mae: 0.3977 - lr: 1.0000e-05\n",
            "Epoch 356/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6113 - mse: 0.6113 - mae: 0.4002\n",
            "Epoch 356: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6089 - mse: 0.6089 - mae: 0.3987 - lr: 1.0000e-05\n",
            "Epoch 357/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6070 - mse: 0.6070 - mae: 0.3988\n",
            "Epoch 357: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6090 - mse: 0.6090 - mae: 0.3990 - lr: 1.0000e-05\n",
            "Epoch 358/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6111 - mse: 0.6111 - mae: 0.4001\n",
            "Epoch 358: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6103 - mse: 0.6103 - mae: 0.3996 - lr: 1.0000e-05\n",
            "Epoch 359/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6122 - mse: 0.6122 - mae: 0.4023\n",
            "Epoch 359: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6089 - mse: 0.6089 - mae: 0.4007 - lr: 1.0000e-05\n",
            "Epoch 360/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.5963 - mse: 0.5963 - mae: 0.3976\n",
            "Epoch 360: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6092 - mse: 0.6092 - mae: 0.3999 - lr: 1.0000e-05\n",
            "Epoch 361/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.3994\n",
            "Epoch 361: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6093 - mse: 0.6093 - mae: 0.4005 - lr: 1.0000e-05\n",
            "Epoch 362/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6058 - mse: 0.6058 - mae: 0.3982\n",
            "Epoch 362: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6075 - mae: 0.3986 - lr: 1.0000e-05\n",
            "Epoch 363/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6129 - mse: 0.6129 - mae: 0.3981\n",
            "Epoch 363: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6092 - mse: 0.6092 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 364/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6077 - mse: 0.6077 - mae: 0.3982\n",
            "Epoch 364: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6081 - mse: 0.6081 - mae: 0.3981 - lr: 1.0000e-05\n",
            "Epoch 365/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6073 - mse: 0.6073 - mae: 0.3963\n",
            "Epoch 365: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6079 - mse: 0.6079 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 366/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6119 - mse: 0.6119 - mae: 0.4000\n",
            "Epoch 366: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6091 - mse: 0.6091 - mae: 0.3992 - lr: 1.0000e-05\n",
            "Epoch 367/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6038 - mse: 0.6038 - mae: 0.3985\n",
            "Epoch 367: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6081 - mse: 0.6081 - mae: 0.3998 - lr: 1.0000e-05\n",
            "Epoch 368/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6061 - mse: 0.6061 - mae: 0.3971\n",
            "Epoch 368: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6093 - mse: 0.6093 - mae: 0.3980 - lr: 1.0000e-05\n",
            "Epoch 369/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6180 - mse: 0.6180 - mae: 0.3985\n",
            "Epoch 369: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6079 - mse: 0.6079 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 370/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6108 - mse: 0.6108 - mae: 0.4024\n",
            "Epoch 370: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6091 - mse: 0.6091 - mae: 0.4023 - lr: 1.0000e-05\n",
            "Epoch 371/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6014 - mse: 0.6014 - mae: 0.3973\n",
            "Epoch 371: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6091 - mse: 0.6091 - mae: 0.3999 - lr: 1.0000e-05\n",
            "Epoch 372/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6136 - mse: 0.6136 - mae: 0.4016\n",
            "Epoch 372: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6088 - mse: 0.6088 - mae: 0.4012 - lr: 1.0000e-05\n",
            "Epoch 373/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.5984 - mse: 0.5984 - mae: 0.3959\n",
            "Epoch 373: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6083 - mse: 0.6083 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 374/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6222 - mse: 0.6222 - mae: 0.4014\n",
            "Epoch 374: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6080 - mse: 0.6080 - mae: 0.3983 - lr: 1.0000e-05\n",
            "Epoch 375/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6084 - mse: 0.6084 - mae: 0.4016\n",
            "Epoch 375: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6079 - mse: 0.6079 - mae: 0.4006 - lr: 1.0000e-05\n",
            "Epoch 376/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6065 - mse: 0.6065 - mae: 0.4014\n",
            "Epoch 376: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6084 - mse: 0.6084 - mae: 0.4017 - lr: 1.0000e-05\n",
            "Epoch 377/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6112 - mse: 0.6112 - mae: 0.3993\n",
            "Epoch 377: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6087 - mse: 0.6087 - mae: 0.3995 - lr: 1.0000e-05\n",
            "Epoch 378/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6054 - mse: 0.6054 - mae: 0.4009\n",
            "Epoch 378: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6080 - mse: 0.6080 - mae: 0.4003 - lr: 1.0000e-05\n",
            "Epoch 379/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6100 - mse: 0.6100 - mae: 0.3985\n",
            "Epoch 379: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6084 - mse: 0.6084 - mae: 0.3980 - lr: 1.0000e-05\n",
            "Epoch 380/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6081 - mse: 0.6081 - mae: 0.3999\n",
            "Epoch 380: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6081 - mse: 0.6081 - mae: 0.3999 - lr: 1.0000e-05\n",
            "Epoch 381/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6064 - mse: 0.6064 - mae: 0.3950\n",
            "Epoch 381: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6078 - mse: 0.6078 - mae: 0.3957 - lr: 1.0000e-05\n",
            "Epoch 382/500\n",
            "152/167 [==========================>...] - ETA: 0s - loss: 0.6112 - mse: 0.6112 - mae: 0.3981\n",
            "Epoch 382: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6081 - mse: 0.6081 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 383/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6097 - mse: 0.6097 - mae: 0.3980\n",
            "Epoch 383: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6073 - mse: 0.6073 - mae: 0.3977 - lr: 1.0000e-05\n",
            "Epoch 384/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.4004\n",
            "Epoch 384: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6081 - mse: 0.6081 - mae: 0.4005 - lr: 1.0000e-05\n",
            "Epoch 385/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6078 - mse: 0.6078 - mae: 0.3979\n",
            "Epoch 385: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6080 - mse: 0.6080 - mae: 0.3981 - lr: 1.0000e-05\n",
            "Epoch 386/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6080 - mse: 0.6080 - mae: 0.3959\n",
            "Epoch 386: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6071 - mse: 0.6071 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 387/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6073 - mse: 0.6073 - mae: 0.3987\n",
            "Epoch 387: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6073 - mse: 0.6073 - mae: 0.3987 - lr: 1.0000e-05\n",
            "Epoch 388/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6004 - mse: 0.6004 - mae: 0.3975\n",
            "Epoch 388: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6075 - mae: 0.3998 - lr: 1.0000e-05\n",
            "Epoch 389/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6082 - mse: 0.6082 - mae: 0.3973\n",
            "Epoch 389: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6069 - mse: 0.6069 - mae: 0.3960 - lr: 1.0000e-05\n",
            "Epoch 390/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6044 - mse: 0.6044 - mae: 0.3987\n",
            "Epoch 390: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6070 - mse: 0.6070 - mae: 0.3990 - lr: 1.0000e-05\n",
            "Epoch 391/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6147 - mse: 0.6147 - mae: 0.3965\n",
            "Epoch 391: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6075 - mse: 0.6075 - mae: 0.3953 - lr: 1.0000e-05\n",
            "Epoch 392/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6103 - mse: 0.6103 - mae: 0.3985\n",
            "Epoch 392: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6071 - mse: 0.6071 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 393/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6070 - mse: 0.6070 - mae: 0.3984\n",
            "Epoch 393: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6070 - mse: 0.6070 - mae: 0.3984 - lr: 1.0000e-05\n",
            "Epoch 394/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6129 - mse: 0.6129 - mae: 0.4045\n",
            "Epoch 394: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6088 - mse: 0.6088 - mae: 0.4037 - lr: 1.0000e-05\n",
            "Epoch 395/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6068 - mse: 0.6068 - mae: 0.3977\n",
            "Epoch 395: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6068 - mse: 0.6068 - mae: 0.3977 - lr: 1.0000e-05\n",
            "Epoch 396/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6027 - mse: 0.6027 - mae: 0.3959\n",
            "Epoch 396: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6061 - mse: 0.6061 - mae: 0.3967 - lr: 1.0000e-05\n",
            "Epoch 397/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6064 - mse: 0.6064 - mae: 0.3982\n",
            "Epoch 397: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6072 - mse: 0.6072 - mae: 0.3980 - lr: 1.0000e-05\n",
            "Epoch 398/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.5985 - mse: 0.5985 - mae: 0.3953\n",
            "Epoch 398: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6072 - mse: 0.6072 - mae: 0.3976 - lr: 1.0000e-05\n",
            "Epoch 399/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.5987 - mse: 0.5987 - mae: 0.3948\n",
            "Epoch 399: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6072 - mse: 0.6072 - mae: 0.3963 - lr: 1.0000e-05\n",
            "Epoch 400/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.3983\n",
            "Epoch 400: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6063 - mse: 0.6063 - mae: 0.3983 - lr: 1.0000e-05\n",
            "Epoch 401/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.5948 - mse: 0.5948 - mae: 0.3963\n",
            "Epoch 401: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6069 - mse: 0.6069 - mae: 0.3982 - lr: 1.0000e-05\n",
            "Epoch 402/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6047 - mse: 0.6047 - mae: 0.3963\n",
            "Epoch 402: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6067 - mse: 0.6067 - mae: 0.3975 - lr: 1.0000e-05\n",
            "Epoch 403/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6101 - mse: 0.6101 - mae: 0.3989\n",
            "Epoch 403: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6072 - mse: 0.6072 - mae: 0.3974 - lr: 1.0000e-05\n",
            "Epoch 404/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6085 - mse: 0.6085 - mae: 0.3976\n",
            "Epoch 404: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6068 - mse: 0.6068 - mae: 0.3972 - lr: 1.0000e-05\n",
            "Epoch 405/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6048 - mse: 0.6048 - mae: 0.3955\n",
            "Epoch 405: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6067 - mse: 0.6067 - mae: 0.3958 - lr: 1.0000e-05\n",
            "Epoch 406/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6154 - mse: 0.6154 - mae: 0.3987\n",
            "Epoch 406: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6064 - mse: 0.6064 - mae: 0.3973 - lr: 1.0000e-05\n",
            "Epoch 407/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6136 - mse: 0.6136 - mae: 0.3996\n",
            "Epoch 407: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6069 - mse: 0.6069 - mae: 0.3981 - lr: 1.0000e-05\n",
            "Epoch 408/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6070 - mse: 0.6070 - mae: 0.3983\n",
            "Epoch 408: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6070 - mse: 0.6070 - mae: 0.3983 - lr: 1.0000e-05\n",
            "Epoch 409/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6059 - mse: 0.6059 - mae: 0.3967\n",
            "Epoch 409: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6066 - mse: 0.6066 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 410/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6123 - mse: 0.6123 - mae: 0.4000\n",
            "Epoch 410: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6062 - mse: 0.6062 - mae: 0.3980 - lr: 1.0000e-05\n",
            "Epoch 411/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6185 - mse: 0.6185 - mae: 0.4055\n",
            "Epoch 411: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6075 - mse: 0.6075 - mae: 0.4028 - lr: 1.0000e-05\n",
            "Epoch 412/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6133 - mse: 0.6133 - mae: 0.4028\n",
            "Epoch 412: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6064 - mse: 0.6064 - mae: 0.4023 - lr: 1.0000e-05\n",
            "Epoch 413/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6000 - mse: 0.6000 - mae: 0.3944\n",
            "Epoch 413: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6069 - mse: 0.6069 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 414/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.3954\n",
            "Epoch 414: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6063 - mse: 0.6063 - mae: 0.3954 - lr: 1.0000e-05\n",
            "Epoch 415/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.3952\n",
            "Epoch 415: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6061 - mse: 0.6061 - mae: 0.3960 - lr: 1.0000e-05\n",
            "Epoch 416/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6027 - mse: 0.6027 - mae: 0.3984\n",
            "Epoch 416: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6059 - mse: 0.6059 - mae: 0.3988 - lr: 1.0000e-05\n",
            "Epoch 417/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6055 - mse: 0.6055 - mae: 0.3981\n",
            "Epoch 417: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6055 - mse: 0.6055 - mae: 0.3981 - lr: 1.0000e-05\n",
            "Epoch 418/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6028 - mse: 0.6028 - mae: 0.3948\n",
            "Epoch 418: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6057 - mse: 0.6057 - mae: 0.3946 - lr: 1.0000e-05\n",
            "Epoch 419/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6086 - mse: 0.6086 - mae: 0.4032\n",
            "Epoch 419: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6075 - mse: 0.6075 - mae: 0.4028 - lr: 1.0000e-05\n",
            "Epoch 420/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6015 - mse: 0.6015 - mae: 0.3955\n",
            "Epoch 420: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6060 - mse: 0.6060 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 421/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6068 - mse: 0.6068 - mae: 0.3967\n",
            "Epoch 421: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6057 - mse: 0.6057 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 422/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.3971\n",
            "Epoch 422: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6056 - mse: 0.6056 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 423/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6049 - mse: 0.6049 - mae: 0.3941\n",
            "Epoch 423: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6055 - mse: 0.6055 - mae: 0.3945 - lr: 1.0000e-05\n",
            "Epoch 424/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6053 - mse: 0.6053 - mae: 0.3957\n",
            "Epoch 424: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6047 - mse: 0.6047 - mae: 0.3955 - lr: 1.0000e-05\n",
            "Epoch 425/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6070 - mse: 0.6070 - mae: 0.3999\n",
            "Epoch 425: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6070 - mse: 0.6070 - mae: 0.3999 - lr: 1.0000e-05\n",
            "Epoch 426/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6005 - mse: 0.6005 - mae: 0.3995\n",
            "Epoch 426: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6064 - mse: 0.6064 - mae: 0.3989 - lr: 1.0000e-05\n",
            "Epoch 427/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6060 - mse: 0.6060 - mae: 0.3970\n",
            "Epoch 427: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6056 - mse: 0.6056 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 428/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6090 - mse: 0.6090 - mae: 0.3988\n",
            "Epoch 428: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6057 - mse: 0.6057 - mae: 0.3975 - lr: 1.0000e-05\n",
            "Epoch 429/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6052 - mse: 0.6052 - mae: 0.3968\n",
            "Epoch 429: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6063 - mse: 0.6063 - mae: 0.3975 - lr: 1.0000e-05\n",
            "Epoch 430/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.5999 - mse: 0.5999 - mae: 0.3936\n",
            "Epoch 430: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6042 - mse: 0.6042 - mae: 0.3947 - lr: 1.0000e-05\n",
            "Epoch 431/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6108 - mse: 0.6108 - mae: 0.3999\n",
            "Epoch 431: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6059 - mse: 0.6059 - mae: 0.3985 - lr: 1.0000e-05\n",
            "Epoch 432/500\n",
            "154/167 [==========================>...] - ETA: 0s - loss: 0.6105 - mse: 0.6105 - mae: 0.3962\n",
            "Epoch 432: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6055 - mse: 0.6055 - mae: 0.3958 - lr: 1.0000e-05\n",
            "Epoch 433/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6062 - mse: 0.6062 - mae: 0.3973\n",
            "Epoch 433: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6058 - mse: 0.6058 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 434/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.5949 - mse: 0.5949 - mae: 0.3953\n",
            "Epoch 434: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6050 - mse: 0.6050 - mae: 0.3972 - lr: 1.0000e-05\n",
            "Epoch 435/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6090 - mse: 0.6090 - mae: 0.3950\n",
            "Epoch 435: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6048 - mse: 0.6048 - mae: 0.3942 - lr: 1.0000e-05\n",
            "Epoch 436/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.5958 - mse: 0.5958 - mae: 0.3965\n",
            "Epoch 436: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6064 - mse: 0.6064 - mae: 0.3991 - lr: 1.0000e-05\n",
            "Epoch 437/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.5943 - mse: 0.5943 - mae: 0.3982\n",
            "Epoch 437: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6059 - mse: 0.6059 - mae: 0.4009 - lr: 1.0000e-05\n",
            "Epoch 438/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6010 - mse: 0.6010 - mae: 0.3927\n",
            "Epoch 438: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6039 - mse: 0.6039 - mae: 0.3951 - lr: 1.0000e-05\n",
            "Epoch 439/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6075 - mse: 0.6075 - mae: 0.3973\n",
            "Epoch 439: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6047 - mse: 0.6047 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 440/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6057 - mse: 0.6057 - mae: 0.3966\n",
            "Epoch 440: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6039 - mse: 0.6039 - mae: 0.3971 - lr: 1.0000e-05\n",
            "Epoch 441/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6031 - mse: 0.6031 - mae: 0.4011\n",
            "Epoch 441: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6060 - mse: 0.6060 - mae: 0.4014 - lr: 1.0000e-05\n",
            "Epoch 442/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6013 - mse: 0.6013 - mae: 0.3997\n",
            "Epoch 442: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6052 - mse: 0.6052 - mae: 0.4005 - lr: 1.0000e-05\n",
            "Epoch 443/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.5987 - mse: 0.5987 - mae: 0.3920\n",
            "Epoch 443: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6047 - mse: 0.6047 - mae: 0.3960 - lr: 1.0000e-05\n",
            "Epoch 444/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6031 - mse: 0.6031 - mae: 0.3963\n",
            "Epoch 444: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6050 - mse: 0.6050 - mae: 0.3959 - lr: 1.0000e-05\n",
            "Epoch 445/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.3979\n",
            "Epoch 445: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6042 - mse: 0.6042 - mae: 0.3973 - lr: 1.0000e-05\n",
            "Epoch 446/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.5981 - mse: 0.5981 - mae: 0.3930\n",
            "Epoch 446: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6043 - mse: 0.6043 - mae: 0.3952 - lr: 1.0000e-05\n",
            "Epoch 447/500\n",
            "164/167 [============================>.] - ETA: 0s - loss: 0.6089 - mse: 0.6089 - mae: 0.3965\n",
            "Epoch 447: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6049 - mse: 0.6049 - mae: 0.3954 - lr: 1.0000e-05\n",
            "Epoch 448/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6040 - mse: 0.6040 - mae: 0.3981\n",
            "Epoch 448: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6053 - mse: 0.6053 - mae: 0.3982 - lr: 1.0000e-05\n",
            "Epoch 449/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6087 - mse: 0.6087 - mae: 0.3941\n",
            "Epoch 449: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6041 - mse: 0.6041 - mae: 0.3937 - lr: 1.0000e-05\n",
            "Epoch 450/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6042 - mse: 0.6042 - mae: 0.3926\n",
            "Epoch 450: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6042 - mse: 0.6042 - mae: 0.3926 - lr: 1.0000e-05\n",
            "Epoch 451/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6034 - mse: 0.6034 - mae: 0.3959\n",
            "Epoch 451: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6039 - mse: 0.6039 - mae: 0.3968 - lr: 1.0000e-05\n",
            "Epoch 452/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.5988 - mse: 0.5988 - mae: 0.3951\n",
            "Epoch 452: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6045 - mse: 0.6045 - mae: 0.3958 - lr: 1.0000e-05\n",
            "Epoch 453/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6048 - mse: 0.6048 - mae: 0.3986\n",
            "Epoch 453: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6044 - mse: 0.6044 - mae: 0.3983 - lr: 1.0000e-05\n",
            "Epoch 454/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6063 - mse: 0.6063 - mae: 0.3924\n",
            "Epoch 454: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6046 - mse: 0.6046 - mae: 0.3923 - lr: 1.0000e-05\n",
            "Epoch 455/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6015 - mse: 0.6015 - mae: 0.3975\n",
            "Epoch 455: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6038 - mse: 0.6038 - mae: 0.3978 - lr: 1.0000e-05\n",
            "Epoch 456/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6060 - mse: 0.6060 - mae: 0.3984\n",
            "Epoch 456: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6045 - mse: 0.6045 - mae: 0.3986 - lr: 1.0000e-05\n",
            "Epoch 457/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6084 - mse: 0.6084 - mae: 0.3993\n",
            "Epoch 457: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6036 - mse: 0.6036 - mae: 0.3972 - lr: 1.0000e-05\n",
            "Epoch 458/500\n",
            "156/167 [===========================>..] - ETA: 0s - loss: 0.6023 - mse: 0.6023 - mae: 0.3983\n",
            "Epoch 458: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6036 - mse: 0.6036 - mae: 0.3988 - lr: 1.0000e-05\n",
            "Epoch 459/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6068 - mse: 0.6068 - mae: 0.3981\n",
            "Epoch 459: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6042 - mse: 0.6042 - mae: 0.3969 - lr: 1.0000e-05\n",
            "Epoch 460/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6021 - mse: 0.6021 - mae: 0.3959\n",
            "Epoch 460: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6034 - mse: 0.6034 - mae: 0.3967 - lr: 1.0000e-05\n",
            "Epoch 461/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6087 - mse: 0.6087 - mae: 0.3978\n",
            "Epoch 461: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6035 - mse: 0.6035 - mae: 0.3964 - lr: 1.0000e-05\n",
            "Epoch 462/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6048 - mse: 0.6048 - mae: 0.3963\n",
            "Epoch 462: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6041 - mse: 0.6041 - mae: 0.3962 - lr: 1.0000e-05\n",
            "Epoch 463/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6014 - mse: 0.6014 - mae: 0.3934\n",
            "Epoch 463: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6035 - mse: 0.6035 - mae: 0.3942 - lr: 1.0000e-05\n",
            "Epoch 464/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6039 - mse: 0.6039 - mae: 0.3928\n",
            "Epoch 464: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6031 - mse: 0.6031 - mae: 0.3924 - lr: 1.0000e-05\n",
            "Epoch 465/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6053 - mse: 0.6053 - mae: 0.3963\n",
            "Epoch 465: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6034 - mse: 0.6034 - mae: 0.3954 - lr: 1.0000e-05\n",
            "Epoch 466/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6021 - mse: 0.6021 - mae: 0.3977\n",
            "Epoch 466: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6035 - mse: 0.6035 - mae: 0.3990 - lr: 1.0000e-05\n",
            "Epoch 467/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6057 - mse: 0.6057 - mae: 0.3963\n",
            "Epoch 467: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6021 - mse: 0.6021 - mae: 0.3959 - lr: 1.0000e-05\n",
            "Epoch 468/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.5917 - mse: 0.5917 - mae: 0.3948\n",
            "Epoch 468: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6036 - mse: 0.6036 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 469/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6017 - mse: 0.6017 - mae: 0.3937\n",
            "Epoch 469: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6025 - mse: 0.6025 - mae: 0.3946 - lr: 1.0000e-05\n",
            "Epoch 470/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6076 - mse: 0.6076 - mae: 0.3958\n",
            "Epoch 470: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6034 - mse: 0.6034 - mae: 0.3951 - lr: 1.0000e-05\n",
            "Epoch 471/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6056 - mse: 0.6056 - mae: 0.3964\n",
            "Epoch 471: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6028 - mse: 0.6028 - mae: 0.3953 - lr: 1.0000e-05\n",
            "Epoch 472/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6093 - mse: 0.6093 - mae: 0.3939\n",
            "Epoch 472: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6027 - mse: 0.6027 - mae: 0.3925 - lr: 1.0000e-05\n",
            "Epoch 473/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.6093 - mse: 0.6093 - mae: 0.3957\n",
            "Epoch 473: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6029 - mse: 0.6029 - mae: 0.3943 - lr: 1.0000e-05\n",
            "Epoch 474/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6051 - mse: 0.6051 - mae: 0.3981\n",
            "Epoch 474: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6052 - mse: 0.6052 - mae: 0.3991 - lr: 1.0000e-05\n",
            "Epoch 475/500\n",
            "159/167 [===========================>..] - ETA: 0s - loss: 0.6037 - mse: 0.6037 - mae: 0.3956\n",
            "Epoch 475: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6024 - mse: 0.6024 - mae: 0.3961 - lr: 1.0000e-05\n",
            "Epoch 476/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6027 - mse: 0.6027 - mae: 0.3967\n",
            "Epoch 476: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6027 - mse: 0.6027 - mae: 0.3967 - lr: 1.0000e-05\n",
            "Epoch 477/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6032 - mse: 0.6032 - mae: 0.3928\n",
            "Epoch 477: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6032 - mse: 0.6032 - mae: 0.3928 - lr: 1.0000e-05\n",
            "Epoch 478/500\n",
            "161/167 [===========================>..] - ETA: 0s - loss: 0.6069 - mse: 0.6069 - mae: 0.3946\n",
            "Epoch 478: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6022 - mse: 0.6022 - mae: 0.3930 - lr: 1.0000e-05\n",
            "Epoch 479/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6076 - mse: 0.6076 - mae: 0.3970\n",
            "Epoch 479: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6028 - mse: 0.6028 - mae: 0.3967 - lr: 1.0000e-05\n",
            "Epoch 480/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.5997 - mse: 0.5997 - mae: 0.3951\n",
            "Epoch 480: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6030 - mse: 0.6030 - mae: 0.3972 - lr: 1.0000e-05\n",
            "Epoch 481/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6021 - mse: 0.6021 - mae: 0.3995\n",
            "Epoch 481: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6034 - mse: 0.6034 - mae: 0.3991 - lr: 1.0000e-05\n",
            "Epoch 482/500\n",
            "157/167 [===========================>..] - ETA: 0s - loss: 0.6101 - mse: 0.6101 - mae: 0.3964\n",
            "Epoch 482: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6032 - mse: 0.6032 - mae: 0.3944 - lr: 1.0000e-05\n",
            "Epoch 483/500\n",
            "167/167 [==============================] - ETA: 0s - loss: 0.6022 - mse: 0.6022 - mae: 0.3924\n",
            "Epoch 483: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6022 - mse: 0.6022 - mae: 0.3924 - lr: 1.0000e-05\n",
            "Epoch 484/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6028 - mse: 0.6028 - mae: 0.3909\n",
            "Epoch 484: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6015 - mse: 0.6015 - mae: 0.3910 - lr: 1.0000e-05\n",
            "Epoch 485/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6035 - mse: 0.6035 - mae: 0.3939\n",
            "Epoch 485: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6016 - mse: 0.6016 - mae: 0.3936 - lr: 1.0000e-05\n",
            "Epoch 486/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6033 - mse: 0.6033 - mae: 0.3946\n",
            "Epoch 486: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6024 - mse: 0.6024 - mae: 0.3945 - lr: 1.0000e-05\n",
            "Epoch 487/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6016 - mse: 0.6016 - mae: 0.3943\n",
            "Epoch 487: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 0.6019 - mse: 0.6019 - mae: 0.3937 - lr: 1.0000e-05\n",
            "Epoch 488/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6029 - mse: 0.6029 - mae: 0.3930\n",
            "Epoch 488: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6021 - mse: 0.6021 - mae: 0.3929 - lr: 1.0000e-05\n",
            "Epoch 489/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.5979 - mse: 0.5979 - mae: 0.3913\n",
            "Epoch 489: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6022 - mse: 0.6022 - mae: 0.3925 - lr: 1.0000e-05\n",
            "Epoch 490/500\n",
            "166/167 [============================>.] - ETA: 0s - loss: 0.6006 - mse: 0.6006 - mae: 0.3915\n",
            "Epoch 490: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6013 - mse: 0.6013 - mae: 0.3917 - lr: 1.0000e-05\n",
            "Epoch 491/500\n",
            "153/167 [==========================>...] - ETA: 0s - loss: 0.6094 - mse: 0.6094 - mae: 0.3971\n",
            "Epoch 491: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 3ms/step - loss: 0.6024 - mse: 0.6024 - mae: 0.3962 - lr: 1.0000e-05\n",
            "Epoch 492/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6021 - mse: 0.6021 - mae: 0.3924\n",
            "Epoch 492: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6020 - mse: 0.6020 - mae: 0.3923 - lr: 1.0000e-05\n",
            "Epoch 493/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6031 - mse: 0.6031 - mae: 0.3987\n",
            "Epoch 493: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6019 - mse: 0.6019 - mae: 0.3987 - lr: 1.0000e-05\n",
            "Epoch 494/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6059 - mse: 0.6059 - mae: 0.3971\n",
            "Epoch 494: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6013 - mse: 0.6013 - mae: 0.3956 - lr: 1.0000e-05\n",
            "Epoch 495/500\n",
            "165/167 [============================>.] - ETA: 0s - loss: 0.6007 - mse: 0.6007 - mae: 0.3928\n",
            "Epoch 495: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6014 - mse: 0.6014 - mae: 0.3930 - lr: 1.0000e-05\n",
            "Epoch 496/500\n",
            "158/167 [===========================>..] - ETA: 0s - loss: 0.6043 - mse: 0.6043 - mae: 0.3957\n",
            "Epoch 496: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6013 - mse: 0.6013 - mae: 0.3951 - lr: 1.0000e-05\n",
            "Epoch 497/500\n",
            "162/167 [============================>.] - ETA: 0s - loss: 0.6042 - mse: 0.6042 - mae: 0.3963\n",
            "Epoch 497: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6021 - mse: 0.6021 - mae: 0.3966 - lr: 1.0000e-05\n",
            "Epoch 498/500\n",
            "155/167 [==========================>...] - ETA: 0s - loss: 0.5969 - mse: 0.5969 - mae: 0.3976\n",
            "Epoch 498: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6037 - mse: 0.6037 - mae: 0.3985 - lr: 1.0000e-05\n",
            "Epoch 499/500\n",
            "160/167 [===========================>..] - ETA: 0s - loss: 0.6049 - mse: 0.6049 - mae: 0.3962\n",
            "Epoch 499: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6021 - mse: 0.6021 - mae: 0.3950 - lr: 1.0000e-05\n",
            "Epoch 500/500\n",
            "163/167 [============================>.] - ETA: 0s - loss: 0.6047 - mse: 0.6047 - mae: 0.3962\n",
            "Epoch 500: saving model to model_weights.h5\n",
            "167/167 [==============================] - 1s 4ms/step - loss: 0.6012 - mse: 0.6012 - mae: 0.3956 - lr: 1.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f34aedf6ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import zscore\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/DEEP Learning Project/Input Data.csv\")\n",
        "X = data.X\n",
        "y = data.Y\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=1)\n",
        "y_train.shape\n",
        "def reshape(X):\n",
        "  X = np.array(X)\n",
        "  return X.reshape(-1,1)\n",
        "\n",
        "X_train = reshape(X_train[:])\n",
        "X_test = reshape(X_test[:])\n",
        "y_train = y_train[:]\n",
        "def scale_datasets(x_train, x_test):\n",
        "\n",
        "  \"\"\"\n",
        "  Standard Scale test and train data\n",
        "  Z - Score normalization\n",
        "  \"\"\"\n",
        "  standard_scaler = StandardScaler()\n",
        "  x_train_scaled = pd.DataFrame(\n",
        "      standard_scaler.fit_transform(x_train)\n",
        "  )\n",
        "  x_test_scaled = pd.DataFrame(\n",
        "      standard_scaler.transform(x_test)\n",
        "  )\n",
        "  return x_train_scaled, x_test_scaled\n",
        "X_train_scaled, X_test_scaled = scale_datasets(X_train, X_test)\n",
        "X_train_scaled.shape\n",
        "\n",
        "\n",
        "# data = pd.read_csv(\"/content/drive/MyDrive/DEEP Learning Project/Input Data.csv\")\n",
        "# X = data.X\n",
        "# y = data.Y\n",
        "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=42)\n",
        "# y_train.shape\n",
        "# def reshape(X):\n",
        "#   X = np.array(X)\n",
        "#   return X.reshape(-1,1)\n",
        "# def scaling(X):\n",
        "\n",
        "# X_train_scaled = reshape(X_train_scaled)\n",
        "# X_test = reshape(X_test_scaled[:])\n",
        "# y_train = y_train[:]\n",
        "\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,BatchNormalization,InputLayer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import L1,L2\n",
        "\n",
        "image_size=X_train.shape[1]\n",
        "\n",
        "# create model\n",
        "model = Sequential()  \n",
        "model.add(InputLayer(input_shape=X_train.shape[1]))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Dense(3200, activation='relu',kernel_initializer='normal')) ###Multiple Dense units with Relu activation\n",
        "# model.add(Dense(64, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(256, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(128, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(64, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(2000, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(128, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(256, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dense(128, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(64, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.3))\n",
        "# model.add(Dense(64, activation='relu',kernel_initializer='normal'))\n",
        "# model.add(Dense(5000, activation='relu',kernel_initializer='normal'))\n",
        "model.add(Dense(1, activation='linear')) ### For multiclass classification Softmax is used \n",
        "\n",
        "\n",
        "model.compile(loss=losses.MeanSquaredError(), optimizer=optimizers.Adam(learning_rate=0.0616*1.7), metrics=['mse','mae']) ### Loss function = Categorical cross entropy\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\",monitor='mae',save_weights_only=True, mode='min',verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='mae',factor=0.85,patience=2,min_lr=0.00001,model='auto')\n",
        "\n",
        "callbacks = [checkpoint,reduce_lr]\n",
        "\n",
        "model.fit(X_train_scaled,y_train,epochs=500,batch_size=68,callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Lowest MeanSquaredError = 0.5896\n",
        "*   and mean absolute error = 0.4004\n",
        "\n"
      ],
      "metadata": {
        "id": "tBLcEkMm_E76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction for test "
      ],
      "metadata": {
        "id": "Dvbopjlu_ajy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "OE-6PDq1TFQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b7bff2-df0b-4384-fd19-44a6078e991e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "pre = model.predict(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating error range and drawing pie chart for error"
      ],
      "metadata": {
        "id": "yXVYVl_Z_qAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 0\n",
        "b = 0\n",
        "c = 0\n",
        "d = 0\n",
        "e = 0\n",
        "da = []\n",
        "for i in range(len(y_test)):\n",
        "  p = pre[i][0]-y_test.iloc[i]\n",
        "  if -0.1<p<=0.1:\n",
        "    da.append(0)\n",
        "    a+=1\n",
        "  elif -0.2<=p<-0.1 or 0.1<p<=0.2:\n",
        "    da.append(1)\n",
        "    b+=1\n",
        "  elif -1<=p<-0.2 or 0.2<p<=1:\n",
        "    da.append(2)\n",
        "    c +=1\n",
        "  elif -5<=p<-1 or 1<p<=5:\n",
        "    da.append(3)\n",
        "    d+=1\n",
        "  else:\n",
        "    da.append(4)\n",
        "    e+=1\n",
        "Error_1 = (a/(a+b+c+d+e))*100\n",
        "Error_2 = (b/(a+b+c+d+e))*100\n",
        "Error_3 = (c/(a+b+c+d+e))*100\n",
        "Error_4 = (d/(a+b+c+d+e))*100\n",
        "Error_5 = (e/(a+b+c+d+e))*100\n",
        "print(\"Model predict with loss in between -0.1-0.1 is \",Error_1,\"%\",\"\\nModel predict with loss in between -0.2 to -0.1 and 0.1 to 0.2 is \",Error_2,\"%\",\n",
        "      \"\\nModel predict with loss in between -1 to -0.2 and 0.2 to 1  is \",Error_3,\"%\",\"\\nModel predict with loss in between -5 to -1 and 1 to 5 is \",Error_4,\"%\",\"\\nModel predict with loss in between -5> and 5< is \",Error_5,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpN3y9AfYl9b",
        "outputId": "e7b5b099-44d6-4039-f74d-170b73b95a88"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model predict with loss in between -0.1-0.1 is  54.12698412698413 % \n",
            "Model predict with loss in between -0.2 to -0.1 and 0.1 to 0.2 is  6.746031746031746 % \n",
            "Model predict with loss in between -1 to -0.2 and 0.2 to 1  is  25.634920634920633 % \n",
            "Model predict with loss in between -5 to -1 and 1 to 5 is  13.015873015873018 % \n",
            "Model predict with loss in between -5> and 5< is  0.4761904761904762 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Error pie chart\n",
        "\n",
        "\n",
        "\n",
        "* Error in between -0.1-0.1 == Error_1\n",
        "* Error in between -0.2 to -0.1 and 0.1 to 0.2. == Error_2\n",
        "* Error in between -1 to -0.2 and 0.2 to 1 == Error_3\n",
        "* Error in between -5 to -1 and 1 to 5 == Error_4\n",
        "* Error in between Other == Error_5\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nx9DexXQ_2ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groups = [\"Error_1\",\"Error_2\",\"Error_3\",'Error_4','Error_5']\n",
        "per = [Error_1,Error_2,Error_3,Error_4,Error_5]\n",
        "figure = plt.figure(figsize = (10,7))\n",
        "plt.pie(per,labels = groups,autopct = \"%1.1f%%\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "d-CMQzGeYosa",
        "outputId": "a55f6ff6-6b4b-4445-b20f-a309b9032321"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ne2qWjYfHVcE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}